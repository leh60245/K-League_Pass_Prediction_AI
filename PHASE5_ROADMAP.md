# ğŸ‰ V4.1 ì„±ê³µ! - ì„±ê³¼ ë¶„ì„ ë° ë‹¤ìŒ ëª©í‘œ

## ğŸ“Š í˜„ì¬ê¹Œì§€ ë‹¬ì„± ì„±ê³¼

### ë²„ì „ë³„ Test ì„±ëŠ¥
```
V1:  24ì ëŒ€     (Baseline, Data Leakage)
V3:  14.535ì    (ì‹œí€€ìŠ¤ ëª¨ë¸ë§, -9.465ì )
V4:  14.308ì    (ë„ë©”ì¸ í”¼ì²˜, -0.227ì )
V4.1: 14.138ì    (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, -0.170ì )
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´ ê°œì„ : 9.86ì  (41.1% ê°œì„ ) âœ…
```

### ê°œì„  ë°©ë²•ë³„ ê¸°ì—¬ë„
```
1. ì‹œí€€ìŠ¤ ëª¨ë¸ë§ (V3):          -9.465ì  â­â­â­â­â­
2. ë„ë©”ì¸ í”¼ì²˜ (V4):           -0.227ì  â­â­â­
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (V4.1): -0.170ì  â­â­â­â­
```

---

## ğŸ¯ ë‹¤ìŒ ëª©í‘œ: 13ì ëŒ€ ì§„ì… (Top 10% ë„ì „)

### ìµœì¢… ëª©í‘œ
```
í˜„ì¬:    14.138ì 
ë‹¨ê¸°:    13.8~14.0ì  (0.1~0.3ì  ê°œì„ )
ì¤‘ê¸°:    13.5~13.8ì  (0.3~0.6ì  ê°œì„ )
ì¥ê¸°:    13.0~13.5ì  (0.6~1.1ì  ê°œì„ )
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ëª©í‘œ:    13.5ì  ì´í•˜ (Top 10% ì˜ˆìƒ)
```

---

## ğŸš€ Phase 5: ì¶”ê°€ ìµœì í™” ì „ëµ (ìš°ì„ ìˆœìœ„)

### Strategy 1: K ê°’ ìµœì í™” â­â­â­â­â­ (ì¦‰ì‹œ ì‹¤í–‰)

**ëª©í‘œ**: ì‹œí€€ìŠ¤ ê¸¸ì´ ìµœì í™”ë¡œ 0.1~0.3ì  ê°œì„ 

**ê°€ì„¤**:
- í˜„ì¬ K=20ì´ ìµœì ì´ ì•„ë‹ ìˆ˜ ìˆìŒ
- ë” ì§§ì€ ì‹œí€€ìŠ¤(K=15)ê°€ ë…¸ì´ì¦ˆ ê°ì†Œ
- ë” ê¸´ ì‹œí€€ìŠ¤(K=25,30)ê°€ ë” ë§ì€ ì •ë³´ ì œê³µ

**ì‹¤í–‰ ê³„íš**:
```python
# 1. Quick Test (1-Fold, ê° Kë‹¹ 5ë¶„)
K_candidates = [15, 20, 25, 30]
for k in K_candidates:
    - ì „ì²˜ë¦¬ (K ë³€ê²½)
    - 1-Fold í•™ìŠµ
    - Validation ì ìˆ˜ ë¹„êµ

# 2. Best Kë¡œ Full 5-Fold ì¬í•™ìŠµ
- ìµœê³  ì„±ëŠ¥ K ì„ íƒ
- V4.2 ìƒì„± (5-Fold ì „ì²´)
- ì œì¶œ ë° ì ìˆ˜ í™•ì¸
```

**ì˜ˆìƒ ê²°ê³¼**:
- K=15: ë” ìµœê·¼ ì´ë²¤íŠ¸ ê°•ì¡° â†’ 13.9~14.1ì 
- K=25: ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ â†’ 13.8~14.0ì 
- K=30: ìµœëŒ€ ì •ë³´ (ë…¸ì´ì¦ˆ ì¦ê°€ ê°€ëŠ¥) â†’ 13.9~14.1ì 

**íˆ¬ì ëŒ€ë¹„ íš¨ê³¼**: ë§¤ìš° ë†’ìŒ
- ì‹œê°„: 2-3ì‹œê°„ (Quick Test 1ì‹œê°„ + Full 1-2ì‹œê°„)
- ê°œì„ : 0.1~0.3ì 

---

### Strategy 2: ëª¨ë¸ ë‹¤ì–‘í™” (XGBoost, CatBoost) â­â­â­â­ (ë³‘ë ¬ ì§„í–‰ ê°€ëŠ¥)

**ëª©í‘œ**: ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìƒí˜¸ë³´ì™„ì  ì˜ˆì¸¡

**ì‹¤í–‰ ê³„íš**:

**2-1. XGBoost êµ¬í˜„**
```python
# LightGBMê³¼ ë™ì¼í•œ V4.1 í”¼ì²˜ ì‚¬ìš©
import xgboost as xgb

params = {
    'objective': 'reg:squarederror',
    'learning_rate': 0.02,
    'max_depth': 7,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
}

# 5-Fold í•™ìŠµ
# ì˜ˆìƒ: 14.0~14.3ì 
```

**2-2. CatBoost êµ¬í˜„**
```python
from catboost import CatBoostRegressor

model = CatBoostRegressor(
    iterations=3000,
    learning_rate=0.02,
    depth=7,
    cat_features=['type_id', 'res_id'],  # ë²”ì£¼í˜• ìë™ ì²˜ë¦¬
)

# ì˜ˆìƒ: 13.9~14.2ì  (ë²”ì£¼í˜• ì²˜ë¦¬ ê°•ì )
```

**2-3. 3-Model ì•™ìƒë¸”**
```python
# ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
pred_final = 0.4 * pred_lgbm + 0.3 * pred_xgb + 0.3 * pred_cat

# ë˜ëŠ” Stacking (Meta-model)
# ì˜ˆìƒ: 13.7~13.9ì  (ì•™ìƒë¸” íš¨ê³¼)
```

**íˆ¬ì ëŒ€ë¹„ íš¨ê³¼**: ë†’ìŒ
- ì‹œê°„: 2-3ì¼ (ê° ëª¨ë¸ 1ì¼ì”©)
- ê°œì„ : 0.2~0.4ì  (ì•™ìƒë¸”)

---

### Strategy 3: Feature Engineering V2 â­â­â­â­

**ëª©í‘œ**: ì‹œí€€ìŠ¤ íŒ¨í„´ì„ ë” ì˜ í¬ì°©í•˜ëŠ” í”¼ì²˜ ì¶”ê°€

**3-1. ì‹œí€€ìŠ¤ ì§‘ê³„ í”¼ì²˜**
```python
# ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ì˜ í†µê³„ëŸ‰
for k in range(K):
    # Rolling statistics
    df[f'speed_rolling_mean_{k}'] = df['speed'].rolling(3).mean()
    df[f'distance_rolling_std_{k}'] = df['dist'].rolling(3).std()
    
    # Exponential weighted (ìµœê·¼ ê°€ì¤‘)
    df[f'x_ema_{k}'] = df['start_x'].ewm(span=3).mean()
    df[f'goal_dist_ema_{k}'] = df['distance_to_goal'].ewm(span=3).mean()
    
    # ì¶”ì„¸ (Trend)
    df[f'x_trend_{k}'] = df['start_x'].diff().rolling(3).mean()
```

**3-2. ì´ë²¤íŠ¸ ê°„ ìƒí˜¸ì‘ìš©**
```python
# ì—°ì† ì´ë²¤íŠ¸ ê°„ íŒ¨í„´
df['direction_change'] = np.abs(angle[i] - angle[i-1])
df['speed_change_rate'] = (speed[i] - speed[i-1]) / (speed[i-1] + 1e-3)
df['pressure_intensity'] = events_in_radius_5m / dt
```

**3-3. ê²Œì„ ìƒí™© í”¼ì²˜**
```python
# ê²½ê¸° ì»¨í…ìŠ¤íŠ¸
df['attack_urgency'] = (remaining_time < 300) & (in_final_third)
df['counter_attack'] = (x_progression > 30) & (dt < 10)
df['possession_tempo'] = episode_length / total_time
```

**íˆ¬ì ëŒ€ë¹„ íš¨ê³¼**: ì¤‘ìƒ
- ì‹œê°„: 2-3ì¼
- ê°œì„ : 0.2~0.5ì 

---

### Strategy 4: Stacking ì•™ìƒë¸” â­â­â­â­

**ëª©í‘œ**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìµœì  ì¡°í•©

**ì‹¤í–‰ ê³„íš**:
```python
# Level 1: Base Models
models_level1 = [
    LightGBM_V4.1,
    XGBoost,
    CatBoost,
]

# Level 2: Meta-Model (Ridge ë˜ëŠ” LightGBM)
meta_model = Ridge(alpha=10)

# Out-of-fold ì˜ˆì¸¡ìœ¼ë¡œ í•™ìŠµ
for fold in 5_folds:
    # Level 1 ì˜ˆì¸¡
    pred_lgbm = model_lgbm.predict(X_val)
    pred_xgb = model_xgb.predict(X_val)
    pred_cat = model_cat.predict(X_val)
    
    # Meta features
    X_meta = np.column_stack([pred_lgbm, pred_xgb, pred_cat])
    
    # Meta model í•™ìŠµ
    meta_model.fit(X_meta, y_val)

# ì˜ˆìƒ: 13.6~13.8ì 
```

**íˆ¬ì ëŒ€ë¹„ íš¨ê³¼**: ë†’ìŒ
- ì‹œê°„: 1-2ì¼ (Base ëª¨ë¸ í•„ìš”)
- ê°œì„ : 0.2~0.4ì 

---

### Strategy 5: Neural Network (LSTM/Transformer) â­â­â­ (ì¥ê¸°)

**ëª©í‘œ**: ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ

**5-1. LSTM**
```python
import torch
import torch.nn as nn

class PassLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim=128):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, 
                           num_layers=2, dropout=0.2)
        self.fc = nn.Linear(hidden_dim, 2)  # end_x, end_y
    
    def forward(self, x):
        # x: [batch, seq_len=20, features]
        lstm_out, _ = self.lstm(x)
        last_output = lstm_out[:, -1, :]
        return self.fc(last_output)

# ì˜ˆìƒ: 13.5~13.9ì 
```

**5-2. Transformer (Attention)**
```python
# Self-attentionìœ¼ë¡œ ì¤‘ìš” ì´ë²¤íŠ¸ ìë™ ì„ íƒ
# ë” ê°•ë ¥í•˜ì§€ë§Œ ë°ì´í„° ë¶€ì¡± ê°€ëŠ¥ì„±

# ì˜ˆìƒ: 13.3~13.8ì  (ê°€ì¥ ë†’ì€ ì ì¬ë ¥)
```

**íˆ¬ì ëŒ€ë¹„ íš¨ê³¼**: ì¤‘í•˜ (ë¶ˆí™•ì‹¤ì„± ë†’ìŒ)
- ì‹œê°„: 3-5ì¼
- ê°œì„ : 0.3~0.8ì  (ì„±ê³µ ì‹œ)
- ë¦¬ìŠ¤í¬: ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ê³¼ì í•© ê°€ëŠ¥

---

## ğŸ“… ì¶”ì²œ ì‹¤í–‰ ìˆœì„œ (1-2ì£¼ ê³„íš)

### Week 1: Quick Wins

**Day 1 (ì˜¤ëŠ˜)** âœ…
- [x] V4.1 ì™„ë£Œ (14.138ì )
- [ ] K ê°’ ìµœì í™” ì‹¤í—˜ ì‹œì‘

**Day 2**
- [ ] K ê°’ ìµœì í™” ì™„ë£Œ
- [ ] V4.2 ìƒì„± (ìµœì  K)
- [ ] ì œì¶œ ë° ì ìˆ˜ í™•ì¸
- **ëª©í‘œ: 13.9~14.0ì **

**Day 3-4**
- [ ] XGBoost êµ¬í˜„ ë° í•™ìŠµ
- [ ] ë‹¨ë… ì„±ëŠ¥ í™•ì¸
- **ëª©í‘œ: 14.0~14.2ì **

**Day 5**
- [ ] CatBoost êµ¬í˜„ ë° í•™ìŠµ
- [ ] ë‹¨ë… ì„±ëŠ¥ í™•ì¸
- **ëª©í‘œ: 13.9~14.2ì **

**Day 6-7**
- [ ] 3-Model ì•™ìƒë¸”
- [ ] ê°€ì¤‘ì¹˜ ìµœì í™”
- [ ] ì œì¶œ ë° ì ìˆ˜ í™•ì¸
- **ëª©í‘œ: 13.7~13.9ì **

### Week 2: Advanced Optimization

**Day 8-10**
- [ ] ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
- [ ] V5 íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- **ëª©í‘œ: 13.6~13.8ì **

**Day 11-12**
- [ ] Stacking ì•™ìƒë¸”
- [ ] Meta-model ìµœì í™”
- **ëª©í‘œ: 13.5~13.7ì **

**Day 13-14 (ì„ íƒ)**
- [ ] LSTM ì‹¤í—˜
- [ ] ìµœì¢… ì•™ìƒë¸”
- **ëª©í‘œ: 13.3~13.6ì **

---

## ğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ê³„íš: K ê°’ ìµœì í™”

### ëª©í‘œ
```
í˜„ì¬ V4.1: 14.138ì  (K=20)
ëª©í‘œ V4.2: 13.9~14.0ì  (ìµœì  K)
ê°œì„ :      0.1~0.3ì 
```

### ì‹¤í–‰ ë‹¨ê³„

**Step 1: Quick Test (1ì‹œê°„)**
```python
# K=15, 20, 25, 30 ê°ê° 1-Fold í…ŒìŠ¤íŠ¸
# ê°€ì¥ ì¢‹ì€ K ì„ íƒ
```

**Step 2: Full Training (1-2ì‹œê°„)**
```python
# ìµœì  Kë¡œ 5-Fold ì¬í•™ìŠµ
# V4.2 ëª¨ë¸ ìƒì„±
```

**Step 3: Inference & Submit (10ë¶„)**
```python
# Test ì¶”ë¡ 
# ì œì¶œ íŒŒì¼ ìƒì„±
```

---

## ğŸ’¡ ì „ë¬¸ê°€ ì¡°ì–¸

### ìš°ì„ ìˆœìœ„ Top 3

**1. K ê°’ ìµœì í™”** â­â­â­â­â­
- ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•œ ê°œì„ 
- íˆ¬ì: 2-3ì‹œê°„
- ë¦¬í„´: 0.1~0.3ì 
- **ì¦‰ì‹œ ì‹œì‘ ê¶Œì¥**

**2. XGBoost/CatBoost ì•™ìƒë¸”** â­â­â­â­
- ê²€ì¦ëœ ë°©ë²•
- íˆ¬ì: 2-3ì¼
- ë¦¬í„´: 0.2~0.4ì 
- **ë³‘ë ¬ ì§„í–‰ ê°€ëŠ¥**

**3. Stacking** â­â­â­â­
- ìµœê³  ì„±ëŠ¥ ê¸°ëŒ€
- íˆ¬ì: 1-2ì¼ (Base ëª¨ë¸ í•„ìš”)
- ë¦¬í„´: 0.2~0.4ì 
- **Week 1 ì´í›„ ì¶”ì²œ**

### í”¼í•´ì•¼ í•  ê²ƒ

âŒ **ê³¼ë„í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**
- 100ê°œ ì´ìƒ ì¶”ê°€ëŠ” ê³¼ì í•© ìœ„í—˜
- ê²€ì¦ëœ íŒ¨í„´ë§Œ ì¶”ê°€

âŒ **ë³µì¡í•œ ì‹ ê²½ë§ë¶€í„° ì‹œì‘**
- LSTM/TransformerëŠ” ë§ˆì§€ë§‰ ì¹´ë“œ
- ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ë¨¼ì € ì™„ë²½í•˜ê²Œ

âŒ **ê²€ì¦ ì—†ëŠ” ì•™ìƒë¸”**
- í•­ìƒ 5-Fold CVë¡œ ê²€ì¦
- Validationê³¼ Test íŒ¨í„´ ë¹„êµ

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ë¡œë“œë§µ

```
í˜„ì¬ (V4.1):        14.138ì  âœ…
    â†“ K ìµœì í™” (Day 2)
V4.2:               13.9~14.0ì 
    â†“ XGBoost (Day 4)
XGB V4.2:           14.0~14.2ì 
    â†“ CatBoost (Day 5)
Cat V4.2:           13.9~14.2ì 
    â†“ 3-Model ì•™ìƒë¸” (Day 7)
Ensemble:           13.7~13.9ì 
    â†“ ê³ ê¸‰ í”¼ì²˜ (Day 10)
V5:                 13.6~13.8ì 
    â†“ Stacking (Day 12)
V6:                 13.5~13.7ì 
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ìµœì¢… ëª©í‘œ:          13.3~13.6ì  (Top 10%)
```

---

## ğŸ”¥ ì¦‰ì‹œ ì‹¤í–‰: K ê°’ ìµœì í™”

### ìƒì„±í•  íŒŒì¼
1. `experiment_k_values_v4.1.py` - K ê°’ ì‹¤í—˜
2. `preprocessing_v4.2_kX.py` - ìµœì  Kë¡œ ì „ì²˜ë¦¬
3. `train_v4.2_best_k.py` - ìµœì  Kë¡œ í•™ìŠµ
4. `inference_v4.2.py` - V4.2 ì¶”ë¡ 

### ì‹¤í–‰ ëª…ë ¹
```bash
# Step 1: K ê°’ ì‹¤í—˜ (1ì‹œê°„)
python experiment_k_values_v4.1.py

# Step 2: ìµœì  Kë¡œ V4.2 í•™ìŠµ (1-2ì‹œê°„)
python train_v4.2_best_k.py

# Step 3: ì¶”ë¡  ë° ì œì¶œ (10ë¶„)
python inference_v4.2.py
```

---

## ğŸŠ ê²°ë¡ 

**í˜„ì¬ ìœ„ì¹˜**: ë§¤ìš° ìš°ìˆ˜! (14.138ì )

**ë‹¤ìŒ ë‹¨ê³„**: K ê°’ ìµœì í™” (ê°€ì¥ ë¹ ë¥¸ ê°œì„ )

**1ì£¼ì¼ ëª©í‘œ**: 13.7~13.9ì  (3-Model ì•™ìƒë¸”)

**2ì£¼ì¼ ëª©í‘œ**: 13.5~13.7ì  (Stacking)

**ìµœì¢… ëª©í‘œ**: 13.3~13.6ì  (Top 10%)

---

**ì‘ì„±ì¼**: 2025-12-17  
**í˜„ì¬ ì„±ê³¼**: V4.1 14.138ì   
**ë‹¤ìŒ ëª©í‘œ**: V4.2 13.9~14.0ì  (K ìµœì í™”)  
**ìµœì¢… ëª©í‘œ**: 13.5ì  ì´í•˜ (Top 10%)

ğŸš€ ì§€ê¸ˆ ë°”ë¡œ K ê°’ ìµœì í™”ë¥¼ ì‹œì‘í•©ì‹œë‹¤!

