# V4 파이프라인 개발 완료 - 최종 요약

## 🎉 프로젝트 완료

**날짜**: 2025-12-17  
**목표**: V2의 도메인 지식 + V3의 시퀀스 모델링 = 최고 성능

---

## ✅ 완료된 작업

### 1. V4 파이프라인 개발
- ✅ `preprocessing_v4.py` - Train/Test 통합 전처리
- ✅ `train_lightgbm_v4.py` - 5-Fold 앙상블 학습
- ✅ `inference_v4.py` - Test 추론
- ✅ `ensemble_v3_v4.py` - V3/V4 앙상블

### 2. 핵심 개선사항 적용
- ✅ Data Leakage 완전 제거
- ✅ 시퀀스 모델링 (마지막 20개 이벤트)
- ✅ Wide format (시간 순서 보존)
- ✅ V2의 비선형 변환 피처 (8개)
- ✅ V2의 위치 특화 피처 (6개)
- ✅ 5-Fold GroupKFold 앙상블

---

## 📊 최종 성능 비교

### Validation 성능

| 버전 | Validation | 피처 수 | 특징 |
|------|-----------|---------|------|
| V1 | 0.93m | ~50 | ❌ Data Leakage (부정확) |
| V2 | N/A | ~100 | ❌ Data Leakage (미검증) |
| **V3** | **14.40m** | ~400 | ✅ 시퀀스 모델링 |
| **V4** | **14.36m** | **776** | ✅ V2 + V3 통합 |

### Test 성능 (실제/예상)

| 버전 | Test 점수 | 개선율 |
|------|-----------|--------|
| V1 | 24점대 | Baseline |
| **V3** | **14점대** | **42% 개선** ✅ |
| **V4** | **13~15점대 (예상)** | **38~46% 개선** 🎯 |

---

## 🔍 V3 vs V4 상세 비교

### 공통점
- ✅ Data Leakage 완전 제거
- ✅ 시퀀스 모델링 (마지막 K=20개 이벤트)
- ✅ Wide format 변환
- ✅ 5-Fold GroupKFold 앙상블
- ✅ Train/Test 통합 처리

### 차이점

#### V3 (단순, 안정)
```
피처: 기본 위치/이동/시간 피처 (~400개)
- start_x, start_y, end_x, end_y
- dx, dy, dist, speed
- dt, x_zone, lane
- is_final_team
- 기본 골 관련 피처

장점:
✅ 단순하고 안정적
✅ 빠른 학습 (100~150 rounds)
✅ 해석 용이

단점:
⚠️  도메인 지식 제한적
```

#### V4 (풍부, 복잡)
```
피처: V3 + V2 도메인 지식 (776개)
- V3의 모든 기본 피처
+ 비선형 변환 (8개 × 20 시점)
  - distance_to_goal_inv, sqrt
  - shooting_angle_sin, cos
  - start_x_squared, start_y_squared
  - x_y_interaction, goal_dist_angle_interaction
+ 위치 특화 (6개 × 20 시점)
  - is_defensive_third
  - goal_urgency
  - is_central_corridor
  - near_goal_zone
  - is_wing_attack
  - is_midfield_control

장점:
✅ 풍부한 도메인 지식
✅ 다양한 패턴 포착
✅ V3와 동일한 성능 (과적합 없음)

단점:
⚠️  복잡도 높음
⚠️  학습 시간 약간 증가
```

---

## 🎯 V3/V4 예측 차이 분석

### 앙상블 잠재력

```
평균 예측 차이: 2.02m (유클리드 거리)
- end_x: 1.38m
- end_y: 1.17m

큰 차이 샘플 (>5m): 68 / 2,414 (2.82%)

✅ 적당한 차이 → 앙상블 효과 기대
```

### Feature Importance 차이

**V3 Top 5 (추정)**
```
1. start_x_19 (마지막 시작 X)
2. end_x_18 (직전 종료 X)
3. dt_19 (마지막 시간 간격)
4. dx_18 (직전 이동량)
5. res_id_19 (마지막 결과)
```

**V4 Top 5 (실제)**
```
1. dt_19 (432.0)
2. end_x_18 (267.0)
3. dx_18 (210.0)
4. start_x_19 (207.0)
5. res_id_19 (172.0)

+ V2 피처들 (상위 20위 내)
- goal_dist_angle_interaction_19 (145.0)
- distance_to_goal_inv_19 (119.0)
- distance_to_goal_sqrt_19 (102.0)
- shooting_angle_19 (86.0)
```

**인사이트:**
- 기본 피처가 여전히 가장 중요
- V2 피처들이 보조적 역할
- 마지막 2개 이벤트(18, 19)가 핵심

---

## 📁 생성된 제출 파일

### V4 단독
```
submission_v4_5fold_20251217_173058.csv
- Validation: 14.36m
- 예상: 13~15점대
```

### V3/V4 앙상블
```
1. submission_ensemble_v3_v4_50_50_*.csv  (0.5:0.5 평균)
2. submission_ensemble_v3_v4_60_40_*.csv  (V3 우선)
3. submission_ensemble_v3_v4_40_60_*.csv  (V4 우선)
```

---

## 🚀 제출 전략

### 1단계: 개별 모델 성능 확인
```
1차 제출: V3 단독
   → 검증된 성능 (Test 14점대)
   
2차 제출: V4 단독
   → V2 피처 효과 확인
   → 예상: V3와 유사 또는 소폭 개선
```

### 2단계: 앙상블 효과 확인
```
3차 제출: 앙상블 0.5:0.5
   → 두 모델의 균형
   → 예상: 안정성 향상
   
4차 제출: 더 나은 모델 우선 (0.6:0.4)
   → 1~2차 결과 기반 결정
```

### 3단계: 추가 개선 (필요시)
```
- 하이퍼파라미터 튜닝
- K 값 조정 (15, 25, 30)
- Feature Selection
- 다른 모델 (XGBoost, CatBoost)
```

---

## 💡 핵심 인사이트

### 1. 시퀀스 모델링이 핵심
```
V1 (전체 이벤트 집계) → 24점대
V3/V4 (마지막 20개) → 14점대

→ 42% 성능 개선의 핵심 요인
```

### 2. Data Leakage 제거 필수
```
V1 Validation (Leakage): 0.93m → Test: 24점대
V3/V4 Validation (정직): 14m → Test: 14점대

→ Validation이 정직해야 Test 성능 예측 가능
```

### 3. 피처 엔지니어링의 적절한 활용
```
V4가 V3보다 2배 많은 피처 (776 vs 400)
→ 성능은 거의 동일 (14.36m vs 14.40m)

→ 기본 피처가 가장 중요, 도메인 피처는 보조
→ 과적합 없이 안정적 (LightGBM의 강점)
```

### 4. 앙상블의 가치
```
V3/V4 예측 차이: 2.02m (적당함)
→ 앙상블로 안정성 향상 가능
→ 서로 다른 패턴 포착 (상호보완)
```

---

## 🎓 프로젝트 교훈

### 성공 요인
1. ✅ **체계적 분석**: 다른 우수 사례 분석 (sample_from_other.py)
2. ✅ **점진적 개선**: V1 → V2 → V3 → V4
3. ✅ **핵심 파악**: 시퀀스 모델링 + Leakage 제거
4. ✅ **검증 철저**: GroupKFold로 정직한 평가
5. ✅ **통합 시도**: V2와 V3의 장점 결합

### 실패에서 배운 점
1. 💡 **V1의 교훈**: Data Leakage는 재앙
2. 💡 **V2의 교훈**: 피처만으로는 부족 (파이프라인 중요)
3. 💡 **V4의 교훈**: 많은 피처 ≠ 더 나은 성능 (단순함의 가치)

### 머신러닝 Best Practices
```
1. Data Leakage 항상 경계
2. Validation을 신뢰하되, Test로 검증
3. 단순 모델부터 시작
4. 점진적 개선
5. 앙상블로 안정성 확보
```

---

## 📊 최종 성과

### 정량적 성과
- ✅ Test 성능 **24점 → 14점** (42% 개선)
- ✅ Validation 성능 안정화 (14.36m ~ 14.40m)
- ✅ 2개의 우수 모델 확보 (V3, V4)
- ✅ 3개의 앙상블 제출 파일 준비

### 정성적 성과
- ✅ 견고한 파이프라인 구축
- ✅ Data Leakage 완전 제거
- ✅ 재현 가능한 코드
- ✅ 도메인 지식 체계화
- ✅ 앙상블 전략 수립

---

## 🎯 결론

**V4 파이프라인 개발 성공! 🎉**

1. **V3**: 단순하고 안정적 (14.40m, 14점대)
2. **V4**: 풍부하고 견고함 (14.36m, 13~15점대)
3. **앙상블**: 더 나은 안정성 기대

**두 모델 모두 우수하며, 상황에 따라 선택 가능**

---

## 📝 다음 단계 (선택사항)

### 단기 (제출 전략)
- [ ] V3 단독 제출 → 점수 확인
- [ ] V4 단독 제출 → V2 피처 효과 검증
- [ ] 앙상블 제출 → 안정성 검증

### 중기 (추가 개선)
- [ ] 하이퍼파라미터 튜닝 (Optuna)
- [ ] K 값 최적화 (15, 25, 30 실험)
- [ ] Feature Importance 기반 선택

### 장기 (모델 다양화)
- [ ] XGBoost 실험
- [ ] CatBoost 실험
- [ ] Neural Network (LSTM, Transformer)
- [ ] Stacking 앙상블

---

**프로젝트 완료일**: 2025-12-17  
**최종 작성자**: AI Assistant  
**버전**: V4 Final

🎉 축하합니다! 성공적인 프로젝트 완료! 🎉

