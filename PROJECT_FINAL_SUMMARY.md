# ğŸ“Š K-League íŒ¨ìŠ¤ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ - ìµœì¢… ìƒíƒœ

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ
**ìˆœìˆ˜ LSTM ëª¨ë¸ë§Œìœ¼ë¡œ LightGBM (14.138m) ì„±ëŠ¥ ì´ˆê³¼**

---

## ğŸ“ˆ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬

| ë²„ì „ | ëª¨ë¸ | ì£¼ìš” ê¸°ë²• | Val Loss | Public LB | ë¹„ê³  |
|------|------|-----------|----------|-----------|------|
| V1-V3 | LightGBM | ê¸°ë³¸ íŠ¸ë¦¬ ëª¨ë¸ | ~1.5m | - | ì´ˆê¸° ë²„ì „ |
| **V4** | LightGBM | ìµœì í™”ëœ í”¼ì²˜ | **1.5m** | **14.138m** | ğŸ† ìµœê³  ì„±ëŠ¥ |
| V4 | LSTM (Baseline) | ê¸°ë³¸ GRU | 14.7m | 15.649m | ë”¥ëŸ¬ë‹ ì²« ì‹œë„ |
| **V5** | LSTM + Attention | Multi-Head Attention, Bidirectional, Padding Mask | **TBD** | **TBD** | ğŸš€ í˜„ì¬ ë²„ì „ |

---

## ğŸ—‚ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

### âœ… í™œì„± íŒŒì¼ (V5 - LSTM ì „ìš©)

#### ğŸ“Š ë°ì´í„°
- `processed_train_data_v4.csv` - Wide Format í•™ìŠµ ë°ì´í„°
- `processed_test_data_v4.csv` - Wide Format í…ŒìŠ¤íŠ¸ ë°ì´í„°

#### ğŸ§  í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- `train_lstm_v5_attention.py` - **ë‹¨ì¼ Fold í”„ë¡œí† íƒ€ì´í•‘** (ë¹ ë¥¸ ê²€ì¦ìš©)
- `train_lstm_v5_5fold.py` - **5-Fold ì „ì²´ í•™ìŠµ** (ìµœì¢… ì„±ëŠ¥ìš©)

#### ğŸ”® ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
- `inference_lstm_v5_attention.py` - ë‹¨ì¼ Fold ëª¨ë¸ ì¶”ë¡ 
- `inference_lstm_v5_5fold.py` - **5-Fold ì•™ìƒë¸” + TTA ì¶”ë¡ ** (ìµœì¢… ì œì¶œìš©)

#### ğŸ’¾ ëª¨ë¸ íŒŒì¼ (ìƒì„± ì˜ˆì •)
- `lstm_model_v5_attention_best.pth` - ë‹¨ì¼ Fold ëª¨ë¸
- `lstm_model_v5_fold0.pth` ~ `lstm_model_v5_fold4.pth` - 5-Fold ëª¨ë¸

#### ğŸ“„ ë¬¸ì„œ
- `LSTM_PERFORMANCE_IMPROVEMENT_STRATEGY.md` - ì„±ëŠ¥ í–¥ìƒ ì „ëµ ìƒì„¸ ì„¤ëª…
- `LSTM_V5_EXECUTION_GUIDE.md` - ì‹¤í–‰ ê°€ì´ë“œ ë° ë¬¸ì œ í•´ê²°
- `PROJECT_FINAL_SUMMARY.md` - ì´ ë¬¸ì„œ

### âŒ ì œê±°ëœ íŒŒì¼ (ì•™ìƒë¸” ê´€ë ¨)
- `ensemble_model.py`
- `ensemble_3models.py`
- `ensemble_v3_v4.py`
- `inference_ensemble.py`
- `create_ensemble.py`
- `inference_3models.py`
- `create_stacking_quickwin.py`
- `optimize_weights.py`
- `ensemble_model.pkl`
- `ensemble_3models.pkl`

### ğŸ—„ï¸ ë ˆê±°ì‹œ íŒŒì¼ (ì°¸ê³ ìš©)
- `lightgbm_model_v4.1_5fold.pkl` - LightGBM ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `preprocessing_v4.py` - V4 ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- `train_lstm_v4.py` - LSTM Baseline (V4)
- ê¸°íƒ€ ì´ì „ ë²„ì „ íŒŒì¼ë“¤

---

## ğŸ”¬ LSTM V5 í•µì‹¬ ê°œì„ ì‚¬í•­

### 1. **Multi-Head Attention** â­â­â­
```python
self.attention = nn.MultiheadAttention(
    embed_dim=rnn_output_dim,
    num_heads=8,
    dropout=dropout,
    batch_first=True
)
```
- **íš¨ê³¼**: ì‹œí€€ìŠ¤ì—ì„œ ì¤‘ìš”í•œ ì‹œì ì— ì§‘ì¤‘
- **ì˜ˆìƒ ê°œì„ í­**: 10~20%

### 2. **Padding Mask** â­â­â­
```python
def _create_padding_mask(self):
    mask = (self.numerical_tensor.sum(dim=-1) == 0)
    return mask
```
- **íš¨ê³¼**: ì‹¤ì œ ë°ì´í„°ì™€ íŒ¨ë”© êµ¬ë¶„í•˜ì—¬ í•™ìŠµ í’ˆì§ˆ í–¥ìƒ
- **ì˜ˆìƒ ê°œì„ í­**: 5~10%

### 3. **Bidirectional RNN** â­â­
```python
self.rnn = nn.GRU(
    hidden_dim, hidden_dim,
    bidirectional=True
)
```
- **íš¨ê³¼**: ì–‘ë°©í–¥ ì‹œí€€ìŠ¤ ì •ë³´ í™œìš©
- **ì˜ˆìƒ ê°œì„ í­**: 5~10%

### 4. **ì „ì²´ í”¼ì²˜ ì •ê·œí™”** â­â­
```python
# X ì¢Œí‘œ: /105, Y ì¢Œí‘œ: /68
# ì†ë„: /30, ê°ë„: /Ï€, ì‹œê°„: ë™ì  ì •ê·œí™”
```
- **íš¨ê³¼**: í•™ìŠµ ì•ˆì •ì„± ë° ìˆ˜ë ´ ì†ë„ í–¥ìƒ
- **ì˜ˆìƒ ê°œì„ í­**: 5~10%

### 5. **ê¹Šì€ Output Head** â­
```python
self.fc = nn.Sequential(
    nn.Linear(rnn_output_dim, hidden_dim),
    nn.ReLU(),
    nn.LayerNorm(hidden_dim),
    nn.Dropout(dropout),
    nn.Linear(hidden_dim, hidden_dim // 2),
    nn.ReLU(),
    nn.LayerNorm(hidden_dim // 2),
    nn.Dropout(dropout),
    nn.Linear(hidden_dim // 2, 2)
)
```
- **íš¨ê³¼**: ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ëŠ¥ë ¥ í–¥ìƒ
- **ì˜ˆìƒ ê°œì„ í­**: 3~5%

### 6. **Residual Connection** â­
```python
attn_out = self.attention_norm(attn_out + rnn_out)
```
- **íš¨ê³¼**: ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ê°œì„ 
- **ì˜ˆìƒ ê°œì„ í­**: 2~5%

### 7. **5-Fold CV + TTA**
- **5-Fold**: ì¼ë°˜í™” ì„±ëŠ¥ ê·¹ëŒ€í™”
- **TTA** (Test Time Augmentation): ì¢Œìš° ë°˜ì „ ì˜ˆì¸¡ í‰ê· 
- **ì˜ˆìƒ ê°œì„ í­**: 5~10%

---

## ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°

### ìµœì í™”ëœ ì„¤ì • (V5)
```python
K = 20                    # ì‹œí€€ìŠ¤ ê¸¸ì´
BATCH_SIZE = 64          # ë°°ì¹˜ í¬ê¸°
HIDDEN_DIM = 384         # Hidden ì°¨ì›
NUM_LAYERS = 3           # RNN ë ˆì´ì–´ ìˆ˜
DROPOUT = 0.4            # Dropout ë¹„ìœ¨
LEARNING_RATE = 5e-4     # í•™ìŠµë¥ 
NUM_EPOCHS = 100         # ìµœëŒ€ ì—í¬í¬
EARLY_STOPPING_PATIENCE = 20
USE_LSTM = False         # GRU ì‚¬ìš©
BIDIRECTIONAL = True     # ì–‘ë°©í–¥
NUM_HEADS = 8            # Attention Head ìˆ˜
```

### Baseline (V4) ëŒ€ë¹„ ë³€ê²½
- `HIDDEN_DIM`: 256 â†’ **384** (â†‘50%)
- `NUM_LAYERS`: 2 â†’ **3** (â†‘1)
- `DROPOUT`: 0.3 â†’ **0.4** (â†‘0.1)
- `LEARNING_RATE`: 1e-3 â†’ **5e-4** (â†“50%)
- **Bidirectional**: ì¶”ê°€
- **Attention**: ì¶”ê°€

---

## ğŸš€ ì‹¤í–‰ ìˆœì„œ

### Phase 1: ë¹ ë¥¸ ê²€ì¦ (30ë¶„~1ì‹œê°„)
```bash
python train_lstm_v5_attention.py
```
â†’ `lstm_model_v5_attention_best.pth` ìƒì„±

### Phase 2: ì „ì²´ í•™ìŠµ (3~5ì‹œê°„)
```bash
python train_lstm_v5_5fold.py
```
â†’ `lstm_model_v5_fold{0-4}.pth` ìƒì„± (5ê°œ)

### Phase 3: ìµœì¢… ì¶”ë¡  (10~20ë¶„)
```bash
python inference_lstm_v5_5fold.py
```
â†’ `submission_lstm_v5_5fold_tta.csv` ìƒì„±

---

## ğŸ¯ ì˜ˆìƒ ì„±ëŠ¥

### ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„

#### ğŸ‰ ë‚™ê´€ì  (ëª¨ë“  ê°œì„ ì‚¬í•­ì´ íš¨ê³¼ì )
- **Val Loss**: 12.5m ~ 13.0m
- **Public LB**: 13.0m ~ 13.5m
- **ê²°ê³¼**: âœ… **LightGBM ì´ˆê³¼ ì„±ê³µ!**

#### âœ… í˜„ì‹¤ì  (ëŒ€ë¶€ë¶„ ê°œì„ ì‚¬í•­ íš¨ê³¼ì )
- **Val Loss**: 13.5m ~ 14.0m
- **Public LB**: 14.0m ~ 14.5m
- **ê²°ê³¼**: âœ… LightGBM ê·¼ì ‘ ë˜ëŠ” ë™ë“±

#### ğŸ“ˆ ë³´ìˆ˜ì  (ì¼ë¶€ ê°œì„ ì‚¬í•­ë§Œ íš¨ê³¼ì )
- **Val Loss**: 14.0m ~ 14.5m
- **Public LB**: 14.5m ~ 15.0m
- **ê²°ê³¼**: ğŸ“Š ì¶”ê°€ íŠœë‹ í•„ìš”

---

## ğŸ› ï¸ ë‹¤ìŒ ë‹¨ê³„ (ì„±ëŠ¥ ë¯¸ë‹¬ ì‹œ)

### 1ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬íŠœë‹
- Learning Rate, Dropout, Hidden Dim ì¡°ì •
- ë” ê¸´ í•™ìŠµ (Epoch ì¦ê°€)

### 2ë‹¨ê³„: Data Augmentation
- ì‹œí€€ìŠ¤ ì—­ìˆœ
- ì¢Œìš° ëŒ€ì¹­
- Gaussian Noise
- Mixup

### 3ë‹¨ê³„: ê³ ê¸‰ ëª¨ë¸ ì‹œë„
- **Transformer** (Self-Attention only)
- **TCN** (Temporal Convolutional Network)
- **CNN-LSTM Hybrid**

### 4ë‹¨ê³„: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
- ì¶”ê°€ ì‹œí€€ìŠ¤ í”¼ì²˜ (ëˆ„ì  ê±°ë¦¬, ë°©í–¥ ì „í™˜ ë“±)
- ê²Œì„ ìƒí™© ì»¨í…ìŠ¤íŠ¸ (ì ìˆ˜, ì‹œê°„ëŒ€ ë“±)

---

## ğŸ“š ì£¼ìš” ë¬¸ì„œ

### 1. `LSTM_PERFORMANCE_IMPROVEMENT_STRATEGY.md`
- ë¬¸ì œ ì›ì¸ ë¶„ì„
- ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ ì „ëµ
- ì‹¤í—˜ ìš°ì„ ìˆœìœ„
- ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  ê²½ë¡œ

### 2. `LSTM_V5_EXECUTION_GUIDE.md`
- ì‹¤í–‰ ìˆœì„œ ìƒì„¸ ê°€ì´ë“œ
- ë¬¸ì œ í•´ê²° (ë©”ëª¨ë¦¬ ë¶€ì¡±, ìˆ˜ë ´ ì‹¤íŒ¨ ë“±)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ
- ì²´í¬ë¦¬ìŠ¤íŠ¸

### 3. `PROJECT_FINAL_SUMMARY.md` (ì´ ë¬¸ì„œ)
- í”„ë¡œì íŠ¸ ì „ì²´ ê°œìš”
- ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
- íŒŒì¼ êµ¬ì¡°
- í•µì‹¬ ê°œì„ ì‚¬í•­

---

## ğŸ” ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### ë°ì´í„° íë¦„

```
CSV (Wide Format)
    â†“
SoccerDatasetV5
    â†“ Reshape + Normalize
3D Tensor (Batch, 20, Features)
    â†“
Embedding (Categorical)
    â†“
Input Projection (Linear)
    â†“
Bidirectional RNN
    â†“
Multi-Head Attention (with Padding Mask)
    â†“
Residual + LayerNorm
    â†“
Deep Output Head (3-Layer MLP)
    â†“
(target_x, target_y)
```

### ì†ì‹¤ í•¨ìˆ˜

```python
class EuclideanDistanceLoss(nn.Module):
    def forward(self, pred, target):
        # ì •ê·œí™”ëœ ì¢Œí‘œ â†’ ì‹¤ì œ ì¢Œí‘œ
        pred_real = pred * [105, 68]
        target_real = target * [105, 68]
        
        # ìœ í´ë¦¬ë“œ ê±°ë¦¬
        distances = âˆš(Î£(pred - target)Â²)
        return mean(distances)
```

### í•™ìŠµ ì•ˆì •í™” ê¸°ë²•
- **Gradient Clipping**: `max_norm=1.0`
- **Weight Decay**: `1e-3`
- **LayerNorm**: ê° ë ˆì´ì–´ ì¶œë ¥ ì •ê·œí™”
- **CosineAnnealingWarmRestarts**: ì£¼ê¸°ì  LR ì¡°ì •
- **Early Stopping**: Patience=20

---

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

### í‰ê°€ ì§€í‘œ
- **Primary**: ìœ í´ë¦¬ë“œ ê±°ë¦¬ (ë¯¸í„°)
- **Formula**: `âˆš((pred_x - true_x)Â² + (pred_y - true_y)Â²)`

### ëª©í‘œ
- **ìµœì†Œ ëª©í‘œ**: LightGBM (14.138m)ì™€ ë™ë“±
- **ì´ìƒì  ëª©í‘œ**: 13.0m ì´í•˜ (ì•½ 8% ê°œì„ )
- **ë„ì „ì  ëª©í‘œ**: 12.5m ì´í•˜ (ì•½ 12% ê°œì„ )

---

## ğŸ“ í•™ìŠµëœ êµí›ˆ

### 1. ë”¥ëŸ¬ë‹ vs íŠ¸ë¦¬ ëª¨ë¸
- **íŠ¸ë¦¬ ëª¨ë¸ ê°•ì **: ë¹ ë¥¸ í•™ìŠµ, ì•ˆì •ì  ì„±ëŠ¥
- **ë”¥ëŸ¬ë‹ ê°•ì **: ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµ, í™•ì¥ì„±
- **ê²°ë¡ **: ì‹œí€€ìŠ¤ ë°ì´í„°ì—ì„œëŠ” ë”¥ëŸ¬ë‹ì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŒ

### 2. Attention ë©”ì»¤ë‹ˆì¦˜ì˜ ì¤‘ìš”ì„±
- ë‹¨ìˆœ RNNë³´ë‹¤ Attentionì´ ì¤‘ìš”í•œ ì‹œì ì„ í•™ìŠµ
- Multi-Headë¡œ ë‹¤ì–‘í•œ íŒ¨í„´ í¬ì°©

### 3. ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±
- Padding Maskë¡œ ì‹¤ì œ ë°ì´í„° êµ¬ë¶„
- ì „ì²´ í”¼ì²˜ ì •ê·œí™”ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ

### 4. 5-Fold CV + TTAì˜ íš¨ê³¼
- ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- TTAë¡œ ì˜ˆì¸¡ ì•ˆì •ì„± ì¦ê°€

---

## ğŸ”® í–¥í›„ ë°œì „ ë°©í–¥

### ë‹¨ê¸° (1ì£¼ì¼)
1. V5 ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŒŒì¸íŠœë‹
3. Data Augmentation ì‹¤í—˜

### ì¤‘ê¸° (1ê°œì›”)
1. Transformer ëª¨ë¸ ì‹œë„
2. Hybrid ëª¨ë¸ (CNN + RNN) ì‹¤í—˜
3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³ ë„í™”

### ì¥ê¸° (2ê°œì›”+)
1. Graph Neural Network (ì„ ìˆ˜ ê°„ ê´€ê³„)
2. ê°•í™”í•™ìŠµ ê¸°ë°˜ íŒ¨ìŠ¤ ì „ëµ í•™ìŠµ
3. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“ ë¬¸ì˜ ë° ê¸°ì—¬

### ë¬¸ì œ ë³´ê³ 
- ì—ëŸ¬ ë°œìƒ ì‹œ: ì—ëŸ¬ ë©”ì‹œì§€ + í™˜ê²½ ì •ë³´ + ì‹¤í–‰ ë¡œê·¸
- ì„±ëŠ¥ ë¬¸ì œ: Val Loss + Hyperparameters + í•™ìŠµ ê³¡ì„ 

### ê¸°ì—¬ ë°©ë²•
1. ìƒˆë¡œìš´ í”¼ì²˜ ì¶”ê°€
2. ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ 
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
4. ë¬¸ì„œ ê°œì„ 

---

## ğŸ“… íƒ€ì„ë¼ì¸

- **2025-12-18**: LSTM V4 Baseline êµ¬í˜„ (15.649m)
- **2025-12-19**: LSTM V5 Attention ëª¨ë¸ ì„¤ê³„ ë° ì½”ë“œ ì‘ì„±
- **2025-12-19 (ì˜ˆì •)**: V5 ë‹¨ì¼ Fold í•™ìŠµ
- **2025-12-19~20 (ì˜ˆì •)**: V5 5-Fold ì „ì²´ í•™ìŠµ
- **2025-12-20 (ì˜ˆì •)**: ìµœì¢… ì œì¶œ ë° ì„±ëŠ¥ í‰ê°€

---

## ğŸ† ëª©í‘œ ë‹¬ì„± ê¸°ì¤€

### âœ… ìµœì†Œ ëª©í‘œ
- [ ] LSTM V5 Val Loss < 14.5m
- [ ] Public LB < 15.0m

### âœ… í•µì‹¬ ëª©í‘œ
- [ ] LSTM V5 Val Loss < 14.0m
- [ ] Public LB < 14.5m
- [ ] LightGBM ê·¼ì ‘ ë˜ëŠ” ë™ë“±

### ğŸ‰ ì´ìƒì  ëª©í‘œ
- [ ] LSTM V5 Val Loss < 13.0m
- [ ] Public LB < 13.5m
- [ ] **LightGBM ì´ˆê³¼ ì„±ê³µ!**

---

**í”„ë¡œì íŠ¸ ìƒíƒœ**: ğŸš€ **ì§„í–‰ ì¤‘ (V5 í•™ìŠµ ëŒ€ê¸°)**  
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-12-19  
**ë‹¤ìŒ ë‹¨ê³„**: `train_lstm_v5_attention.py` ì‹¤í–‰ (Colab/GPU)

---

## ğŸ¯ í•µì‹¬ ë©”ì‹œì§€

> **"ìˆœìˆ˜ LSTM ëª¨ë¸ì˜ êµ¬ì¡°ì  ê°œì„ ë§Œìœ¼ë¡œ LightGBM ì„±ëŠ¥ì„ ì´ˆê³¼í•  ìˆ˜ ìˆë‹¤"**

ì´ë¥¼ ìœ„í•´:
1. âœ… **Attention ë©”ì»¤ë‹ˆì¦˜** - ì¤‘ìš” ì‹œì  í•™ìŠµ
2. âœ… **Padding Mask** - ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
3. âœ… **Bidirectional RNN** - ì–‘ë°©í–¥ ì •ë³´ í™œìš©
4. âœ… **5-Fold + TTA** - ì¼ë°˜í™” ì„±ëŠ¥ ê·¹ëŒ€í™”

**ì§€ê¸ˆ ë°”ë¡œ `train_lstm_v5_attention.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ìƒˆë¡œìš´ ì„±ëŠ¥ì„ í™•ì¸í•˜ì„¸ìš”!** ğŸš€

