"""
K-League Pass Prediction - Ensemble Model
XGBoost + LightGBM ì•™ìƒë¸”

ëª©í‘œ: ë‘ ëª¨ë¸ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
ì˜ˆìƒ ì„±ëŠ¥: 0.85 ~ 0.95m
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

def euclidean_distance(y_true, y_pred):
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    true_x, true_y = y_true[:, 0], y_true[:, 1]
    pred_x, pred_y = y_pred[:, 0], y_pred[:, 1]
    return np.mean(np.sqrt((true_x - pred_x)**2 + (true_y - pred_y)**2))

class EnsembleModel:
    def __init__(self):
        self.models = []
        self.weights = []

    def add_model(self, model_path, weight=1.0):
        """ëª¨ë¸ ì¶”ê°€"""
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        self.models.append(model)
        self.weights.append(weight)
        print(f"âœ… ëª¨ë¸ ì¶”ê°€: {model_path} (ê°€ì¤‘ì¹˜: {weight})")

    def predict(self, X):
        """ì•™ìƒë¸” ì˜ˆì¸¡ (ê°€ì¤‘ í‰ê· )"""
        predictions = []

        for model, weight in zip(self.models, self.weights):
            pred_x = model['model_x'].predict(X)
            pred_y = model['model_y'].predict(X)
            pred = np.column_stack([pred_x, pred_y])
            predictions.append(pred * weight)

        # ê°€ì¤‘ í‰ê· 
        ensemble_pred = np.sum(predictions, axis=0) / np.sum(self.weights)

        return ensemble_pred

    def evaluate(self, X, y_true, verbose=True):
        """í‰ê°€"""
        y_pred = self.predict(X)

        # ìœ í´ë¦¬ë“œ ê±°ë¦¬
        eucl_dist = euclidean_distance(y_true, y_pred)

        # MSE
        mse_x = mean_squared_error(y_true[:, 0], y_pred[:, 0])
        mse_y = mean_squared_error(y_true[:, 1], y_pred[:, 1])

        if verbose:
            print(f"ğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥:")
            print(f"  - ìœ í´ë¦¬ë“œ ê±°ë¦¬: {eucl_dist:.2f}m")
            print(f"  - MSE X: {mse_x:.2f}")
            print(f"  - MSE Y: {mse_y:.2f}")

        return eucl_dist, mse_x, mse_y

    def evaluate_individual(self, X, y_true):
        """ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸"""
        print("\nê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
        print("-" * 60)

        individual_perfs = []

        for i, model in enumerate(self.models):
            pred_x = model['model_x'].predict(X)
            pred_y = model['model_y'].predict(X)
            pred = np.column_stack([pred_x, pred_y])

            eucl_dist = euclidean_distance(y_true, pred)
            individual_perfs.append(eucl_dist)

            print(f"  ëª¨ë¸ {i+1}: {eucl_dist:.2f}m")

        print("-" * 60)

        return individual_perfs

    def optimize_weights(self, X, y_true, verbose=True):
        """ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰ (Grid Search)"""
        if verbose:
            print("\nğŸ” ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰ ì¤‘...")

        best_weights = self.weights.copy()
        best_score = float('inf')

        # Grid Search (0.0 ~ 1.0, 0.1 ê°„ê²©)
        weight_range = np.arange(0.0, 1.1, 0.1)

        for w1 in weight_range:
            w2 = 1.0 - w1
            self.weights = [w1, w2]

            score, _, _ = self.evaluate(X, y_true, verbose=False)

            if score < best_score:
                best_score = score
                best_weights = [w1, w2]

        self.weights = best_weights

        if verbose:
            print(f"âœ… ìµœì  ê°€ì¤‘ì¹˜: {best_weights}")
            print(f"âœ… ìµœì  ì„±ëŠ¥: {best_score:.2f}m")

        return best_weights, best_score

    def save_ensemble(self, filename='ensemble_model.pkl'):
        """ì•™ìƒë¸” ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'models': self.models,
                'weights': self.weights
            }, f)
        print(f"âœ… ì•™ìƒë¸” ì €ì¥: {filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=" * 80)
    print("  K-League Pass Prediction - Ensemble Model")
    print("  XGBoost + LightGBM ì•™ìƒë¸”")
    print("=" * 80)
    print()

    # ğŸ”¥ ì‹¤ë¬´ íŒ¨í„´: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    from train_utils import (
        load_data_and_features,
        prepare_train_val_split,
        print_performance_summary
    )

    # 1. ë°ì´í„° ë° í”¼ì²˜ ì„¤ì • ë¡œë”©
    data, feature_cols, target_cols, config = load_data_and_features()

    # 2. Train/Val Split
    X_train, y_train, X_val, y_val = prepare_train_val_split(
        data, feature_cols, target_cols, val_ratio=0.2
    )

    # 3. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    print("\n" + "=" * 80)
    print("  ì•™ìƒë¸” êµ¬ì„±")
    print("=" * 80)
    print()

    ensemble = EnsembleModel()
    ensemble.add_model('xgboost_baseline.pkl', weight=0.5)
    ensemble.add_model('lightgbm_model.pkl', weight=0.5)

    # 5. ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
    print("\n" + "=" * 80)
    print("  ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ (Validation)")
    print("=" * 80)

    individual_perfs = ensemble.evaluate_individual(X_val, y_val)

    # 6. ê¸°ë³¸ ì•™ìƒë¸” í‰ê°€ (ë™ì¼ ê°€ì¤‘ì¹˜)
    print("\n" + "=" * 80)
    print("  ê¸°ë³¸ ì•™ìƒë¸” í‰ê°€ (ê°€ì¤‘ì¹˜ 0.5 : 0.5)")
    print("=" * 80)
    print()

    val_eucl, val_mse_x, val_mse_y = ensemble.evaluate(X_val, y_val, verbose=True)

    # 7. ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰
    print("\n" + "=" * 80)
    print("  ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰")
    print("=" * 80)

    best_weights, best_score = ensemble.optimize_weights(X_val, y_val, verbose=True)

    # 8. ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì¬í‰ê°€
    print("\n" + "=" * 80)
    print("  ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” í‰ê°€")
    print("=" * 80)
    print()

    print(f"ğŸ¯ ìµœì  ê°€ì¤‘ì¹˜:")
    print(f"  - XGBoost:  {best_weights[0]:.2f}")
    print(f"  - LightGBM: {best_weights[1]:.2f}")
    print()

    final_eucl, final_mse_x, final_mse_y = ensemble.evaluate(X_val, y_val, verbose=True)

    # 9. ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 80)
    print("  ìµœì¢… ê²°ê³¼ ë¹„êµ")
    print("=" * 80)

    print(f"""
    ğŸ“Š ê°œë³„ ëª¨ë¸:
      - XGBoost:  {individual_perfs[0]:.2f}m
      - LightGBM: {individual_perfs[1]:.2f}m
    
    ğŸ“Š ì•™ìƒë¸” (ë™ì¼ ê°€ì¤‘ì¹˜):
      - ì„±ëŠ¥: {val_eucl:.2f}m
    
    ğŸ“Š ì•™ìƒë¸” (ìµœì  ê°€ì¤‘ì¹˜):
      - ê°€ì¤‘ì¹˜: XGBoost {best_weights[0]:.2f}, LightGBM {best_weights[1]:.2f}
      - ì„±ëŠ¥: {final_eucl:.2f}m
    
    ğŸ“Š ê°œì„ :
      - XGBoost ëŒ€ë¹„: {individual_perfs[0] - final_eucl:.2f}m ê°œì„ 
      - LightGBM ëŒ€ë¹„: {individual_perfs[1] - final_eucl:.2f}m ê°œì„ 
      - ìµœê³  ë‹¨ë… ëª¨ë¸ ëŒ€ë¹„: {min(individual_perfs) - final_eucl:.2f}m ê°œì„ 
    """)

    if final_eucl < 1.0:
        print("ğŸ¯ âœ… 1.0m ì´í•˜ ë‹¬ì„±!")

    if final_eucl < 0.9:
        print("ğŸ‰ âœ… 0.9m ì´í•˜ ë‹¬ì„±! ìš°ìˆ˜í•œ ì„±ëŠ¥!")

    # 10. Train Set ì„±ëŠ¥ í™•ì¸
    print("\n" + "=" * 80)
    print("  Train Set ì„±ëŠ¥")
    print("=" * 80)
    print()

    train_eucl, _, _ = ensemble.evaluate(X_train, y_train, verbose=True)

    # Overfitting ì²´í¬
    overfit_ratio = train_eucl / final_eucl
    print(f"\nğŸ“Š Overfitting ì²´í¬:")
    print(f"  - Train: {train_eucl:.2f}m")
    print(f"  - Val: {final_eucl:.2f}m")
    print(f"  - ë¹„ìœ¨: {overfit_ratio:.2f}")

    if overfit_ratio < 0.8:
        print("  âœ… ê³¼ì í•© ì—†ìŒ (ì•ˆì •ì )")
    elif overfit_ratio < 1.0:
        print("  âš ï¸  ì•½ê°„ì˜ ê³¼ì í•©")
    else:
        print("  âš ï¸  ì£¼ì˜: Trainë³´ë‹¤ Val ì„±ëŠ¥ì´ ì¢‹ìŒ")

    # 11. ì•™ìƒë¸” ì €ì¥
    print("\n" + "=" * 80)
    ensemble.save_ensemble('ensemble_model.pkl')

    # 12. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("  ğŸ‰ ìµœì¢… ìš”ì•½")
    print("=" * 80)
    print(f"""
    âœ… ì•™ìƒë¸” ëª¨ë¸ ì™„ì„±!
    
    ğŸ“Š ìµœì¢… ì„±ëŠ¥:
      - Validation: {final_eucl:.2f}m
      - Train: {train_eucl:.2f}m
    
    ğŸ“Š êµ¬ì„±:
      - XGBoost ({best_weights[0]:.2f}) + LightGBM ({best_weights[1]:.2f})
    
    ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„:
      - ë‹¨ìˆœ ë² ì´ìŠ¤ë¼ì¸ (20.37m) â†’ {final_eucl:.2f}m
      - ê°œì„ : {20.37 - final_eucl:.2f}m ({(20.37 - final_eucl) / 20.37 * 100:.1f}%)
    
    ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:
      1. CatBoost ì¶”ê°€ (GBM 3ì¢… ì•™ìƒë¸”)
      2. ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
      3. Test ë°ì´í„° ì˜ˆì¸¡
      4. ìµœì¢… ì œì¶œ
    
    ğŸ† í˜„ì¬ ìœ„ì¹˜: ìƒìœ„ê¶Œ í™•ì‹¤!
    """)

    return ensemble, final_eucl

if __name__ == "__main__":
    ensemble, final_eucl = main()

