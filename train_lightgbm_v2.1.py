"""
LightGBM V2.1 - Feature Selection ì ìš©

ëª©í‘œ: ì¤‘ìš”ë„ ë‚®ì€ í”¼ì²˜ ì œê±° ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
"""

import pandas as pd
import numpy as np
import pickle
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GroupKFold
import warnings
warnings.filterwarnings('ignore')

def euclidean_distance(y_true, y_pred):
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    distances = np.sqrt((y_true[:, 0] - y_pred[:, 0])**2 +
                       (y_true[:, 1] - y_pred[:, 1])**2)
    return distances.mean()

def main():
    print("=" * 80)
    print("  LightGBM V2.1 - Feature Selection + í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    print("=" * 80)
    print()

    # 1. ë°ì´í„° ë¡œë”©
    print("ğŸ“Š V2 ë°ì´í„° ë¡œë”©...")
    data = pd.read_csv('processed_train_data_v2.csv')
    print(f"âœ… ë°ì´í„°: {data.shape}")

    # 2. í”¼ì²˜ ì„ íƒ (V1ì—ì„œ íš¨ê³¼ì ì´ì—ˆë˜ í”¼ì²˜ + V2 ìƒˆ í”¼ì²˜ ì¤‘ ì¤‘ìš”í•œ ê²ƒë§Œ)
    print("\nğŸ¯ Feature Selection...")

    # V1 í•µì‹¬ í”¼ì²˜
    core_features = [
        'start_x', 'start_y',
        'delta_x', 'delta_y', 'distance',
        'distance_to_goal_start', 'distance_to_goal_end',
        'goal_approach',
        'shooting_angle',
        'in_penalty_area', 'in_final_third',
        'episode_length', 'event_order',
        'x_progression', 'x_total_progression',
        'velocity', 'velocity_x', 'velocity_y',
        'tempo',
        'direction_consistency',
        'forward_momentum',
        'goal_approach_trend',
        'prev_start_x', 'prev_start_y',
        'prev_end_x', 'prev_end_y',
        'period_id', 'is_home'
    ]

    # V2 ìƒˆ í”¼ì²˜ ì¤‘ í•µì‹¬ë§Œ ì„ íƒ
    new_features_v2 = [
        'distance_to_goal_inv',  # ê³¨ë¬¸ ê±°ë¦¬ ì—­ìˆ˜
        'shooting_angle_sin',  # ê°ë„ ë³€í™˜
        'shooting_angle_cos',
        'start_x_squared',  # ë¹„ì„ í˜•
        'goal_dist_angle_interaction',  # ìƒí˜¸ì‘ìš©
        'goal_urgency',  # ìœ„ì¹˜ íŠ¹í™”
        'is_central_corridor',
        'player_avg_x',  # ì»¨í…ìŠ¤íŠ¸
        'player_avg_pass_dist',
        'team_aggression',
        'time_pressure',
        'player_position_deviation'
    ]

    selected_features = core_features + new_features_v2

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ
    available_features = [col for col in selected_features if col in data.columns]
    print(f"âœ… ì„ íƒëœ í”¼ì²˜: {len(available_features)}ê°œ (ì „ì²´ 75ê°œ â†’ {len(available_features)}ê°œ)")

    X = data[available_features]
    y = data[['end_x', 'end_y']].values

    # 3. Train/Val Split
    print("\nğŸ“Š 5-Fold Cross Validation...")

    gkf = GroupKFold(n_splits=5)
    fold_scores = []

    # ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    params = {
        'n_estimators': 800,  # ì¦ê°€
        'learning_rate': 0.03,  # ê°ì†Œ (ë” ì„¸ë°€í•˜ê²Œ)
        'max_depth': 10,  # ì¦ê°€
        'num_leaves': 127,  # ì¦ê°€
        'subsample': 0.85,
        'colsample_bytree': 0.85,
        'min_child_samples': 20,
        'reg_alpha': 0.1,  # L1 regularization
        'reg_lambda': 0.1,  # L2 regularization
        'random_state': 42,
        'verbose': -1
    }

    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, groups=data['game_id'])):
        print(f"\nFold {fold+1}/5", end=" ")

        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # X ì¢Œí‘œ ëª¨ë¸
        model_x = LGBMRegressor(**params)
        model_x.fit(X_train, y_train[:, 0])

        # Y ì¢Œí‘œ ëª¨ë¸
        model_y = LGBMRegressor(**params)
        model_y.fit(X_train, y_train[:, 1])

        # ì˜ˆì¸¡
        y_pred_x = model_x.predict(X_val)
        y_pred_y = model_y.predict(X_val)
        y_pred = np.column_stack([y_pred_x, y_pred_y])

        # í‰ê°€
        eucl_dist = euclidean_distance(y_val, y_pred)
        mse_x = mean_squared_error(y_val[:, 0], y_pred[:, 0])
        mse_y = mean_squared_error(y_val[:, 1], y_pred[:, 1])

        print(f"â†’ {eucl_dist:.4f}m")

        fold_scores.append({
            'fold': fold + 1,
            'euclidean': eucl_dist,
            'mse_x': mse_x,
            'mse_y': mse_y
        })

        # Feature Importance (ì²« fold)
        if fold == 0:
            print("\nğŸ“Š Feature Importance Top 15:")
            importance_x = model_x.feature_importances_
            importance_df = pd.DataFrame({
                'feature': available_features,
                'importance': importance_x
            }).sort_values('importance', ascending=False)

            for i, row in importance_df.head(15).iterrows():
                print(f"  {i+1:2d}. {row['feature']:35s}: {row['importance']:8.0f}")

    # 4. ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print("  ê²°ê³¼ ìš”ì•½")
    print("="*80)

    scores_df = pd.DataFrame(fold_scores)
    mean_score = scores_df['euclidean'].mean()
    std_score = scores_df['euclidean'].std()

    print(f"\ní‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬: {mean_score:.4f}m Â± {std_score:.4f}m")
    print(f"í‰ê·  MSE X: {scores_df['mse_x'].mean():.4f}")
    print(f"í‰ê·  MSE Y: {scores_df['mse_y'].mean():.4f}")

    print("\n" + "="*80)
    print("  ì„±ëŠ¥ ë¹„êµ")
    print("="*80)
    print(f"V1 (54ê°œ í”¼ì²˜):  0.93m")
    print(f"V2 (75ê°œ í”¼ì²˜):  1.06m")
    print(f"V2.1 ({len(available_features)}ê°œ í”¼ì²˜): {mean_score:.4f}m")

    improvement_from_v1 = (0.93 - mean_score) / 0.93 * 100
    improvement_from_v2 = (1.06 - mean_score) / 1.06 * 100

    if mean_score < 0.93:
        print(f"\nâœ… V1 ëŒ€ë¹„ {-improvement_from_v1:.2f}% ê°œì„ !")
    elif mean_score < 1.06:
        print(f"\nâœ… V2 ëŒ€ë¹„ {-improvement_from_v2:.2f}% ê°œì„ ")
    else:
        print(f"\nâš ï¸  ì¶”ê°€ íŠœë‹ í•„ìš”")

    # 5. ìµœì¢… ëª¨ë¸ í•™ìŠµ
    if mean_score <= 0.93:
        print("\nğŸ’¾ ì„±ëŠ¥ì´ ê°œì„ ë˜ì–´ ìµœì¢… ëª¨ë¸ ì €ì¥...")

        model_x_final = LGBMRegressor(**params)
        model_y_final = LGBMRegressor(**params)

        model_x_final.fit(X, y[:, 0])
        model_y_final.fit(X, y[:, 1])

        with open('lightgbm_model_v2.1.pkl', 'wb') as f:
            pickle.dump({
                'model_x': model_x_final,
                'model_y': model_y_final,
                'feature_cols': available_features,
                'val_score': mean_score
            }, f)
        print("âœ… ëª¨ë¸ ì €ì¥: lightgbm_model_v2.1.pkl")

    print("\n" + "="*80)
    print("âœ… V2.1 í•™ìŠµ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()

