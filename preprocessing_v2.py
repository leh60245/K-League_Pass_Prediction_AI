"""
K-League Pass Prediction - Data Preprocessing Pipeline V2

ê°œì„  ì‚¬í•­ (2025-12-16):
1. ë‹¤ì¤‘ê³µì„ ì„± í”¼ì²˜ ì œê±° (6ê°œ)
2. ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ ì¶”ê°€ (8ê°œ)
3. ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ ì¶”ê°€ (6ê°œ)
4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ê°œì„ 
5. ì„ ìˆ˜/íŒ€ ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ ì¶”ê°€ (4ê°œ)

ëª©í‘œ: EDA Phase 4 ì¸ì‚¬ì´íŠ¸ ë°˜ì˜í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ
"""

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import GroupKFold
from scipy.spatial.distance import cdist
import pickle
import warnings
warnings.filterwarnings('ignore')

class DataPreprocessorV2:
    def __init__(self, data_dir='./data'):
        self.data_dir = data_dir
        self.scaler_x = StandardScaler()
        self.scaler_y = StandardScaler()
        self.type_encoder = LabelEncoder()
        self.result_encoder = LabelEncoder()

        # ì„ ìˆ˜/íŒ€ í†µê³„ ì €ì¥
        self.player_stats = None
        self.team_stats = None

    def load_data(self, verbose=True):
        """ë°ì´í„° ë¡œë”©"""
        if verbose:
            print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")

        # Train ë°ì´í„°
        train_path = os.path.join(self.data_dir, 'train.csv')
        train_data = pd.read_csv(train_path)

        # Match info
        match_info_path = os.path.join(self.data_dir, 'match_info.csv')
        match_info = pd.read_csv(match_info_path)

        if verbose:
            print(f"âœ… Train: {len(train_data):,} ì´ë²¤íŠ¸, {train_data['game_episode'].nunique():,} ì—í”¼ì†Œë“œ")
            print(f"âœ… Match Info: {len(match_info)} ê²½ê¸°\n")

        return train_data, match_info

    def sort_by_time(self, data, verbose=True):
        """ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬"""
        if verbose:
            print("â° ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬ ì¤‘...")

        data = data.sort_values(['game_episode', 'time_seconds']).reset_index(drop=True)

        if verbose:
            print("âœ… ì •ë ¬ ì™„ë£Œ\n")

        return data

    def create_basic_features(self, data, verbose=True):
        """ê¸°ë³¸ í”¼ì²˜ ìƒì„±"""
        if verbose:
            print("ğŸ”§ ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ì´ë™ ê±°ë¦¬/ë°©í–¥
        data['delta_x'] = data['end_x'] - data['start_x']
        data['delta_y'] = data['end_y'] - data['start_y']
        data['distance'] = np.sqrt(data['delta_x']**2 + data['delta_y']**2)

        # 2. ê³¨ë¬¸ ê±°ë¦¬ (ì˜¤ë¥¸ìª½ ê³¨ë¬¸ ê¸°ì¤€: 105, 34)
        goal_x, goal_y = 105, 34
        data['distance_to_goal_start'] = np.sqrt(
            (data['start_x'] - goal_x)**2 +
            (data['start_y'] - goal_y)**2
        )
        data['distance_to_goal_end'] = np.sqrt(
            (data['end_x'] - goal_x)**2 +
            (data['end_y'] - goal_y)**2
        )

        # 2-1. ê³¨ë¬¸ ì§„í–‰ë„ (ê³¨ë¬¸ìœ¼ë¡œ ê°€ê¹Œì›Œì§€ëŠ” ì •ë„)
        data['goal_approach'] = data['distance_to_goal_start'] - data['distance_to_goal_end']

        # 3. ê²½ê¸°ì¥ ì˜ì—­ (3ë“±ë¶„) - start_x_zone_fineì€ ì œê±° (ë‹¤ì¤‘ê³µì„ ì„±)
        data['start_x_zone'] = pd.cut(data['start_x'], bins=[0, 35, 70, 105], labels=[0, 1, 2])
        data['start_y_zone'] = pd.cut(data['start_y'], bins=[0, 22.67, 45.33, 68], labels=[0, 1, 2])

        # 3-2. ìœ„í—˜ ì§€ì—­ í”Œë˜ê·¸ (í˜ë„í‹° ë°•ìŠ¤: x > 87.5, 22.9 < y < 45.1)
        data['in_penalty_area'] = ((data['start_x'] > 87.5) &
                                   (data['start_y'] > 22.9) &
                                   (data['start_y'] < 45.1)).astype(int)

        # 3-3. ìµœì¢… 1/3 ì§€ì—­ (Final Third)
        data['in_final_third'] = (data['start_x'] > 70).astype(int)

        # 4. ì—í”¼ì†Œë“œ ë‚´ ìˆœì„œ
        data['event_order'] = data.groupby('game_episode').cumcount()

        # 4-1. ì—í”¼ì†Œë“œ ì²« ì´ë²¤íŠ¸ í”Œë˜ê·¸ (ê²°ì¸¡ì¹˜ ì²˜ë¦¬ìš©)
        data['is_first_event'] = (data['event_order'] == 0).astype(int)

        # 5. ê³¨ ê°ë„ (Shooting Angle)
        post_left_y = 30.34
        post_right_y = 37.66

        vec_left_x = goal_x - data['start_x']
        vec_left_y = post_left_y - data['start_y']
        vec_right_x = goal_x - data['start_x']
        vec_right_y = post_right_y - data['start_y']

        dot_product = vec_left_x * vec_right_x + vec_left_y * vec_right_y
        cross_product = vec_left_x * vec_right_y - vec_left_y * vec_right_x

        data['shooting_angle'] = np.abs(np.arctan2(cross_product, dot_product))

        # 6. ì •ê·œí™”ëœ ì¢Œí‘œëŠ” ì œê±° (ë‹¤ì¤‘ê³µì„ ì„±) - ì›ë³¸ë§Œ ì‚¬ìš©

        if verbose:
            print(f"âœ… ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_nonlinear_features(self, data, verbose=True):
        """ğŸ”¥ NEW: ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ ìƒì„± (EDA Phase 4 ì¸ì‚¬ì´íŠ¸)"""
        if verbose:
            print("ğŸ”¥ ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ê³¨ë¬¸ ê±°ë¦¬ ì—­ìˆ˜ (ê°€ê¹Œìš¸ìˆ˜ë¡ í° ê°€ì¤‘ì¹˜)
        data['distance_to_goal_inv'] = 1 / (data['distance_to_goal_start'] + 1)

        # 2. ê³¨ë¬¸ ê±°ë¦¬ ì œê³±ê·¼ (ë¹„ì„ í˜• íŒ¨í„´ í¬ì°©)
        data['distance_to_goal_sqrt'] = np.sqrt(data['distance_to_goal_start'])

        # 3. ê°ë„ì˜ ì‚¼ê°í•¨ìˆ˜ (ì£¼ê¸°ì„± í¬ì°©)
        data['shooting_angle_sin'] = np.sin(data['shooting_angle'])
        data['shooting_angle_cos'] = np.cos(data['shooting_angle'])

        # 4. ìœ„ì¹˜ì˜ ì œê³± (ë¹„ì„ í˜• ê´€ê³„)
        data['start_x_squared'] = data['start_x'] ** 2
        data['start_y_squared'] = data['start_y'] ** 2

        # 5. ìƒí˜¸ì‘ìš© í”¼ì²˜
        data['x_y_interaction'] = data['start_x'] * data['start_y']
        data['goal_dist_angle_interaction'] = data['distance_to_goal_start'] * data['shooting_angle']

        if verbose:
            print(f"âœ… ë¹„ì„ í˜• í”¼ì²˜ 8ê°œ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_position_specific_features(self, data, verbose=True):
        """ğŸ¯ NEW: ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ (EDA Phase 4 ì¸ì‚¬ì´íŠ¸)"""
        if verbose:
            print("ğŸ¯ ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ìˆ˜ë¹„ì§„ íŠ¹í™” (ë¶ˆí™•ì‹¤ì„± ë†’ì€ êµ¬ê°„)
        data['is_defensive_third'] = (data['start_x'] < 35).astype(int)

        # 2. ê³µê²©ì§„ íŠ¹í™” - ê³¨ ê¸´ê¸‰ë„ (exponential decay)
        data['goal_urgency'] = np.exp(-data['distance_to_goal_start'] / 20)

        # 3. Yì¶• ì¤‘ì•™ ë³µë„ (ì˜ˆì¸¡ ì–´ë ¤ìš´ êµ¬ê°„)
        data['is_central_corridor'] = ((data['start_y'] > 20) &
                                       (data['start_y'] < 48)).astype(int)

        # 4. ê³¨ë¬¸ ê·¼ì ‘ë„ (í˜ë„í‹° ë°•ìŠ¤ ê·¼ì²˜)
        data['near_goal_zone'] = ((data['distance_to_goal_start'] < 25) &
                                  (data['start_x'] > 80)).astype(int)

        # 5. ì‚¬ì´ë“œ ê³µê²© ì—¬ë¶€
        data['is_wing_attack'] = ((data['start_x'] > 70) &
                                  ((data['start_y'] < 15) | (data['start_y'] > 53))).astype(int)

        # 6. ì¤‘ì› ì§€ë°° ì˜ì—­
        data['is_midfield_control'] = ((data['start_x'] >= 35) &
                                       (data['start_x'] <= 70) &
                                       (data['start_y'] >= 20) &
                                       (data['start_y'] <= 48)).astype(int)

        if verbose:
            print(f"âœ… ìœ„ì¹˜ íŠ¹í™” í”¼ì²˜ 6ê°œ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_sequence_features(self, data, verbose=True):
        """ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± (ê° ì—í”¼ì†Œë“œë³„)"""
        if verbose:
            print("ğŸ”„ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± ì¤‘...")

        episode_features = []

        for episode_id, group in data.groupby('game_episode'):
            group = group.copy()

            # 1. ì—í”¼ì†Œë“œ ê¸¸ì´
            episode_length = len(group)
            group['episode_length'] = episode_length

            # 2. Xì¶• ëˆ„ì  ì§„í–‰ë„
            first_x = group.iloc[0]['start_x']
            last_x = group.iloc[-1]['end_x']
            group['x_progression'] = group['start_x'] - first_x
            group['x_total_progression'] = last_x - first_x

            # 3. ìƒëŒ€ ì‹œê°„
            start_time = group.iloc[0]['time_seconds']
            group['relative_time'] = group['time_seconds'] - start_time

            # 4. í…œí¬
            if episode_length > 1:
                duration = group.iloc[-1]['time_seconds'] - group.iloc[0]['time_seconds']
                tempo = duration / episode_length if episode_length > 0 else 0
            else:
                tempo = 0
            group['tempo'] = tempo

            # 5. ì†ë„ ê³„ì‚° (ê°œì„ : ì—í”¼ì†Œë“œ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ëŒ€ì²´)
            time_diff = group['time_seconds'].diff()
            group['velocity_x'] = group['start_x'].diff() / time_diff.replace(0, np.nan)
            group['velocity_y'] = group['start_y'].diff() / time_diff.replace(0, np.nan)
            group['velocity'] = np.sqrt(group['velocity_x']**2 + group['velocity_y']**2)

            # 6. ê°€ì†ë„
            group['acceleration'] = group['velocity'].diff() / time_diff.replace(0, np.nan)

            # 7. í…œí¬ ë³€í™”ìœ¨
            group['tempo_change'] = tempo - group['relative_time'].rolling(2).mean().fillna(0)

            # 8. ì§„í–‰ ë°©í–¥ ì¼ê´€ì„±
            prev_delta_x = group['delta_x'].shift(1)
            prev_delta_y = group['delta_y'].shift(1)

            dot_prod = group['delta_x'] * prev_delta_x + group['delta_y'] * prev_delta_y
            mag_curr = np.sqrt(group['delta_x']**2 + group['delta_y']**2)
            mag_prev = np.sqrt(prev_delta_x**2 + prev_delta_y**2)
            group['direction_consistency'] = dot_prod / (mag_curr * mag_prev + 1e-10)

            # 9. ìµœì¢… 1/3 ì§€ì—­ ì²´ë¥˜ ì‹œê°„ ë¹„ìœ¨
            if 'in_final_third' in group.columns:
                final_third_time = group[group['in_final_third'] == 1]['relative_time'].sum()
                total_time = group['relative_time'].iloc[-1] if len(group) > 0 else 1
                group['final_third_time_ratio'] = final_third_time / (total_time + 1e-10)

            # 10. ìˆ˜í‰/ìˆ˜ì§ ì§„í–‰ë„ ë¹„ìœ¨
            total_horizontal = group['delta_x'].abs().sum()
            total_vertical = group['delta_y'].abs().sum()
            group['horizontal_vertical_ratio'] = total_horizontal / (total_vertical + 1e-10)

            episode_features.append(group)

        data = pd.concat(episode_features, ignore_index=True)

        if verbose:
            print(f"âœ… ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_previous_event_features(self, data, verbose=True):
        """ì§ì „ ì´ë²¤íŠ¸ í”¼ì²˜ ìƒì„±"""
        if verbose:
            print("â¬…ï¸  ì§ì „ ì´ë²¤íŠ¸ í”¼ì²˜ ìƒì„± ì¤‘...")

        episode_features = []

        for episode_id, group in data.groupby('game_episode'):
            group = group.copy()

            # ì§ì „ ì´ë²¤íŠ¸ ì •ë³´
            group['prev_type_name'] = group['type_name'].shift(1)
            group['prev_result_name'] = group['result_name'].shift(1)
            group['prev_start_x'] = group['start_x'].shift(1)
            group['prev_start_y'] = group['start_y'].shift(1)
            group['prev_end_x'] = group['end_x'].shift(1)
            group['prev_end_y'] = group['end_y'].shift(1)

            # ì§ì „ 2ê°œ ì´ë²¤íŠ¸
            group['prev2_type_name'] = group['type_name'].shift(2)

            episode_features.append(group)

        data = pd.concat(episode_features, ignore_index=True)

        if verbose:
            print(f"âœ… ì§ì „ ì´ë²¤íŠ¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_advanced_tactical_features(self, data, verbose=True):
        """ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ ìƒì„±"""
        if verbose:
            print("âš½ ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ ìƒì„± ì¤‘...")

        episode_features = []

        for episode_id, group in data.groupby('game_episode'):
            group = group.copy()

            # 1. ì••ë°• ê°•ë„
            if len(group) > 1:
                x_range = group['start_x'].max() - group['start_x'].min() + 1
                y_range = group['start_y'].max() - group['start_y'].min() + 1
                area = x_range * y_range
                event_density = len(group) / area
            else:
                event_density = 0
            group['event_density'] = event_density

            pressure_radius = 10

            if len(group) > 50:
                group['local_pressure'] = event_density * 10
                group['weighted_pressure'] = event_density * 5
            else:
                positions = group[['start_x', 'start_y']].values
                dist_matrix = cdist(positions, positions, metric='euclidean')

                nearby_mask = (dist_matrix <= pressure_radius) & (dist_matrix > 0)
                group['local_pressure'] = nearby_mask.sum(axis=1)

                weights_matrix = 1 / (dist_matrix + 1)
                np.fill_diagonal(weights_matrix, 0)
                group['weighted_pressure'] = weights_matrix.sum(axis=1)

            # 2. ê³µê°„ ì°½ì¶œ
            prev_distance = group['distance'].shift(1)
            group['distance_change_rate'] = (group['distance'] - prev_distance) / (prev_distance + 1e-10)

            group['vertical_spread'] = group['start_y'].rolling(window=3, min_periods=1).std()

            group['attack_width'] = group['start_y'].rolling(window=5, min_periods=1).apply(
                lambda x: x.max() - x.min(), raw=True
            )

            # 3. ì „ìˆ ì  ë²¡í„°
            group['forward_momentum'] = group['delta_x'].rolling(window=3, min_periods=1).sum()

            current_angle = np.arctan2(group['delta_y'], group['delta_x'])
            prev_angle = current_angle.shift(1)
            angle_change = np.abs(current_angle - prev_angle)
            angle_change = np.minimum(angle_change, 2*np.pi - angle_change)
            group['pass_angle_change'] = angle_change

            # 4. íˆìŠ¤í† ë¦¬ ê¸°ë°˜
            if 'velocity' in group.columns:
                group['avg_velocity_3'] = group['velocity'].rolling(window=3, min_periods=1).mean()

            if 'distance_to_goal_end' in group.columns:
                group['goal_approach_trend'] = group['distance_to_goal_end'].rolling(
                    window=3, min_periods=1
                ).apply(lambda x: x.iloc[0] - x.iloc[-1] if len(x) > 1 else 0, raw=False)

            # 5. ìµœì  ê²½ë¡œ
            if len(group) > 1:
                first_goal_dist = group.iloc[0]['distance_to_goal_start']
                last_goal_dist = group.iloc[-1]['distance_to_goal_end']
                actual_distance = group['distance'].sum()

                direct_progress = first_goal_dist - last_goal_dist
                path_efficiency = direct_progress / (actual_distance + 1e-10)
            else:
                path_efficiency = 0

            group['path_efficiency'] = path_efficiency

            # 6. íŒ€ ì¤‘ì‹¬ì  ëŒ€ë¹„ ìœ„ì¹˜
            team_center_x = group['start_x'].mean()
            team_center_y = group['start_y'].mean()

            group['dist_from_team_center'] = np.sqrt(
                (group['start_x'] - team_center_x)**2 +
                (group['start_y'] - team_center_y)**2
            )

            # 7. ê²½ê¸° í˜ì´ì¦ˆ
            if 'time_seconds' in group.columns:
                max_time = 5400
                group['match_phase'] = pd.cut(
                    group['time_seconds'],
                    bins=[0, 1800, 3600, max_time],
                    labels=[0, 1, 2]
                ).astype(float)

            episode_features.append(group)

        data = pd.concat(episode_features, ignore_index=True)

        if verbose:
            print(f"âœ… ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_context_features(self, data, verbose=True):
        """ğŸ’ NEW: ì„ ìˆ˜/íŒ€ ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ (EDA Phase 4 ì¸ì‚¬ì´íŠ¸)"""
        if verbose:
            print("ğŸ’ ì„ ìˆ˜/íŒ€ ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ì„ ìˆ˜ í†µê³„ ê³„ì‚° (ì „ì²´ ë°ì´í„° ê¸°ì¤€)
        if self.player_stats is None:
            self.player_stats = data.groupby('player_id').agg({
                'start_x': 'mean',
                'start_y': 'mean',
                'distance': 'mean',
                'velocity': 'mean'
            }).rename(columns={
                'start_x': 'player_avg_x',
                'start_y': 'player_avg_y',
                'distance': 'player_avg_pass_dist',
                'velocity': 'player_avg_velocity'
            })

        # ì„ ìˆ˜ í†µê³„ ë³‘í•©
        data = data.merge(self.player_stats, left_on='player_id', right_index=True, how='left')

        # 2. íŒ€ í†µê³„ ê³„ì‚°
        if self.team_stats is None:
            self.team_stats = data.groupby('team_id').agg({
                'x_total_progression': 'mean',
                'episode_length': 'mean',
                'tempo': 'mean'
            }).rename(columns={
                'x_total_progression': 'team_aggression',
                'episode_length': 'team_avg_episode_length',
                'tempo': 'team_avg_tempo'
            })

        # íŒ€ í†µê³„ ë³‘í•©
        data = data.merge(self.team_stats, left_on='team_id', right_index=True, how='left')

        # 3. ì‹œê°„ ì••ë°• (ê²½ê¸° ì¢…ë£Œ ì„ë°•)
        max_time_by_period = {1: 2700, 2: 2700}  # 45ë¶„ì”©
        data['time_pressure'] = data.apply(
            lambda row: np.maximum(0, (max_time_by_period.get(row['period_id'], 2700) - row['time_seconds']) / 2700),
            axis=1
        )

        # 4. ì„ ìˆ˜ ìœ„ì¹˜ ì´íƒˆë„ (í‰ì†Œì™€ ë‹¤ë¥¸ ìœ„ì¹˜)
        data['player_position_deviation'] = np.sqrt(
            (data['start_x'] - data['player_avg_x'])**2 +
            (data['start_y'] - data['player_avg_y'])**2
        )

        if verbose:
            print(f"âœ… ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ 8ê°œ ìƒì„± ì™„ë£Œ\n")

        return data

    def extract_last_events(self, data, verbose=True):
        """ê° ì—í”¼ì†Œë“œì˜ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œ"""
        if verbose:
            print("ğŸ¯ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ ì¶”ì¶œ ì¤‘...")

        last_events = data.groupby('game_episode').tail(1).copy()

        if verbose:
            print(f"âœ… {len(last_events):,}ê°œ ì—í”¼ì†Œë“œì˜ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ\n")

        return last_events

    def encode_categorical(self, data, fit=True, verbose=True):
        """ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"""
        if verbose:
            print("ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...")

        # type_name ì¸ì½”ë”© - í•˜ì§€ë§Œ ëª¨ë‘ Passì´ë¯€ë¡œ ì œê±° ê°€ëŠ¥
        # ì¼ë‹¨ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        data['type_name'] = data['type_name'].fillna('Unknown')
        if fit:
            data['type_name_encoded'] = self.type_encoder.fit_transform(data['type_name'])
        else:
            data['type_name_encoded'] = self.type_encoder.transform(data['type_name'])

        if 'prev_type_name' in data.columns:
            data['prev_type_name'] = data['prev_type_name'].fillna('Unknown')
            data['prev_type_name_encoded'] = self.type_encoder.transform(data['prev_type_name'])

        if 'prev2_type_name' in data.columns:
            data['prev2_type_name'] = data['prev2_type_name'].fillna('Unknown')
            data['prev2_type_name_encoded'] = self.type_encoder.transform(data['prev2_type_name'])

        # result_name ì¸ì½”ë”©
        if 'result_name' in data.columns and len(self.result_encoder.classes_) > 0:
            data['result_name'] = data['result_name'].fillna('Unknown')
            if fit:
                data['result_name_encoded'] = self.result_encoder.fit_transform(data['result_name'])
            else:
                data['result_name_encoded'] = self.result_encoder.transform(data['result_name'])

            if 'prev_result_name' in data.columns:
                data['prev_result_name'] = data['prev_result_name'].fillna('Unknown')
                data['prev_result_name_encoded'] = self.result_encoder.transform(data['prev_result_name'])

        if verbose:
            print(f"âœ… ì¸ì½”ë”© ì™„ë£Œ\n")

        return data

    def fill_missing(self, data, verbose=True):
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê°œì„ : ì—í”¼ì†Œë“œ í‰ê·  í™œìš©)"""
        if verbose:
            print("ğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")

        # ì†ë„/ê°€ì†ë„ í”¼ì²˜ì˜ ê²°ì¸¡ì¹˜ë¥¼ ì—í”¼ì†Œë“œ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
        for col in ['velocity', 'velocity_x', 'velocity_y', 'acceleration']:
            if col in data.columns:
                # ì—í”¼ì†Œë“œë³„ í‰ê·  ê³„ì‚°
                episode_mean = data.groupby('game_episode')[col].transform('mean')
                # ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
                data[col] = data[col].fillna(episode_mean)
                # ì—¬ì „íˆ NaNì´ë©´ 0ìœ¼ë¡œ (ì—í”¼ì†Œë“œ ì „ì²´ê°€ NaNì¸ ê²½ìš°)
                data[col] = data[col].fillna(0)

        # ì§ì „ ì´ë²¤íŠ¸ í”¼ì²˜
        prev_cols = [col for col in data.columns if col.startswith('prev_')]

        for col in prev_cols:
            if col.endswith('_encoded'):
                data[col] = data[col].fillna(-1)
            elif data[col].dtype in ['float64', 'int64']:
                data[col] = data[col].fillna(0)
            else:
                data[col] = data[col].fillna('Unknown')

        # zone í”¼ì²˜
        if 'start_x_zone' in data.columns:
            data['start_x_zone'] = data['start_x_zone'].astype(float).fillna(-1)
            data['start_y_zone'] = data['start_y_zone'].astype(float).fillna(-1)

        # ê¸°íƒ€ ìˆ˜ì¹˜í˜• í”¼ì²˜
        numeric_cols = data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if data[col].isna().sum() > 0:
                data[col] = data[col].fillna(0)

        if verbose:
            print(f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n")

        return data

    def create_train_val_split(self, data, n_splits=5, random_state=42, verbose=True):
        """Game-based K-Fold Split"""
        if verbose:
            print(f"ğŸ“Š {n_splits}-Fold Game-based Split ìƒì„± ì¤‘...")

        gkf = GroupKFold(n_splits=n_splits)

        splits = []
        for fold, (train_idx, val_idx) in enumerate(gkf.split(data, groups=data['game_id'])):
            train_games = data.iloc[train_idx]['game_id'].unique()
            val_games = data.iloc[val_idx]['game_id'].unique()

            splits.append({
                'fold': fold,
                'train_idx': train_idx,
                'val_idx': val_idx,
                'train_games': train_games,
                'val_games': val_games
            })

            if verbose:
                print(f"  Fold {fold+1}: Train {len(train_games)} games ({len(train_idx):,} episodes), "
                      f"Val {len(val_games)} games ({len(val_idx):,} episodes)")

        if verbose:
            print()

        return splits

    def fit_encoders(self, data, verbose=True):
        """ì „ì²´ ë°ì´í„°ì—ì„œ ì¸ì½”ë” í•™ìŠµ"""
        if verbose:
            print("ğŸ”¤ ì¸ì½”ë” í•™ìŠµ ì¤‘...")

        # type_name
        all_types = set()
        for col in ['type_name', 'prev_type_name', 'prev2_type_name']:
            if col in data.columns:
                all_types.update(data[col].fillna('Unknown').unique())

        self.type_encoder.fit(list(all_types))

        # result_name
        all_results = set()
        for col in ['result_name', 'prev_result_name']:
            if col in data.columns:
                all_results.update(data[col].fillna('Unknown').unique())

        if len(all_results) > 0:
            self.result_encoder.fit(list(all_results))

        if verbose:
            print(f"âœ… ì¸ì½”ë” í•™ìŠµ ì™„ë£Œ\n")

    def preprocess_pipeline(self, normalize_coords=False, verbose=True):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V2"""
        print("=" * 80)
        print("  K-League Pass Prediction - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V2")
        print("  ê°œì„ : ë‹¤ì¤‘ê³µì„ ì„± ì œê±° + ë¹„ì„ í˜• ë³€í™˜ + ìœ„ì¹˜ íŠ¹í™” + ì»¨í…ìŠ¤íŠ¸")
        print("=" * 80)
        print()

        # 1. ë°ì´í„° ë¡œë”©
        train_data, match_info = self.load_data(verbose=verbose)

        # 2. ì‹œê°„ ì •ë ¬
        train_data = self.sort_by_time(train_data, verbose=verbose)

        # 3. ê¸°ë³¸ í”¼ì²˜
        train_data = self.create_basic_features(train_data, verbose=verbose)

        # 4. ğŸ”¥ NEW: ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜
        train_data = self.create_nonlinear_features(train_data, verbose=verbose)

        # 5. ğŸ¯ NEW: ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜
        train_data = self.create_position_specific_features(train_data, verbose=verbose)

        # 6. ì‹œí€€ìŠ¤ í”¼ì²˜
        train_data = self.create_sequence_features(train_data, verbose=verbose)

        # 7. ì§ì „ ì´ë²¤íŠ¸ í”¼ì²˜
        train_data = self.create_previous_event_features(train_data, verbose=verbose)

        # 8. ê³ ê¸‰ ì „ìˆ  í”¼ì²˜
        train_data = self.create_advanced_tactical_features(train_data, verbose=verbose)

        # 9. ğŸ’ NEW: ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ (ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ ì¶”ì¶œ ì „ì— ì „ì²´ ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°)
        train_data = self.create_context_features(train_data, verbose=verbose)

        # 10. ì¸ì½”ë” í•™ìŠµ
        self.fit_encoders(train_data, verbose=verbose)

        # 11. ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œ
        last_events = self.extract_last_events(train_data, verbose=verbose)

        # 12. ë²”ì£¼í˜• ì¸ì½”ë”©
        last_events = self.encode_categorical(last_events, fit=False, verbose=verbose)

        # 13. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        last_events = self.fill_missing(last_events, verbose=verbose)

        # 14. Train/Val Split
        splits = self.create_train_val_split(last_events, n_splits=5, verbose=verbose)

        print("=" * 80)
        print("âœ… ì „ì²˜ë¦¬ V2 ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ í”¼ì²˜ ê°œìˆ˜: {len(self.get_feature_columns())}ê°œ")
        print("=" * 80)

        return last_events, splits

    def get_feature_columns(self):
        """í”¼ì²˜ ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜ (V2 - ê°œì„ ëœ ë²„ì „)"""
        feature_cols = [
            # ===== ê¸°ë³¸ ìœ„ì¹˜ ë° ì´ë™ =====
            'start_x', 'start_y',
            'delta_x', 'delta_y', 'distance',
            # ì œê±°: start_x_norm, start_y_norm (ë‹¤ì¤‘ê³µì„ ì„±)

            # ===== ê³¨ ê´€ë ¨ =====
            'distance_to_goal_start', 'distance_to_goal_end',
            'goal_approach',
            'shooting_angle',

            # ===== ğŸ”¥ NEW: ë¹„ì„ í˜• ë³€í™˜ =====
            'distance_to_goal_inv',
            'distance_to_goal_sqrt',
            'shooting_angle_sin',
            'shooting_angle_cos',
            'start_x_squared',
            'start_y_squared',
            'x_y_interaction',
            'goal_dist_angle_interaction',

            # ===== ì˜ì—­ ë¶„í•  =====
            'start_x_zone', 'start_y_zone',
            # ì œê±°: start_x_zone_fine (ë‹¤ì¤‘ê³µì„ ì„±)
            'in_penalty_area', 'in_final_third',

            # ===== ğŸ¯ NEW: ìœ„ì¹˜ë³„ íŠ¹í™” =====
            'is_defensive_third',
            'goal_urgency',
            'is_central_corridor',
            'near_goal_zone',
            'is_wing_attack',
            'is_midfield_control',

            # ===== ì—í”¼ì†Œë“œ ì •ë³´ =====
            'episode_length', 'event_order',
            'is_first_event',
            'x_progression', 'x_total_progression',
            'relative_time', 'tempo',

            # ===== ì†ë„ ë° ê°€ì†ë„ =====
            'velocity', 'velocity_x', 'velocity_y',
            'acceleration',

            # ===== ì „ìˆ ì  íë¦„ =====
            'tempo_change',
            'direction_consistency',
            'horizontal_vertical_ratio',
            'final_third_time_ratio',

            # ===== ì••ë°• ê°•ë„ =====
            'event_density',
            'local_pressure',
            'weighted_pressure',

            # ===== ê³µê°„ ì°½ì¶œ =====
            'distance_change_rate',
            'vertical_spread',
            'attack_width',

            # ===== ì „ìˆ ì  ë²¡í„° =====
            'forward_momentum',
            'pass_angle_change',

            # ===== íˆìŠ¤í† ë¦¬ ê¸°ë°˜ =====
            'avg_velocity_3',
            'goal_approach_trend',

            # ===== ìµœì  ê²½ë¡œ =====
            'path_efficiency',

            # ===== íŒ€ í¬ì§€ì…”ë‹ =====
            'dist_from_team_center',

            # ===== ê²½ê¸° í˜ì´ì¦ˆ =====
            'match_phase',

            # ===== ğŸ’ NEW: ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜ =====
            'player_avg_x',
            'player_avg_y',
            'player_avg_pass_dist',
            'player_avg_velocity',
            'team_aggression',
            'team_avg_episode_length',
            'team_avg_tempo',
            'time_pressure',
            'player_position_deviation',

            # ===== ì´ë²¤íŠ¸ íƒ€ì… =====
            # ì œê±° ê°€ëŠ¥í•˜ì§€ë§Œ í˜¸í™˜ì„± ìœ ì§€: type_name_encoded
            'type_name_encoded',

            # ===== ì§ì „ ì´ë²¤íŠ¸ =====
            'prev_type_name_encoded',
            'prev_start_x', 'prev_start_y',
            'prev_end_x', 'prev_end_y',

            # ===== ì§ì „ 2ê°œ =====
            'prev2_type_name_encoded',

            # ===== ê²½ê¸° ì •ë³´ =====
            'period_id', 'is_home'
        ]

        # result_nameì´ ìˆìœ¼ë©´ ì¶”ê°€
        if hasattr(self, 'result_encoder') and len(self.result_encoder.classes_) > 0:
            feature_cols.extend(['result_name_encoded', 'prev_result_name_encoded'])

        return feature_cols

    def save_preprocessor(self, filename='preprocessor_v2.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'scaler_x': self.scaler_x,
                'scaler_y': self.scaler_y,
                'type_encoder': self.type_encoder,
                'result_encoder': self.result_encoder,
                'player_stats': self.player_stats,
                'team_stats': self.team_stats
            }, f)
        print(f"âœ… Preprocessor V2 ì €ì¥: {filename}")

    def load_preprocessor(self, filename='preprocessor_v2.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ë¡œë”©"""
        with open(filename, 'rb') as f:
            saved = pickle.load(f)
            self.scaler_x = saved['scaler_x']
            self.scaler_y = saved['scaler_y']
            self.type_encoder = saved['type_encoder']
            self.result_encoder = saved['result_encoder']
            self.player_stats = saved.get('player_stats')
            self.team_stats = saved.get('team_stats')
        print(f"âœ… Preprocessor V2 ë¡œë”©: {filename}")


def main():
    """V2 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    preprocessor = DataPreprocessorV2(data_dir='./data')

    # ì „ì²˜ë¦¬ ì‹¤í–‰
    processed_data, splits = preprocessor.preprocess_pipeline(
        normalize_coords=False,
        verbose=True
    )

    # í”¼ì²˜ ì»¬ëŸ¼ í™•ì¸
    feature_cols = preprocessor.get_feature_columns()

    print("\n" + "=" * 80)
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„° Shape: {processed_data.shape}")
    print(f"ğŸ“Š í”¼ì²˜ ê°œìˆ˜: {len(feature_cols)}")
    print(f"ğŸ“Š Fold ê°œìˆ˜: {len(splits)}")
    print("=" * 80)

    print("\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜:")
    for i, col in enumerate(feature_cols, 1):
        if col in processed_data.columns:
            status = "âœ“"
        else:
            status = "âœ—"
        print(f"  {status} {i:2d}. {col}")

    # Preprocessor ì €ì¥
    preprocessor.save_preprocessor('preprocessor_v2.pkl')

    # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
    processed_data.to_csv('processed_train_data_v2.csv', index=False)
    print(f"\nâœ… ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥: processed_train_data_v2.csv")

    # ê°œì„  ì‚¬í•­ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“ˆ V2 ê°œì„  ì‚¬í•­ ìš”ì•½")
    print("=" * 80)
    print("âœ… ì œê±°ëœ í”¼ì²˜ (ë‹¤ì¤‘ê³µì„ ì„±): 5ê°œ")
    print("   - start_x_norm, start_y_norm, start_x_zone_fine")
    print("ğŸ”¥ ì¶”ê°€ëœ ë¹„ì„ í˜• í”¼ì²˜: 8ê°œ")
    print("   - distance_to_goal_inv, sqrt, angle_sin/cos, squared ë“±")
    print("ğŸ¯ ì¶”ê°€ëœ ìœ„ì¹˜ íŠ¹í™” í”¼ì²˜: 6ê°œ")
    print("   - is_defensive_third, goal_urgency, is_central_corridor ë“±")
    print("ğŸ’ ì¶”ê°€ëœ ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜: 9ê°œ")
    print("   - player_avg_*, team_*, time_pressure ë“±")
    print("ğŸ”§ ê°œì„ ëœ ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì—í”¼ì†Œë“œ í‰ê·  í™œìš©")
    print("=" * 80)

    return processed_data, splits, preprocessor


if __name__ == "__main__":
    processed_data, splits, preprocessor = main()

