"""
LightGBM ëª¨ë¸ í•™ìŠµ - V4 (5-Fold ì•™ìƒë¸”)

V2ì˜ í’ë¶€í•œ í”¼ì²˜ + V3ì˜ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ = ìµœê³  ì„±ëŠ¥
ëª©í‘œ: Test ì„±ëŠ¥ 14~16ì ëŒ€
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GroupKFold
import pickle
import warnings
warnings.filterwarnings('ignore')


def euclidean_distance(y_true, y_pred):
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    distances = np.sqrt((y_true[:, 0] - y_pred[:, 0])**2 +
                       (y_true[:, 1] - y_pred[:, 1])**2)
    return distances.mean()


def main():
    print("=" * 80)
    print("  LightGBM V4 - 5-Fold ì•™ìƒë¸” í•™ìŠµ")
    print("  V2 í”¼ì²˜ + V3 ì‹œí€€ìŠ¤ ëª¨ë¸ë§")
    print("=" * 80)
    print()

    # 1. ë°ì´í„° ë¡œë”©
    print("ğŸ“Š ë°ì´í„° ë¡œë”©...")
    data = pd.read_csv('processed_train_data_v4.csv')
    print(f"ë°ì´í„°: {data.shape}\n")

    # 2. í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬
    print("ğŸ“Š í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬...")

    # íƒ€ê²Ÿ
    y_train_x = data['target_x'].values
    y_train_y = data['target_y'].values

    # game_id ì¶”ì¶œ (GroupKFoldìš©)
    game_ids = data['game_id'].values

    # í”¼ì²˜ (ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°)
    drop_cols = ['game_episode', 'game_id', 'target_x', 'target_y', 'final_team_id']
    X_train = data.drop(columns=[c for c in drop_cols if c in data.columns])

    # NaN ì±„ìš°ê¸°
    X_train = X_train.fillna(0)

    # ë°ì´í„° íƒ€ì… ë³€í™˜
    for col in X_train.columns:
        if X_train[col].dtype == 'object':
            X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)

    print(f"í”¼ì²˜ ìˆ˜: {X_train.shape[1]}")
    print(f"ìƒ˜í”Œ ìˆ˜: {len(X_train):,}\n")

    # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'learning_rate': 0.05,
        'num_leaves': 127,
        'min_data_in_leaf': 80,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 1,
        'verbose': -1,
    }

    # 4. 5-Fold GroupKFold í•™ìŠµ
    print("ğŸ”§ 5-Fold GroupKFold í•™ìŠµ ì‹œì‘...\n")

    gkf = GroupKFold(n_splits=5)

    models_x = []
    models_y = []
    fold_scores = []

    for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train, groups=game_ids)):
        print(f"{'='*60}")
        print(f"  Fold {fold+1}/5")
        print(f"{'='*60}")

        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
        y_tr_x, y_val_x = y_train_x[train_idx], y_train_x[val_idx]
        y_tr_y, y_val_y = y_train_y[train_idx], y_train_y[val_idx]

        print(f"Train: {len(X_tr):,}, Val: {len(X_val):,}")

        # X ì¢Œí‘œ ëª¨ë¸
        print("end_x ëª¨ë¸ í•™ìŠµ ì¤‘...")
        dtrain_x = lgb.Dataset(X_tr, label=y_tr_x)
        dvalid_x = lgb.Dataset(X_val, label=y_val_x, reference=dtrain_x)

        model_x = lgb.train(
            params,
            dtrain_x,
            num_boost_round=3000,
            valid_sets=[dtrain_x, dvalid_x],
            valid_names=['train', 'valid'],
            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
        )
        models_x.append(model_x)
        print(f"  -> ìµœì¢… {model_x.best_iteration} rounds")

        # Y ì¢Œí‘œ ëª¨ë¸
        print("end_y ëª¨ë¸ í•™ìŠµ ì¤‘...")
        dtrain_y = lgb.Dataset(X_tr, label=y_tr_y)
        dvalid_y = lgb.Dataset(X_val, label=y_val_y, reference=dtrain_y)

        model_y = lgb.train(
            params,
            dtrain_y,
            num_boost_round=3000,
            valid_sets=[dtrain_y, dvalid_y],
            valid_names=['train', 'valid'],
            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
        )
        models_y.append(model_y)
        print(f"  -> ìµœì¢… {model_y.best_iteration} rounds")

        # ê²€ì¦
        pred_x = model_x.predict(X_val, num_iteration=model_x.best_iteration)
        pred_y = model_y.predict(X_val, num_iteration=model_y.best_iteration)
        y_pred = np.column_stack([pred_x, pred_y])
        y_val = np.column_stack([y_val_x, y_val_y])

        eucl_dist = euclidean_distance(y_val, y_pred)
        mse_x = mean_squared_error(y_val_x, pred_x)
        mse_y = mean_squared_error(y_val_y, pred_y)

        print(f"\nFold {fold+1} ê²°ê³¼:")
        print(f"  - ìœ í´ë¦¬ë“œ ê±°ë¦¬: {eucl_dist:.4f}m")
        print(f"  - MSE X: {mse_x:.4f}")
        print(f"  - MSE Y: {mse_y:.4f}\n")

        fold_scores.append({
            'fold': fold + 1,
            'euclidean': eucl_dist,
            'mse_x': mse_x,
            'mse_y': mse_y
        })

        # Feature Importance (ì²« ë²ˆì§¸ foldë§Œ)
        if fold == 0:
            print("\nğŸ“Š Feature Importance Top 20 (X ì¢Œí‘œ):")
            importance_x = model_x.feature_importance()
            importance_df = pd.DataFrame({
                'feature': X_train.columns,
                'importance': importance_x
            }).sort_values('importance', ascending=False)

            for idx, row in importance_df.head(20).iterrows():
                print(f"  {importance_df.index.get_loc(idx)+1:2d}. {row['feature']:40s}: {row['importance']:8.1f}")

    # 5. ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print("  ì „ì²´ ê²°ê³¼ ìš”ì•½")
    print("="*80)

    scores_df = pd.DataFrame(fold_scores)
    mean_eucl = scores_df['euclidean'].mean()
    std_eucl = scores_df['euclidean'].std()

    print(f"\ní‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬: {mean_eucl:.4f}m Â± {std_eucl:.4f}m")
    print(f"í‰ê·  MSE X: {scores_df['mse_x'].mean():.4f}")
    print(f"í‰ê·  MSE Y: {scores_df['mse_y'].mean():.4f}")

    print("\nFoldë³„ ìƒì„¸:")
    for _, row in scores_df.iterrows():
        print(f"  Fold {int(row['fold'])}: {row['euclidean']:.4f}m")

    # 6. ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
    with open('lightgbm_model_v4_5fold.pkl', 'wb') as f:
        pickle.dump({
            'models_x': models_x,
            'models_y': models_y,
            'val_score': mean_eucl,
            'fold_scores': fold_scores
        }, f)
    print("âœ… ëª¨ë¸ ì €ì¥: lightgbm_model_v4_5fold.pkl")

    # 7. ì„±ëŠ¥ ë¹„êµ
    print("\n" + "="*80)
    print("  ì„±ëŠ¥ ë¹„êµ")
    print("="*80)

    print("\nğŸ“Š ë²„ì „ë³„ ì„±ëŠ¥ ë¹„êµ:")
    print("V1 (Baseline):")
    print("  - Validation: 0.93m (Data Leakage)")
    print("  - Test: 24ì ëŒ€")

    print("\nV2 (ë„ë©”ì¸ ì§€ì‹ í”¼ì²˜):")
    print("  - í’ë¶€í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
    print("  - Data Leakage ì¡´ì¬")

    print("\nV3 (ì‹œí€€ìŠ¤ ëª¨ë¸ë§):")
    print("  - Validation: ~1.5m")
    print("  - Test: 14ì ëŒ€ (30% ê°œì„ )")

    print(f"\nV4 (V2 + V3 í†µí•©):")
    print(f"  - Validation: {mean_eucl:.4f}m")
    print(f"  - ì˜ˆìƒ Test: 13~15ì ëŒ€ (ìµœê³  ì„±ëŠ¥ ê¸°ëŒ€)")

    if mean_eucl < 1.5:
        print("\nğŸ‰ ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥! Testì—ì„œ ì¢‹ì€ ê²°ê³¼ ê¸°ëŒ€")
    elif mean_eucl < 2.0:
        print("\nâœ… ì¢‹ì€ ì„±ëŠ¥! V3ì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ë” ë‚˜ì€ ê²°ê³¼ ì˜ˆìƒ")
    else:
        print("\nğŸ“ˆ ì¶”ê°€ íŠœë‹ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥")

    print("\n" + "="*80)
    print("ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. Test ì¶”ë¡  (inference_v4.py)")
    print("   2. ì œì¶œ ë° ì ìˆ˜ í™•ì¸")
    print("   3. V3/V4 ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
    print("="*80)


if __name__ == "__main__":
    main()

