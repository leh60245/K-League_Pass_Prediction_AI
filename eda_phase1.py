"""
K-League Pass Prediction - EDA Analysis
Phase 1: Data Foundation Analysis

ëª©í‘œ: ë°ì´í„° êµ¬ì¡°, í’ˆì§ˆ, ê¸°ë³¸ í†µê³„ íŒŒì•…
ì¶œë ¥: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

# ì¶œë ¥ í˜•ì‹ ì„¤ì •
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', lambda x: f'{x:.4f}')

class EDAAnalyzer:
    def __init__(self, data_dir='./data'):
        self.data_dir = data_dir
        self.insights = []
        self.train_data = None
        self.test_data = None
        self.match_info = None

    def log_insight(self, text):
        """ì¸ì‚¬ì´íŠ¸ ë¡œê¹…"""
        print(text)
        self.insights.append(text)

    def print_section(self, title, level=1):
        """ì„¹ì…˜ êµ¬ë¶„ ì¶œë ¥"""
        if level == 1:
            separator = "=" * 80
            self.log_insight(f"\n{separator}")
            self.log_insight(f"  {title}")
            self.log_insight(separator + "\n")
        elif level == 2:
            self.log_insight(f"\n{'â”€' * 60}")
            self.log_insight(f"[{title}]")
            self.log_insight('â”€' * 60)

    def save_insights(self, filename='EDA_insights.txt'):
        """ì¸ì‚¬ì´íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"K-League Pass Prediction EDA Insights\n")
            f.write(f"Generated: {timestamp}\n")
            f.write("=" * 80 + "\n\n")
            f.write('\n'.join(self.insights))
        print(f"\nâœ… ì¸ì‚¬ì´íŠ¸ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ========================================================================
    # Phase 1: ë°ì´í„° ê¸°ì´ˆ ì§„ë‹¨
    # ========================================================================

    def load_data_structure(self):
        """ë°ì´í„° êµ¬ì¡° íŒŒì•… ë° ë¡œë”© ì „ëµ ìˆ˜ë¦½"""
        self.print_section("PHASE 1: ë°ì´í„° ê¸°ì´ˆ ì§„ë‹¨ - ë°ì´í„° êµ¬ì¡° íŒŒì•…", level=1)

        # 1.1 Train ë°ì´í„° êµ¬ì¡°
        self.print_section("1.1 Train ë°ì´í„° êµ¬ì¡°", level=2)
        train_path = os.path.join(self.data_dir, 'train.csv')

        # íŒŒì¼ í¬ê¸° í™•ì¸
        if os.path.exists(train_path):
            file_size_mb = os.path.getsize(train_path) / (1024 * 1024)
            self.log_insight(f"ğŸ“Š Train ë°ì´í„° íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

            # ìƒ˜í”Œ ë¡œë”©ìœ¼ë¡œ êµ¬ì¡° íŒŒì•…
            try:
                # ì²˜ìŒ 100,000í–‰ë§Œ ë¡œë”©
                sample_train = pd.read_csv(train_path, nrows=100000)
                self.log_insight(f"âœ… ìƒ˜í”Œ ë¡œë”© ì„±ê³µ (100,000 rows)")
                self.log_insight(f"\nì»¬ëŸ¼ êµ¬ì¡°:")
                for col in sample_train.columns:
                    dtype = sample_train[col].dtype
                    non_null = sample_train[col].notna().sum()
                    null_pct = (1 - non_null/len(sample_train)) * 100
                    self.log_insight(f"  - {col:20s}: {str(dtype):12s} (ê²°ì¸¡: {null_pct:5.2f}%)")

                # ì—í”¼ì†Œë“œ ìˆ˜ ì¶”ì •
                unique_episodes_sample = sample_train['game_episode'].nunique()
                self.log_insight(f"\nìƒ˜í”Œ ë‚´ ê³ ìœ  ì—í”¼ì†Œë“œ ìˆ˜: {unique_episodes_sample:,}")

                # ì „ì²´ íŒŒì¼ ë¼ì¸ ìˆ˜ ì¶”ì • (ì •í™•í•˜ê²Œ ì„¸ê¸°)
                self.log_insight(f"\nì „ì²´ íŒŒì¼ í¬ê¸° ë¶„ì„ ì¤‘...")
                total_lines = sum(1 for _ in open(train_path, encoding='utf-8')) - 1  # í—¤ë” ì œì™¸
                self.log_insight(f"ì „ì²´ ì´ë²¤íŠ¸ ìˆ˜: {total_lines:,}")

                # ì „ì²´ ë°ì´í„° ë¡œë”©
                self.log_insight(f"\nì „ì²´ Train ë°ì´í„° ë¡œë”© ì¤‘...")
                self.train_data = pd.read_csv(train_path)
                total_episodes = self.train_data['game_episode'].nunique()
                total_games = self.train_data['game_id'].nunique()

                self.log_insight(f"âœ… Train ë°ì´í„° ë¡œë”© ì™„ë£Œ")
                self.log_insight(f"  - ì´ ì—í”¼ì†Œë“œ ìˆ˜: {total_episodes:,}")
                self.log_insight(f"  - ì´ ê²½ê¸° ìˆ˜: {total_games:,}")
                self.log_insight(f"  - ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(self.train_data):,}")
                self.log_insight(f"  - ê²½ê¸°ë‹¹ í‰ê·  ì—í”¼ì†Œë“œ: {total_episodes/total_games:.1f}")
                self.log_insight(f"  - ì—í”¼ì†Œë“œë‹¹ í‰ê·  ì´ë²¤íŠ¸: {len(self.train_data)/total_episodes:.1f}")

            except Exception as e:
                self.log_insight(f"âŒ Train ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        else:
            self.log_insight(f"âŒ Train íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_path}")

        # 1.2 Test ë°ì´í„° êµ¬ì¡°
        self.print_section("1.2 Test ë°ì´í„° êµ¬ì¡°", level=2)
        test_index_path = os.path.join(self.data_dir, 'test.csv')

        if os.path.exists(test_index_path):
            test_index = pd.read_csv(test_index_path)
            self.log_insight(f"ğŸ“Š Test ì—í”¼ì†Œë“œ ìˆ˜: {len(test_index):,}")
            self.log_insight(f"  - ê²½ê¸° ìˆ˜: {test_index['game_id'].nunique()}")
            self.log_insight(f"  - ê²½ê¸°ë‹¹ í‰ê·  ì—í”¼ì†Œë“œ: {len(test_index)/test_index['game_id'].nunique():.1f}")

            # ìƒ˜í”Œ ì—í”¼ì†Œë“œ ë¡œë”©
            sample_path = test_index.iloc[0]['path']
            sample_full_path = os.path.join(self.data_dir, sample_path.replace('./', ''))

            if os.path.exists(sample_full_path):
                sample_episode = pd.read_csv(sample_full_path)
                self.log_insight(f"\nìƒ˜í”Œ ì—í”¼ì†Œë“œ ë¶„ì„: {test_index.iloc[0]['game_episode']}")
                self.log_insight(f"  - ì´ë²¤íŠ¸ ìˆ˜: {len(sample_episode)}")
                self.log_insight(f"  - ë§ˆì§€ë§‰ í–‰ end_x ê²°ì¸¡: {pd.isna(sample_episode.iloc[-1]['end_x'])}")
                self.log_insight(f"  - ë§ˆì§€ë§‰ í–‰ end_y ê²°ì¸¡: {pd.isna(sample_episode.iloc[-1]['end_y'])}")

        # 1.3 Match Info
        self.print_section("1.3 Match Info ë°ì´í„°", level=2)
        match_info_path = os.path.join(self.data_dir, 'match_info.csv')

        if os.path.exists(match_info_path):
            self.match_info = pd.read_csv(match_info_path)
            self.log_insight(f"ğŸ“Š ê²½ê¸° ì •ë³´: {len(self.match_info)} ê²½ê¸°")
            self.log_insight(f"  - ì‹œì¦Œ: {self.match_info['season_name'].unique()}")
            self.log_insight(f"  - ëŒ€íšŒ: {self.match_info['competition_name'].unique()}")
            self.log_insight(f"  - íŒ€ ìˆ˜: {len(set(self.match_info['home_team_id']) | set(self.match_info['away_team_id']))}")

    def analyze_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        self.print_section("PHASE 1: ë°ì´í„° í’ˆì§ˆ ë¶„ì„", level=1)

        if self.train_data is None:
            self.log_insight("âŒ Train ë°ì´í„°ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # 2.1 ê²°ì¸¡ì¹˜ ë¶„ì„
        self.print_section("2.1 ê²°ì¸¡ì¹˜ ë¶„ì„", level=2)

        missing_summary = []
        for col in self.train_data.columns:
            missing_count = self.train_data[col].isna().sum()
            missing_pct = (missing_count / len(self.train_data)) * 100
            if missing_count > 0:
                missing_summary.append({
                    'column': col,
                    'missing_count': missing_count,
                    'missing_pct': missing_pct
                })

        if missing_summary:
            self.log_insight("ğŸ“Š ê²°ì¸¡ì¹˜ í˜„í™©:")
            for item in sorted(missing_summary, key=lambda x: x['missing_pct'], reverse=True):
                self.log_insight(f"  - {item['column']:20s}: {item['missing_count']:8,} ({item['missing_pct']:6.2f}%)")

            # player_id ê²°ì¸¡ì¹˜ íŒ¨í„´ ë¶„ì„
            if 'player_id' in self.train_data.columns:
                self.log_insight("\nğŸ” player_id ê²°ì¸¡ì¹˜ ìƒì„¸ ë¶„ì„:")
                missing_player = self.train_data[self.train_data['player_id'].isna()]
                event_types = missing_player['type_name'].value_counts()
                self.log_insight("  ê²°ì¸¡ì¹˜ê°€ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸ íƒ€ì…:")
                for event, count in event_types.head(10).items():
                    pct = (count / len(missing_player)) * 100
                    self.log_insight(f"    - {event:30s}: {count:6,} ({pct:5.1f}%)")
        else:
            self.log_insight("âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ")

        # 2.2 ì¢Œí‘œ ë²”ìœ„ ê²€ì¦
        self.print_section("2.2 ì¢Œí‘œ ë²”ìœ„ ê²€ì¦", level=2)

        coord_cols = ['start_x', 'start_y', 'end_x', 'end_y']
        coord_ranges = {'x': (0, 105), 'y': (0, 68)}

        outliers = {}
        for col in coord_cols:
            if col in self.train_data.columns:
                valid_data = self.train_data[col].dropna()
                axis = 'x' if 'x' in col else 'y'
                min_val, max_val = coord_ranges[axis]

                below_min = (valid_data < min_val).sum()
                above_max = (valid_data > max_val).sum()
                total_outliers = below_min + above_max

                if total_outliers > 0:
                    outliers[col] = {
                        'below': below_min,
                        'above': above_max,
                        'total': total_outliers,
                        'pct': (total_outliers / len(valid_data)) * 100
                    }

                self.log_insight(f"{col:12s}: min={valid_data.min():7.2f}, max={valid_data.max():7.2f}, "
                               f"mean={valid_data.mean():7.2f}, std={valid_data.std():6.2f}")

        if outliers:
            self.log_insight("\nâš ï¸  ë²”ìœ„ ë²—ì–´ë‚œ ì¢Œí‘œ:")
            for col, stats in outliers.items():
                self.log_insight(f"  - {col}: {stats['total']:,} ({stats['pct']:.4f}%) "
                               f"[í•˜í•œ ì´ˆê³¼: {stats['below']}, ìƒí•œ ì´ˆê³¼: {stats['above']}]")
        else:
            self.log_insight("\nâœ… ëª¨ë“  ì¢Œí‘œê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")

        # 2.3 ì‹œê°„ ì •í•©ì„± ê²€ì¦
        self.print_section("2.3 ì‹œê°„ ì •í•©ì„± ê²€ì¦", level=2)

        # ì—í”¼ì†Œë“œë³„ë¡œ ì‹œê°„ ìˆœì„œ í™•ì¸
        time_issues = 0
        total_episodes = 0

        for episode_id, group in self.train_data.groupby('game_episode'):
            total_episodes += 1
            # action_id ìˆœì„œì™€ time_seconds ìˆœì„œ ë¹„êµ
            action_sorted = group.sort_values('action_id')
            time_sorted = group.sort_values('time_seconds')

            if not action_sorted.index.equals(time_sorted.index):
                time_issues += 1

        self.log_insight(f"ğŸ“Š ì‹œê°„ ìˆœì„œ ê²€ì¦:")
        self.log_insight(f"  - ì „ì²´ ì—í”¼ì†Œë“œ: {total_episodes:,}")
        self.log_insight(f"  - action_idì™€ time_seconds ìˆœì„œ ë¶ˆì¼ì¹˜: {time_issues:,} ({time_issues/total_episodes*100:.2f}%)")

        if time_issues > 0:
            self.log_insight(f"  âš ï¸  ê¶Œì¥: time_seconds ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í•„ìš”")

        # ì‹œê°„ ì—­ì „ í™•ì¸
        time_reversals = 0
        for episode_id, group in self.train_data.groupby('game_episode'):
            time_diff = group.sort_values('action_id')['time_seconds'].diff()
            if (time_diff < 0).any():
                time_reversals += 1

        self.log_insight(f"  - ì‹œê°„ ì—­ì „ ì—í”¼ì†Œë“œ: {time_reversals:,} ({time_reversals/total_episodes*100:.2f}%)")

    def analyze_basic_statistics(self):
        """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
        self.print_section("PHASE 1: ê¸°ë³¸ í†µê³„ ë¶„ì„", level=1)

        if self.train_data is None:
            return

        # 3.1 ì—í”¼ì†Œë“œ ê¸¸ì´ ë¶„ì„
        self.print_section("3.1 ì—í”¼ì†Œë“œ ê¸¸ì´ ë¶„ì„", level=2)

        episode_lengths = self.train_data.groupby('game_episode').size()

        self.log_insight("ğŸ“Š ì—í”¼ì†Œë“œ ê¸¸ì´ í†µê³„:")
        self.log_insight(f"  - í‰ê· : {episode_lengths.mean():.1f} ì´ë²¤íŠ¸")
        self.log_insight(f"  - ì¤‘ì•™ê°’: {episode_lengths.median():.0f} ì´ë²¤íŠ¸")
        self.log_insight(f"  - í‘œì¤€í¸ì°¨: {episode_lengths.std():.1f}")
        self.log_insight(f"  - ìµœì†Œ: {episode_lengths.min()} ì´ë²¤íŠ¸")
        self.log_insight(f"  - ìµœëŒ€: {episode_lengths.max()} ì´ë²¤íŠ¸")

        self.log_insight("\në°±ë¶„ìœ„ìˆ˜:")
        percentiles = [25, 50, 75, 90, 95, 99]
        for p in percentiles:
            val = episode_lengths.quantile(p/100)
            self.log_insight(f"  - {p:2d}%: {val:6.0f} ì´ë²¤íŠ¸")

        # ê¸¸ì´ë³„ ë¶„í¬
        self.log_insight("\nì—í”¼ì†Œë“œ ê¸¸ì´ ë¶„í¬:")
        length_bins = [0, 10, 20, 30, 50, 100, float('inf')]
        length_labels = ['1-10', '11-20', '21-30', '31-50', '51-100', '100+']
        length_dist = pd.cut(episode_lengths, bins=length_bins, labels=length_labels).value_counts().sort_index()

        for length_range, count in length_dist.items():
            pct = (count / len(episode_lengths)) * 100
            self.log_insight(f"  - {length_range:8s}: {count:6,} ({pct:5.1f}%)")

        # 3.2 ì´ë²¤íŠ¸ íƒ€ì… ë¶„ì„
        self.print_section("3.2 ì´ë²¤íŠ¸ íƒ€ì… ë¶„ì„", level=2)

        event_counts = self.train_data['type_name'].value_counts()
        self.log_insight(f"ğŸ“Š ì´ {len(event_counts)} ì¢…ë¥˜ì˜ ì´ë²¤íŠ¸ íƒ€ì…")
        self.log_insight(f"\nTop 15 ì´ë²¤íŠ¸ íƒ€ì…:")

        for i, (event_type, count) in enumerate(event_counts.head(15).items(), 1):
            pct = (count / len(self.train_data)) * 100
            self.log_insight(f"  {i:2d}. {event_type:30s}: {count:8,} ({pct:5.2f}%)")

        # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„
        if 'result_name' in self.train_data.columns:
            self.log_insight("\nğŸ“Š ì´ë²¤íŠ¸ ê²°ê³¼ ë¶„í¬:")
            result_counts = self.train_data['result_name'].value_counts(dropna=False)
            for result, count in result_counts.items():
                pct = (count / len(self.train_data)) * 100
                result_str = 'NaN (ê²°ê³¼ ì—†ìŒ)' if pd.isna(result) else result
                self.log_insight(f"  - {result_str:30s}: {count:8,} ({pct:5.2f}%)")

        # 3.3 ì‹œê°„ ë¶„ì„
        self.print_section("3.3 ì‹œê°„ íŠ¹ì„± ë¶„ì„", level=2)

        # ì—í”¼ì†Œë“œ ì§€ì† ì‹œê°„
        episode_durations = self.train_data.groupby('game_episode').apply(
            lambda x: x['time_seconds'].max() - x['time_seconds'].min()
        )

        self.log_insight("ğŸ“Š ì—í”¼ì†Œë“œ ì§€ì† ì‹œê°„:")
        self.log_insight(f"  - í‰ê· : {episode_durations.mean():.1f} ì´ˆ")
        self.log_insight(f"  - ì¤‘ì•™ê°’: {episode_durations.median():.1f} ì´ˆ")
        self.log_insight(f"  - í‘œì¤€í¸ì°¨: {episode_durations.std():.1f} ì´ˆ")
        self.log_insight(f"  - ìµœì†Œ: {episode_durations.min():.1f} ì´ˆ")
        self.log_insight(f"  - ìµœëŒ€: {episode_durations.max():.1f} ì´ˆ")

        # ì „ë°˜/í›„ë°˜ ë¶„ì„
        if 'period_id' in self.train_data.columns:
            self.log_insight("\nğŸ“Š ì „ë°˜/í›„ë°˜ ë¶„í¬:")
            period_counts = self.train_data['period_id'].value_counts().sort_index()
            for period, count in period_counts.items():
                pct = (count / len(self.train_data)) * 100
                self.log_insight(f"  - Period {period}: {count:8,} ({pct:5.2f}%)")

    def generate_summary(self):
        """Phase 1 ì¢…í•© ìš”ì•½ ë° ëª¨ë¸ë§ ì‹œì‚¬ì """
        self.print_section("PHASE 1 ì¢…í•© ìš”ì•½ ë° ëª¨ë¸ë§ ì‹œì‚¬ì ", level=1)

        self.log_insight("=" * 80)
        self.log_insight("ğŸ“‹ í•µì‹¬ ë°œê²¬ (Key Findings)")
        self.log_insight("=" * 80)

        self.log_insight("""
[1. ë°ì´í„° ê·œëª¨]
- Train: ëŒ€ê·œëª¨ ì‹œí€€ìŠ¤ ë°ì´í„° (ìˆ˜ë§Œ ê°œ ì—í”¼ì†Œë“œ)
- Test: 2,415 ì—í”¼ì†Œë“œ ì˜ˆì¸¡ í•„ìš”
- ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„° í™•ë³´ë¨

[2. ë°ì´í„° í’ˆì§ˆ]
- player_id ê²°ì¸¡: íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì…ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë°œìƒ (Out, Block ë“±)
- ì¢Œí‘œ ë°ì´í„°: ëŒ€ë¶€ë¶„ ì •ìƒ ë²”ìœ„ ë‚´
- ì‹œê°„ ìˆœì„œ: ì¼ë¶€ ë¶ˆì¼ì¹˜ ì¡´ì¬ â†’ time_seconds ê¸°ì¤€ ì •ë ¬ í•„ìš”

[3. ì‹œí€€ìŠ¤ íŠ¹ì„±]
- ì—í”¼ì†Œë“œ ê¸¸ì´: ë§¤ìš° ê°€ë³€ì  (ìµœì†Œ ~ ìµœëŒ€ í¸ì°¨ í¼)
- ëŒ€ë¶€ë¶„ 50ê°œ ì´í•˜ ì´ë²¤íŠ¸
- Padding/Truncation ì „ëµ í•„ìš”

[4. ì´ë²¤íŠ¸ íŒ¨í„´]
- Passê°€ ê°€ì¥ ë¹ˆë²ˆí•œ ì´ë²¤íŠ¸
- Carry, Duel ë“± ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ íƒ€ì… ì¡´ì¬
- ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ ì¸ì½”ë”©ì´ í•µì‹¬
""")

        self.log_insight("\n" + "=" * 80)
        self.log_insight("ğŸ¯ ëª¨ë¸ë§ ì‹œì‚¬ì  (Modeling Implications)")
        self.log_insight("=" * 80)

        self.log_insight("""
[í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§]
âœ“ ì‹œí€€ìŠ¤ ê¸¸ì´ í‘œì¤€í™”: 95 percentile ê¸°ì¤€ (ì•½ ~ê°œ ì´ë²¤íŠ¸)
âœ“ ì¢Œí‘œ ì •ê·œí™”: MinMax or Standard Scaling
âœ“ ì‹œê°„ ì •ë³´: ìƒëŒ€ ì‹œê°„, ì‹œê°„ ê°„ê²© í”¼ì²˜
âœ“ ì´ë²¤íŠ¸ íƒ€ì…: Embedding or One-Hot Encoding

[ëª¨ë¸ ì„ íƒ]
âœ“ LSTM/GRU: ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ (Masking í•„ìˆ˜)
âœ“ Transformer: Attentionìœ¼ë¡œ ì¤‘ìš” ì´ë²¤íŠ¸ í¬ì°©
âœ“ ì•™ìƒë¸”: XGBoost + ë”¥ëŸ¬ë‹ ì¡°í•©

[ì „ì²˜ë¦¬ ì „ëµ]
âœ“ time_seconds ê¸°ì¤€ ì •ë ¬ í•„ìˆ˜
âœ“ player_id ê²°ì¸¡: íŠ¹ìˆ˜ í† í° (-1) ì²˜ë¦¬
âœ“ ì¢Œí‘œ ì´ìƒì¹˜: Clipping (0-105, 0-68)

[ê²€ì¦ ì „ëµ]
âœ“ Game-based Split: ê²½ê¸° ë‹¨ìœ„ë¡œ Train/Val ë¶„ë¦¬
âœ“ Time-based Split: ì‹œê°„ ìˆœì„œ ê³ ë ¤
âœ“ Cross Validation: 5-Fold ê¶Œì¥
""")

        self.log_insight("\n" + "=" * 80)
        self.log_insight("ğŸš€ ë‹¤ìŒ ë‹¨ê³„ (Next Steps)")
        self.log_insight("=" * 80)

        self.log_insight("""
Phase 2ì—ì„œ ë¶„ì„í•  ë‚´ìš©:
1. ì˜ˆì¸¡ ëŒ€ìƒ(ë§ˆì§€ë§‰ íŒ¨ìŠ¤) ìƒì„¸ ë¶„ì„
2. ì‹œì‘ ìœ„ì¹˜ â†’ ë„ì°© ìœ„ì¹˜ ê´€ê³„ì„±
3. ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ì¶”ì • (ë‹¨ìˆœ í‰ê·  ì˜ˆì¸¡)
4. ê²½ê¸°ì¥ ê³µê°„ ë¶„í¬ ë¶„ì„
""")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("  K-League Pass Prediction - EDA Phase 1")
    print("  ë°ì´í„° ê¸°ì´ˆ ì§„ë‹¨ ë° í’ˆì§ˆ ë¶„ì„")
    print("=" * 80)
    print()

    # Analyzer ì´ˆê¸°í™”
    analyzer = EDAAnalyzer(data_dir='./data')

    # Phase 1 ë¶„ì„ ì‹¤í–‰
    analyzer.load_data_structure()
    analyzer.analyze_data_quality()
    analyzer.analyze_basic_statistics()
    analyzer.generate_summary()

    # ì¸ì‚¬ì´íŠ¸ ì €ì¥
    analyzer.save_insights('EDA_Phase1_insights.txt')

    print("\n" + "=" * 80)
    print("âœ… Phase 1 ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    main()

