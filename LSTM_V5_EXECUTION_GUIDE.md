# ğŸš€ LSTM V5 ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì•™ìƒë¸” íŒŒì¼ ì œê±° ì™„ë£Œ](#ì•™ìƒë¸”-íŒŒì¼-ì œê±°-ì™„ë£Œ)
3. [ì‹¤í–‰ ìˆœì„œ](#ì‹¤í–‰-ìˆœì„œ)
4. [ì˜ˆìƒ ì„±ëŠ¥](#ì˜ˆìƒ-ì„±ëŠ¥)
5. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ê°œìš”

**ëª©í‘œ**: ìˆœìˆ˜ LSTM ë‹¨ì¼ ëª¨ë¸(Multi-Head Attention í¬í•¨)ë¡œ LightGBM (14.138m) ì„±ëŠ¥ ì´ˆê³¼

### ì£¼ìš” ê°œì„ ì‚¬í•­
âœ… **Multi-Head Attention** - ì¤‘ìš”í•œ ì‹œì ì— ì§‘ì¤‘  
âœ… **Padding Mask** - ì‹¤ì œ ë°ì´í„°ì™€ íŒ¨ë”© êµ¬ë¶„  
âœ… **Bidirectional RNN** - ì–‘ë°©í–¥ ì‹œí€€ìŠ¤ ì •ë³´ í™œìš©  
âœ… **ì „ì²´ í”¼ì²˜ ì •ê·œí™”** - í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ  
âœ… **ê¹Šì€ Output Head** - ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ  
âœ… **Residual Connection** - ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ê°œì„   
âœ… **5-Fold CV + TTA** - ì¼ë°˜í™” ì„±ëŠ¥ ê·¹ëŒ€í™”  

---

## ì•™ìƒë¸” íŒŒì¼ ì œê±° ì™„ë£Œ

ë‹¤ìŒ íŒŒì¼ë“¤ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤:

### Python íŒŒì¼
- `simple_ensemble.py`
- `ensemble_model.py`
- `ensemble_3models.py`
- `ensemble_v3_v4.py`
- `inference_ensemble.py`
- `create_ensemble.py`
- `inference_3models.py`
- `create_stacking_quickwin.py`
- `optimize_weights.py`

### ëª¨ë¸ íŒŒì¼
- `ensemble_model.pkl`
- `ensemble_3models.pkl`

---

## ì‹¤í–‰ ìˆœì„œ

### ğŸ”¹ Phase 1: ë‹¨ì¼ Fold í”„ë¡œí† íƒ€ì´í•‘ (ë¹ ë¥¸ ê²€ì¦)

```bash
# Colab ë˜ëŠ” GPU ì„œë²„ì—ì„œ ì‹¤í–‰
python train_lstm_v5_attention.py
```

**ëª©ì **: 
- ëª¨ë¸ êµ¬ì¡° ê²€ì¦
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¹ ë¥¸ íŠœë‹
- ì˜ˆìƒ ì„±ëŠ¥ í™•ì¸

**ì¶œë ¥**:
- `lstm_model_v5_attention_best.pth` (ë‹¨ì¼ Fold ëª¨ë¸)

**ì†Œìš” ì‹œê°„**: GPU ê¸°ì¤€ 30ë¶„~1ì‹œê°„

**ë‹¤ìŒ ë‹¨ê³„ ê²°ì •**:
- Val Loss < 14.0m â†’ Phase 2ë¡œ ì§„í–‰ âœ…
- Val Loss > 14.5m â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬ì¡°ì • í•„ìš” ğŸ“ˆ

---

### ğŸ”¹ Phase 2: 5-Fold ì „ì²´ í•™ìŠµ (ìµœì¢… ì„±ëŠ¥)

```bash
# GPU í•„ìˆ˜ (Colab Pro ë˜ëŠ” ë¡œì»¬ GPU)
python train_lstm_v5_5fold.py
```

**ëª©ì **:
- 5ê°œ Fold ëª¨ë‘ í•™ìŠµí•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ ê·¹ëŒ€í™”
- ê° Foldë³„ ìµœì  ëª¨ë¸ ì €ì¥

**ì¶œë ¥**:
- `lstm_model_v5_fold0.pth`
- `lstm_model_v5_fold1.pth`
- `lstm_model_v5_fold2.pth`
- `lstm_model_v5_fold3.pth`
- `lstm_model_v5_fold4.pth`

**ì†Œìš” ì‹œê°„**: GPU ê¸°ì¤€ 3~5ì‹œê°„

**í™•ì¸ ì‚¬í•­**:
```
Foldë³„ Val Loss:
   Fold 1: 13.xxm
   Fold 2: 13.xxm
   Fold 3: 13.xxm
   Fold 4: 13.xxm
   Fold 5: 13.xxm

í‰ê· : 13.xxm Â± 0.xxm
```

---

### ğŸ”¹ Phase 3: 5-Fold ì•™ìƒë¸” + TTA ì¶”ë¡ 

```bash
# 5ê°œ ëª¨ë¸ì´ ëª¨ë‘ ì¤€ë¹„ëœ í›„ ì‹¤í–‰
python inference_lstm_v5_5fold.py
```

**ëª©ì **:
- 5ê°œ Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ í‰ê·  (ë‹¨ì¼ ëª¨ë¸ ì•™ìƒë¸”)
- Test Time Augmentation (ì¢Œìš° ë°˜ì „) ì ìš©
- ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±

**ì¶œë ¥**:
- `submission_lstm_v5_5fold_tta.csv`

**ì†Œìš” ì‹œê°„**: GPU ê¸°ì¤€ 10~20ë¶„

**ì˜ˆì¸¡ í†µê³„ í™•ì¸**:
```
end_x í†µê³„:
   - ìµœì†Œ: 10~20
   - ìµœëŒ€: 90~100
   - í‰ê· : 60~70
   - í‘œì¤€í¸ì°¨: 15~20

end_y í†µê³„:
   - ìµœì†Œ: 5~10
   - ìµœëŒ€: 60~65
   - í‰ê· : 30~35
   - í‘œì¤€í¸ì°¨: 15~20

Fold ê°„ ì˜ˆì¸¡ ë¶ˆì¼ì¹˜ (í‘œì¤€í¸ì°¨):
   - X ì¢Œí‘œ: < 1.0m âœ…
   - Y ì¢Œí‘œ: < 1.0m âœ…
```

---

### ğŸ”¹ (ì„ íƒ) ë‹¨ì¼ Fold ë¹ ë¥¸ ì¶”ë¡ 

Phase 1 ëª¨ë¸ë§Œìœ¼ë¡œ ë¹ ë¥´ê²Œ ì œì¶œí•˜ê³  ì‹¶ë‹¤ë©´:

```bash
python inference_lstm_v5_attention.py
```

**ì¶œë ¥**:
- `submission_lstm_v5_attention.csv`

---

## ì˜ˆìƒ ì„±ëŠ¥

### ê¸°ì¡´ ì„±ëŠ¥
| ëª¨ë¸ | Val Loss | Public LB | Private LB |
|------|----------|-----------|------------|
| LightGBM V4 | 1.5m | 14.138m | - |
| LSTM V4 (Baseline) | 14.7m | 15.649m | - |

### ëª©í‘œ ì„±ëŠ¥ (LSTM V5)

#### ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤ ğŸ‰
- **Val Loss**: 12.5m ~ 13.0m
- **Public LB**: 13.0m ~ 13.5m
- **ëª©í‘œ**: âœ… LightGBM ì´ˆê³¼

#### í˜„ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤ âœ…
- **Val Loss**: 13.5m ~ 14.0m
- **Public LB**: 14.0m ~ 14.5m
- **ëª©í‘œ**: âœ… LightGBM ê·¼ì ‘ ë˜ëŠ” ë™ë“±

#### ë³´ìˆ˜ì  ì‹œë‚˜ë¦¬ì˜¤ ğŸ“ˆ
- **Val Loss**: 14.0m ~ 14.5m
- **Public LB**: 14.5m ~ 15.0m
- **ì¶”ê°€ ì¡°ì¹˜**: Data Augmentation, í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬íŠœë‹

---

## ë¬¸ì œ í•´ê²°

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± (CUDA Out of Memory)

**ì¦ìƒ**:
```
RuntimeError: CUDA out of memory
```

**í•´ê²°ì±…**:
```python
# train_lstm_v5_attention.py ë˜ëŠ” train_lstm_v5_5fold.py ìˆ˜ì •

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
BATCH_SIZE = 32  # 64 â†’ 32ë¡œ ê°ì†Œ
HIDDEN_DIM = 256  # 384 â†’ 256ìœ¼ë¡œ ê°ì†Œ
NUM_LAYERS = 2    # 3 â†’ 2ë¡œ ê°ì†Œ
```

---

### 2. í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
```
Epoch 50: Train=16.5m, Val=16.8m (ê³„ì† ë†’ìŒ)
```

**í•´ê²°ì±…**:
1. **Learning Rate ì¡°ì •**
   ```python
   LEARNING_RATE = 1e-3  # 5e-4 â†’ 1e-3ìœ¼ë¡œ ì¦ê°€
   ```

2. **Dropout ê°ì†Œ**
   ```python
   DROPOUT = 0.2  # 0.4 â†’ 0.2ë¡œ ê°ì†Œ (Overfittingì´ ì•„ë‹Œ ê²½ìš°)
   ```

3. **ë°ì´í„° í™•ì¸**
   - `processed_train_data_v4.csv`ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
   - NaN ë¹„ìœ¨ í™•ì¸

---

### 3. Validation LossëŠ” ì¢‹ì€ë° Public LBê°€ ë‚˜ì¨

**ì¦ìƒ**:
- Val Loss: 13.5m
- Public LB: 16.0m (í° ì°¨ì´)

**ì›ì¸**:
- Train/Test ë¶„í¬ ë¶ˆì¼ì¹˜
- Overfitting

**í•´ê²°ì±…**:
1. **Dropout ì¦ê°€**
   ```python
   DROPOUT = 0.5  # 0.4 â†’ 0.5
   ```

2. **Weight Decay ì¦ê°€**
   ```python
   optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)
   ```

3. **Early Stopping ë” ì¼ì°**
   ```python
   EARLY_STOPPING_PATIENCE = 10  # 20 â†’ 10
   ```

---

### 4. Fold ê°„ ì„±ëŠ¥ ì°¨ì´ê°€ í¼

**ì¦ìƒ**:
```
Fold 1: 12.5m âœ…
Fold 2: 15.8m âŒ
Fold 3: 13.2m âœ…
Fold 4: 16.2m âŒ
Fold 5: 13.5m âœ…
```

**ì›ì¸**:
- íŠ¹ì • ê²Œì„ì´ í•™ìŠµí•˜ê¸° ì–´ë ¤ì›€
- ë°ì´í„° ë¶ˆê· í˜•

**í•´ê²°ì±…**:
1. **ë” ê¸´ í•™ìŠµ**
   ```python
   NUM_EPOCHS = 150  # 100 â†’ 150
   ```

2. **Learning Rate ê°ì†Œ**
   ```python
   LEARNING_RATE = 3e-4  # 5e-4 â†’ 3e-4
   ```

3. **ë¬¸ì œ Fold ì¬í•™ìŠµ**

---

### 5. ì¶”ë¡  ì‹œ ì¢Œí‘œê°€ ì´ìƒí•¨

**ì¦ìƒ**:
```
end_x í†µê³„:
   - ìµœì†Œ: -50.0  âŒ (ìŒìˆ˜)
   - ìµœëŒ€: 200.0  âŒ (í•„ë“œ ë²—ì–´ë‚¨)
```

**ì›ì¸**:
- ì •ê·œí™”/ì—­ì •ê·œí™” ì˜¤ë¥˜
- ëª¨ë¸ ì¶œë ¥ ë²”ìœ„ ë¬¸ì œ

**í•´ê²°ì±…**:
1. **Clipping ì¶”ê°€** (inference ì½”ë“œì—)
   ```python
   # ì˜ˆì¸¡ í›„ ë²”ìœ„ ì œí•œ
   predictions[:, 0] = np.clip(predictions[:, 0], 0, 105)
   predictions[:, 1] = np.clip(predictions[:, 1], 0, 68)
   ```

2. **ëª¨ë¸ ì¶œë ¥ì— Sigmoid ì¶”ê°€** (train ì½”ë“œì—)
   ```python
   # Output Head ë§ˆì§€ë§‰ì—
   nn.Linear(hidden_dim // 2, 2),
   nn.Sigmoid()  # 0~1 ë²”ìœ„ë¡œ ì œí•œ
   ```

---

## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ

### ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¡°ì • ë°©í–¥

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì¦ê°€ ì‹œ íš¨ê³¼ | ê°ì†Œ ì‹œ íš¨ê³¼ |
|---------|--------|-------------|-------------|
| `HIDDEN_DIM` | 384 | í‘œí˜„ë ¥â†‘, ë©”ëª¨ë¦¬â†‘ | ì†ë„â†‘, ì¼ë°˜í™”â†‘ |
| `NUM_LAYERS` | 3 | í‘œí˜„ë ¥â†‘, í•™ìŠµ ì–´ë ¤ì›€ | í•™ìŠµ ì•ˆì •â†‘ |
| `DROPOUT` | 0.4 | ì¼ë°˜í™”â†‘, Underfitting ìœ„í—˜ | Overfitting ìœ„í—˜â†‘ |
| `LEARNING_RATE` | 5e-4 | í•™ìŠµ ë¹ ë¦„, ë¶ˆì•ˆì • | í•™ìŠµ ëŠë¦¼, ì•ˆì • |
| `BATCH_SIZE` | 64 | ì¼ë°˜í™”â†‘, ë©”ëª¨ë¦¬â†‘ | ë…¸ì´ì¦ˆâ†‘, í•™ìŠµ ë¹ ë¦„ |
| `NUM_HEADS` | 8 | Attention ì„¸ë°€í•¨â†‘ | ê³„ì‚° ë¹ ë¦„ |

### ì¶”ì²œ ì‹¤í—˜ ì¡°í•©

#### ì‹¤í—˜ A: ë” í° ëª¨ë¸
```python
HIDDEN_DIM = 512
NUM_LAYERS = 4
BATCH_SIZE = 32  # ë©”ëª¨ë¦¬ ê³ ë ¤
DROPOUT = 0.5    # Overfitting ë°©ì§€
```

#### ì‹¤í—˜ B: í•™ìŠµ ì•ˆì •ì„± ìš°ì„ 
```python
HIDDEN_DIM = 256
NUM_LAYERS = 2
DROPOUT = 0.3
LEARNING_RATE = 1e-3
```

#### ì‹¤í—˜ C: Attention ê°•í™”
```python
NUM_HEADS = 16       # 8 â†’ 16
HIDDEN_DIM = 512     # 16ì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•™ìŠµ ì „
- [ ] `processed_train_data_v4.csv` ì¡´ì¬ í™•ì¸
- [ ] GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸ (`nvidia-smi`)
- [ ] ë””ìŠ¤í¬ ê³µê°„ ì¶©ë¶„ (5-Fold: ~5GB í•„ìš”)
- [ ] ì•™ìƒë¸” ê´€ë ¨ íŒŒì¼ ëª¨ë‘ ì‚­ì œë¨

### í•™ìŠµ ì¤‘
- [ ] Train Lossê°€ ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸
- [ ] Val Lossê°€ Train Lossë¥¼ ë”°ë¼ê°€ëŠ”ì§€ í™•ì¸
- [ ] Early Stoppingì´ ë„ˆë¬´ ì¼ì° ë°œë™í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸

### ì¶”ë¡  ì „
- [ ] `processed_test_data_v4.csv` ì¡´ì¬ í™•ì¸
- [ ] ëª¨ë“  Fold ëª¨ë¸ íŒŒì¼ ì¡´ì¬ (5-Foldì˜ ê²½ìš°)
- [ ] ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ í™•ì¸

### ì œì¶œ ì „
- [ ] `game_episode` ì»¬ëŸ¼ ëˆ„ë½ ì—†ëŠ”ì§€ í™•ì¸
- [ ] ì¢Œí‘œ ë²”ìœ„ ì •ìƒ (end_x: 0~105, end_y: 0~68)
- [ ] CSV í¬ë§· ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- [ ] ìƒ˜í”Œ ìˆ˜ ì¼ì¹˜ (Test ë°ì´í„°ì™€ ë™ì¼)

---

## ë‹¤ìŒ ë‹¨ê³„ (ì„±ëŠ¥ ë¯¸ë‹¬ ì‹œ)

LSTM V5ë¡œë„ LightGBMì„ ì´ˆê³¼í•˜ì§€ ëª»í–ˆë‹¤ë©´:

### 1. Data Augmentation ì¶”ê°€
- ì‹œí€€ìŠ¤ ì—­ìˆœ
- ì¢Œìš°/ìƒí•˜ ëŒ€ì¹­
- Gaussian Noise ì¶”ê°€
- Mixup

### 2. ë” ê³ ê¸‰ ëª¨ë¸ ì‹œë„
- **Transformer** (Self-Attentionë§Œ ì‚¬ìš©)
- **Temporal Convolutional Network** (TCN)
- **Hybrid Model** (CNN + RNN)

### 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¬ê²€í† 
- ëˆ„ì  ê±°ë¦¬, ë°©í–¥ ì „í™˜ ë¹ˆë„ ë“± ì¶”ê°€
- ì‹œê°„ ê°„ê²© íŒ¨í„´ í”¼ì²˜
- íŒ€ë³„/ì„ ìˆ˜ë³„ í†µê³„ í”¼ì²˜

### 4. ì „ì²˜ë¦¬ ë°©ì‹ ë³€ê²½
- Wide Format â†’ Long Format
- ì‹œí€€ìŠ¤ ê¸¸ì´ ë™ì  ì¡°ì •
- Attention Mask ê°œì„ 

---

## ì—°ë½ì²˜

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜:
1. ì—ëŸ¬ ë©”ì‹œì§€ ì „ì²´
2. ì‹¤í–‰ í™˜ê²½ (GPU ì¢…ë¥˜, ë©”ëª¨ë¦¬, Python ë²„ì „)
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
4. í•™ìŠµ ë¡œê·¸ (ë§ˆì§€ë§‰ 10 ì—í¬í¬)

---

**ì‘ì„±ì¼**: 2025-12-19  
**ë²„ì „**: V5.0  
**ëª©í‘œ**: ğŸ¯ LightGBM (14.138m) ì´ˆê³¼!

