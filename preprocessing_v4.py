"""
K-League Pass Prediction - Data Preprocessing Pipeline V4

V2 + V3ì˜ í•µì‹¬ ê°œì„ ì‚¬í•­ í†µí•©:
âœ… Data Leakage ì™„ì „ ì œê±° - ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ end_x, end_y ë§ˆìŠ¤í‚¹
âœ… ì‹œí€€ìŠ¤ ëª¨ë¸ë§ - ë§ˆì§€ë§‰ 20ê°œ ì´ë²¤íŠ¸ì˜ íŒ¨í„´ í•™ìŠµ (Wide format)
âœ… Train/Test í†µí•© ì²˜ë¦¬ - ì¼ê´€ëœ ë²”ì£¼í˜• ì¸ì½”ë”©
âœ… V2ì˜ í’ë¶€í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ë¹„ì„ í˜• ë³€í™˜, ìœ„ì¹˜ íŠ¹í™”, ì»¨í…ìŠ¤íŠ¸)
âœ… 5-Fold GroupKFold ì•™ìƒë¸”

ëª©í‘œ: V2ì˜ ë„ë©”ì¸ ì§€ì‹ + V3ì˜ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ = ìµœê³  ì„±ëŠ¥
ì‘ì„±ì¼: 2025-12-17
"""

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GroupKFold
from scipy.spatial.distance import cdist
import pickle
import warnings
warnings.filterwarnings('ignore')


class DataPreprocessorV4:
    def __init__(self, data_dir='./data', K=20):
        """
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            K: ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ ì‚¬ìš© (ê¸°ë³¸ 20)
        """
        self.data_dir = data_dir
        self.K = K
        self.type_encoder = LabelEncoder()
        self.result_encoder = LabelEncoder()

        # ì„ ìˆ˜/íŒ€ í†µê³„ ì €ì¥
        self.player_stats = None
        self.team_stats = None

    def load_data(self, verbose=True):
        """ë°ì´í„° ë¡œë”© (Train + Test í†µí•©)"""
        if verbose:
            print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")

        # Train ë°ì´í„°
        train_path = os.path.join(self.data_dir, 'train.csv')
        train_data = pd.read_csv(train_path)
        train_data['is_train'] = 1

        # Test ë°ì´í„° (test_index.csv ì‚¬ìš©)
        test_index_path = os.path.join(self.data_dir, 'test_index.csv')
        test_index = pd.read_csv(test_index_path)

        test_events_list = []
        for _, row in test_index.iterrows():
            ep_path = os.path.join(self.data_dir, row['path'].replace('./', ''))
            df_ep = pd.read_csv(ep_path)
            test_events_list.append(df_ep)

        test_events = pd.concat(test_events_list, ignore_index=True)
        test_events['is_train'] = 0

        # Train + Test ê²°í•©
        data = pd.concat([train_data, test_events], ignore_index=True)

        if verbose:
            print(f"âœ… Train: {len(train_data):,} ì´ë²¤íŠ¸, {train_data['game_episode'].nunique():,} ì—í”¼ì†Œë“œ")
            print(f"âœ… Test: {len(test_events):,} ì´ë²¤íŠ¸, {test_events['game_episode'].nunique():,} ì—í”¼ì†Œë“œ\n")

        return data

    def sort_and_index(self, data, verbose=True):
        """ì‹œê°„ ì •ë ¬ ë° ì¸ë±ì‹±"""
        if verbose:
            print("â° ì‹œê°„ ì •ë ¬ ë° ì¸ë±ì‹±...")

        # ì •ë ¬
        data = data.sort_values(['game_episode', 'time_seconds', 'action_id']).reset_index(drop=True)

        # ì—í”¼ì†Œë“œ ë‚´ ì¸ë±ìŠ¤
        data['event_idx'] = data.groupby('game_episode').cumcount()
        data['n_events'] = data.groupby('game_episode')['event_idx'].transform('max') + 1
        data['ep_idx_norm'] = data['event_idx'] / (data['n_events'] - 1).clip(lower=1)

        # ì—­ì¸ë±ìŠ¤ (0ì´ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸)
        data['rev_idx'] = data.groupby('game_episode')['event_idx'].transform(
            lambda s: s.max() - s
        )

        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ í”Œë˜ê·¸
        data['last_idx'] = data.groupby('game_episode')['event_idx'].transform('max')
        data['is_last'] = (data['event_idx'] == data['last_idx']).astype(int)

        if verbose:
            print("âœ… ì •ë ¬ ë° ì¸ë±ì‹± ì™„ë£Œ\n")

        return data

    def create_basic_features(self, data, verbose=True):
        """ê¸°ë³¸ í”¼ì²˜ ìƒì„± (V2 ê¸°ë°˜)"""
        if verbose:
            print("ğŸ”§ ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì¤‘...")

        # ì‹œê°„ ì°¨ì´
        data['prev_time'] = data.groupby('game_episode')['time_seconds'].shift(1)
        data['dt'] = data['time_seconds'] - data['prev_time']
        data['dt'] = data['dt'].fillna(0.0)

        # ì´ë™ëŸ‰/ê±°ë¦¬
        data['dx'] = data['end_x'] - data['start_x']
        data['dy'] = data['end_y'] - data['start_y']
        data['dist'] = np.sqrt(data['dx']**2 + data['dy']**2)

        # ì†ë„ (dt=0 ë³´í˜¸)
        data['speed'] = data['dist'] / data['dt'].replace(0, 1e-3)

        # Zone ë¶„í• 
        data['x_zone'] = (data['start_x'] / (105/7)).astype(int).clip(0, 6)
        data['lane'] = pd.cut(
            data['start_y'],
            bins=[0, 68/3, 2*68/3, 68],
            labels=[0, 1, 2],
            include_lowest=True
        ).astype(int)

        # ê³¨ë¬¸ ê±°ë¦¬ (ì˜¤ë¥¸ìª½ ê³¨ë¬¸: 105, 34)
        goal_x, goal_y = 105, 34
        data['distance_to_goal_start'] = np.sqrt(
            (data['start_x'] - goal_x)**2 +
            (data['start_y'] - goal_y)**2
        )
        data['distance_to_goal_end'] = np.sqrt(
            (data['end_x'] - goal_x)**2 +
            (data['end_y'] - goal_y)**2
        )

        # ê³¨ë¬¸ ì§„í–‰ë„
        data['goal_approach'] = data['distance_to_goal_start'] - data['distance_to_goal_end']

        # í˜ë„í‹° ë°•ìŠ¤
        data['in_penalty_area'] = ((data['start_x'] > 87.5) &
                                   (data['start_y'] > 22.9) &
                                   (data['start_y'] < 45.1)).astype(int)

        # Final third
        data['in_final_third'] = (data['start_x'] > 70).astype(int)

        # ê³¨ ê°ë„
        post_left_y = 30.34
        post_right_y = 37.66

        vec_left_x = goal_x - data['start_x']
        vec_left_y = post_left_y - data['start_y']
        vec_right_x = goal_x - data['start_x']
        vec_right_y = post_right_y - data['start_y']

        dot_product = vec_left_x * vec_right_x + vec_left_y * vec_right_y
        cross_product = vec_left_x * vec_right_y - vec_left_y * vec_right_x

        data['shooting_angle'] = np.abs(np.arctan2(cross_product, dot_product))

        # ê²½ê¸° ì‹œê°„ (ë¶„)
        data['game_clock_min'] = np.where(
            data['period_id'] == 1,
            data['time_seconds'] / 60.0,
            45.0 + data['time_seconds'] / 60.0
        )

        if verbose:
            print("âœ… ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_nonlinear_features(self, data, verbose=True):
        """ğŸ”¥ ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ ìƒì„± (V2)"""
        if verbose:
            print("ğŸ”¥ ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ê³¨ë¬¸ ê±°ë¦¬ ì—­ìˆ˜
        data['distance_to_goal_inv'] = 1 / (data['distance_to_goal_start'] + 1)

        # 2. ê³¨ë¬¸ ê±°ë¦¬ ì œê³±ê·¼
        data['distance_to_goal_sqrt'] = np.sqrt(data['distance_to_goal_start'])

        # 3. ê°ë„ì˜ ì‚¼ê°í•¨ìˆ˜
        data['shooting_angle_sin'] = np.sin(data['shooting_angle'])
        data['shooting_angle_cos'] = np.cos(data['shooting_angle'])

        # 4. ìœ„ì¹˜ì˜ ì œê³±
        data['start_x_squared'] = data['start_x'] ** 2
        data['start_y_squared'] = data['start_y'] ** 2

        # 5. ìƒí˜¸ì‘ìš© í”¼ì²˜
        data['x_y_interaction'] = data['start_x'] * data['start_y']
        data['goal_dist_angle_interaction'] = data['distance_to_goal_start'] * data['shooting_angle']

        if verbose:
            print(f"âœ… ë¹„ì„ í˜• í”¼ì²˜ 8ê°œ ìƒì„± ì™„ë£Œ\n")

        return data

    def create_position_specific_features(self, data, verbose=True):
        """ğŸ¯ ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ (V2)"""
        if verbose:
            print("ğŸ¯ ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ ìƒì„± ì¤‘...")

        # 1. ìˆ˜ë¹„ì§„ íŠ¹í™”
        data['is_defensive_third'] = (data['start_x'] < 35).astype(int)

        # 2. ê³µê²©ì§„ íŠ¹í™” - ê³¨ ê¸´ê¸‰ë„
        data['goal_urgency'] = np.exp(-data['distance_to_goal_start'] / 20)

        # 3. Yì¶• ì¤‘ì•™ ë³µë„
        data['is_central_corridor'] = ((data['start_y'] > 20) &
                                       (data['start_y'] < 48)).astype(int)

        # 4. ê³¨ë¬¸ ê·¼ì ‘ë„
        data['near_goal_zone'] = ((data['distance_to_goal_start'] < 25) &
                                  (data['start_x'] > 80)).astype(int)

        # 5. ì‚¬ì´ë“œ ê³µê²©
        data['is_wing_attack'] = ((data['start_x'] > 70) &
                                  ((data['start_y'] < 15) | (data['start_y'] > 53))).astype(int)

        # 6. ì¤‘ì› ì§€ë°° ì˜ì—­
        data['is_midfield_control'] = ((data['start_x'] >= 35) &
                                       (data['start_x'] <= 70) &
                                       (data['start_y'] >= 20) &
                                       (data['start_y'] <= 48)).astype(int)

        if verbose:
            print(f"âœ… ìœ„ì¹˜ íŠ¹í™” í”¼ì²˜ 6ê°œ ìƒì„± ì™„ë£Œ\n")

        return data

    def extract_labels(self, data, verbose=True):
        """ğŸ¯ íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ (Train ì „ìš©)"""
        if verbose:
            print("ğŸ¯ íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ ì¤‘...")

        # Train ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
        train_events = data[data['is_train'] == 1].copy()
        last_events = train_events[train_events['is_last'] == 1].copy()

        labels = last_events[['game_episode', 'end_x', 'end_y']].rename(
            columns={'end_x': 'target_x', 'end_y': 'target_y'}
        )

        # Episode ë©”íƒ€ ì •ë³´
        ep_meta = last_events[['game_episode', 'game_id', 'team_id', 'is_home',
                               'period_id', 'time_seconds', 'game_clock_min']].copy()
        ep_meta = ep_meta.rename(columns={'team_id': 'final_team_id'})

        if verbose:
            print(f"âœ… {len(labels):,}ê°œ Train ì—í”¼ì†Œë“œì˜ íƒ€ê²Ÿ ì¶”ì¶œ ì™„ë£Œ\n")

        return labels, ep_meta

    def add_final_team_flag(self, data, ep_meta, verbose=True):
        """ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€"""
        if verbose:
            print("âš½ ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€ ì¤‘...")

        data = data.merge(
            ep_meta[['game_episode', 'final_team_id']],
            on='game_episode',
            how='left'
        )

        data['is_final_team'] = (data['team_id'] == data['final_team_id']).astype(int)

        if verbose:
            print("âœ… ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€ ì™„ë£Œ\n")

        return data

    def mask_target_leakage(self, data, verbose=True):
        """ğŸš¨ Data Leakage ì œê±° (V3 í•µì‹¬)"""
        if verbose:
            print("ğŸš¨ Data Leakage ì œê±° ì¤‘...")

        mask_last = data['is_last'] == 1

        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ end ì •ë³´ ì œê±°
        leakage_cols = ['end_x', 'end_y', 'dx', 'dy', 'dist', 'speed',
                       'distance_to_goal_end', 'goal_approach']
        for col in leakage_cols:
            if col in data.columns:
                data.loc[mask_last, col] = np.nan

        if verbose:
            print(f"âœ… {len(leakage_cols)}ê°œ ì»¬ëŸ¼ì˜ Leakage ì œê±° ì™„ë£Œ")
            print("   â†’ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ end ì •ë³´ NaN ì²˜ë¦¬\n")

        return data

    def encode_categorical(self, data, verbose=True):
        """ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"""
        if verbose:
            print("ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...")

        # type_name ì¸ì½”ë”©
        data['type_name'] = data['type_name'].fillna('__NA_TYPE__')
        data['type_id'] = self.type_encoder.fit_transform(data['type_name'])

        # result_name ì¸ì½”ë”©
        data['result_name'] = data['result_name'].fillna('__NA_RES__')
        data['res_id'] = self.result_encoder.fit_transform(data['result_name'])

        # team_id ì¸ì½”ë”© (ë¬¸ìì—´ì¸ ê²½ìš°)
        if data['team_id'].dtype == 'object':
            le_team = LabelEncoder()
            data['team_id_enc'] = le_team.fit_transform(data['team_id'])
        else:
            data['team_id_enc'] = data['team_id'].astype(int)

        if verbose:
            print("âœ… ì¸ì½”ë”© ì™„ë£Œ\n")

        return data

    def filter_last_k_events(self, data, verbose=True):
        """ğŸ¯ ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§ (V3 í•µì‹¬)"""
        if verbose:
            print(f"ğŸ¯ ë§ˆì§€ë§‰ {self.K}ê°œ ì´ë²¤íŠ¸ í•„í„°ë§ ì¤‘...")

        lastK = data[data['rev_idx'] < self.K].copy()

        # pos_in_K: 0~(K-1), ì•ìª½ íŒ¨ë”© ê³ ë ¤
        def assign_pos_in_K(df):
            df = df.sort_values('event_idx')
            L = len(df)
            df = df.copy()
            df['pos_in_K'] = np.arange(self.K - L, self.K)
            return df

        lastK = lastK.groupby('game_episode', group_keys=False).apply(assign_pos_in_K)

        if verbose:
            print(f"âœ… {len(lastK):,}ê°œ ì´ë²¤íŠ¸ í•„í„°ë§ ì™„ë£Œ\n")

        return lastK

    def create_wide_features(self, lastK, ep_meta, labels, verbose=True):
        """ğŸŒ Wide format í”¼ì²˜ ìƒì„± (V3 í•µì‹¬)"""
        if verbose:
            print("ğŸŒ Wide format í”¼ì²˜ ìƒì„± ì¤‘...")

        # ì‚¬ìš©í•  ì´ë²¤íŠ¸ í”¼ì²˜
        num_cols = [
            'start_x', 'start_y',
            'end_x', 'end_y',
            'dx', 'dy', 'dist', 'speed',
            'dt',
            'ep_idx_norm',
            'x_zone', 'lane',
            'is_final_team',
            'distance_to_goal_start',
            'distance_to_goal_end',
            'goal_approach',
            'in_penalty_area',
            'in_final_third',
            'shooting_angle',
            'distance_to_goal_inv',
            'distance_to_goal_sqrt',
            'shooting_angle_sin',
            'shooting_angle_cos',
            'start_x_squared',
            'start_y_squared',
            'x_y_interaction',
            'goal_dist_angle_interaction',
            'is_defensive_third',
            'goal_urgency',
            'is_central_corridor',
            'near_goal_zone',
            'is_wing_attack',
            'is_midfield_control',
        ]

        cat_cols = [
            'type_id',
            'res_id',
            'team_id_enc',
            'is_home',
            'period_id',
            'is_last',
        ]

        feature_cols = num_cols + cat_cols

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        num_cols = [c for c in num_cols if c in lastK.columns]
        cat_cols = [c for c in cat_cols if c in lastK.columns]
        feature_cols = num_cols + cat_cols

        wide = lastK[['game_episode', 'pos_in_K'] + feature_cols].copy()

        # ìˆ«ìí˜• pivot
        wide_num = wide.pivot_table(
            index='game_episode',
            columns='pos_in_K',
            values=num_cols,
            aggfunc='first'
        )

        # ë²”ì£¼í˜• pivot
        wide_cat = wide.pivot_table(
            index='game_episode',
            columns='pos_in_K',
            values=cat_cols,
            aggfunc='first'
        )

        # ì»¬ëŸ¼ ì´ë¦„ í‰íƒ„í™”
        wide_num.columns = [f"{c}_{int(pos)}" for (c, pos) in wide_num.columns]
        wide_cat.columns = [f"{c}_{int(pos)}" for (c, pos) in wide_cat.columns]

        X = pd.concat([wide_num, wide_cat], axis=1).reset_index()

        # Episode-level ë©”íƒ€ ë¶™ì´ê¸°
        X = X.merge(
            ep_meta[['game_episode', 'game_id', 'game_clock_min', 'final_team_id', 'is_home', 'period_id']],
            on='game_episode',
            how='left'
        )

        # Train ë¼ë²¨ ë¶™ì´ê¸°
        X = X.merge(labels, on='game_episode', how='left')

        if verbose:
            print(f"âœ… Wide format í”¼ì²˜ ìƒì„± ì™„ë£Œ")
            print(f"   - í”¼ì²˜ ì°¨ì›: {X.shape[1] - 4} (episode, game_id, target ì œì™¸)\n")

        return X

    def split_train_test(self, X, verbose=True):
        """Train/Test ë¶„ë¦¬"""
        if verbose:
            print("ğŸ“Š Train/Test ë¶„ë¦¬ ì¤‘...")

        # Train: targetì´ ìˆëŠ” ë°ì´í„°
        train_mask = X['target_x'].notna()
        X_train = X[train_mask].copy()
        X_test = X[~train_mask].copy()

        if verbose:
            print(f"âœ… Train: {len(X_train):,}, Test: {len(X_test):,}\n")

        return X_train, X_test

    def preprocess_pipeline(self, verbose=True):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V4"""
        print("=" * 80)
        print("  K-League Pass Prediction - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V4")
        print("  V2 í”¼ì²˜ + V3 ì‹œí€€ìŠ¤ ëª¨ë¸ë§ = ìµœê³  ì„±ëŠ¥")
        print("=" * 80)
        print()

        # 1. ë°ì´í„° ë¡œë”© (Train + Test)
        data = self.load_data(verbose=verbose)

        # 2. ì •ë ¬ ë° ì¸ë±ì‹±
        data = self.sort_and_index(data, verbose=verbose)

        # 3. ê¸°ë³¸ í”¼ì²˜
        data = self.create_basic_features(data, verbose=verbose)

        # 4. ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ (V2)
        data = self.create_nonlinear_features(data, verbose=verbose)

        # 5. ìœ„ì¹˜ë³„ íŠ¹í™” í”¼ì²˜ (V2)
        data = self.create_position_specific_features(data, verbose=verbose)

        # 6. íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ
        labels, ep_meta = self.extract_labels(data, verbose=verbose)

        # 7. ê³µê²© íŒ€ í”Œë˜ê·¸
        data = self.add_final_team_flag(data, ep_meta, verbose=verbose)

        # 8. ğŸš¨ Data Leakage ì œê±° (V3 í•µì‹¬)
        data = self.mask_target_leakage(data, verbose=verbose)

        # 9. ë²”ì£¼í˜• ì¸ì½”ë”©
        data = self.encode_categorical(data, verbose=verbose)

        # 10. ğŸ¯ ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ í•„í„°ë§ (V3 í•µì‹¬)
        lastK = self.filter_last_k_events(data, verbose=verbose)

        # 11. ğŸŒ Wide format í”¼ì²˜ ìƒì„± (V3 í•µì‹¬)
        X = self.create_wide_features(lastK, ep_meta, labels, verbose=verbose)

        # 12. Train/Test ë¶„ë¦¬
        X_train, X_test = self.split_train_test(X, verbose=verbose)

        print("=" * 80)
        print("âœ… ì „ì²˜ë¦¬ V4 ì™„ë£Œ!")
        print(f"ğŸ“Š Train Shape: {X_train.shape}")
        print(f"ğŸ“Š Test Shape: {X_test.shape}")
        print(f"ğŸ“Š ì´ í”¼ì²˜ ê°œìˆ˜: {X_train.shape[1] - 4}ê°œ")
        print("=" * 80)

        return X_train, X_test

    def save_preprocessor(self, filename='preprocessor_v4.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'type_encoder': self.type_encoder,
                'result_encoder': self.result_encoder,
                'K': self.K
            }, f)
        print(f"âœ… Preprocessor V4 ì €ì¥: {filename}")

    def load_preprocessor(self, filename='preprocessor_v4.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ë¡œë”©"""
        with open(filename, 'rb') as f:
            saved = pickle.load(f)
            self.type_encoder = saved['type_encoder']
            self.result_encoder = saved['result_encoder']
            self.K = saved['K']
        print(f"âœ… Preprocessor V4 ë¡œë”©: {filename}")


def main():
    """V4 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    preprocessor = DataPreprocessorV4(data_dir='./data', K=20)

    # ì „ì²˜ë¦¬ ì‹¤í–‰
    X_train, X_test = preprocessor.preprocess_pipeline(verbose=True)

    # ë°ì´í„° ì €ì¥
    X_train.to_csv('processed_train_data_v4.csv', index=False)
    X_test.to_csv('processed_test_data_v4.csv', index=False)

    print(f"\nâœ… ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥:")
    print(f"   - processed_train_data_v4.csv")
    print(f"   - processed_test_data_v4.csv")

    # Preprocessor ì €ì¥
    preprocessor.save_preprocessor('preprocessor_v4.pkl')

    # ê°œì„  ì‚¬í•­ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“ˆ V4 ê°œì„  ì‚¬í•­ ìš”ì•½")
    print("=" * 80)
    print("âœ… V2ì˜ ë„ë©”ì¸ ì§€ì‹ í”¼ì²˜:")
    print("   - ë¹„ì„ í˜• ë³€í™˜ í”¼ì²˜ 8ê°œ")
    print("   - ìœ„ì¹˜ íŠ¹í™” í”¼ì²˜ 6ê°œ")
    print("   - ê³¨ ê´€ë ¨ ê³ ê¸‰ í”¼ì²˜")
    print("\nâœ… V3ì˜ ì‹œí€€ìŠ¤ ëª¨ë¸ë§:")
    print("   - ë§ˆì§€ë§‰ 20ê°œ ì´ë²¤íŠ¸ ì‚¬ìš©")
    print("   - Wide format (ì‹œê°„ ìˆœì„œ ë³´ì¡´)")
    print("   - Data Leakage ì™„ì „ ì œê±°")
    print("   - Train/Test í†µí•© ì²˜ë¦¬")
    print("\nğŸ¯ ê¸°ëŒ€ íš¨ê³¼:")
    print("   - V2ì˜ í’ë¶€í•œ ë„ë©”ì¸ ì§€ì‹")
    print("   - V3ì˜ ì•ˆì •ì ì¸ ì¼ë°˜í™” ì„±ëŠ¥")
    print("   - ì˜ˆìƒ Test ì„±ëŠ¥: 14~16ì ëŒ€")
    print("=" * 80)

    return X_train, X_test, preprocessor


if __name__ == "__main__":
    X_train, X_test, preprocessor = main()

