"""
K-League Pass Prediction - Data Preprocessing Pipeline V3

í•µì‹¬ ê°œì„ ì‚¬í•­:
1. âœ… Data Leakage ì œê±° (end_x, end_y ì œê±°)
2. âœ… ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ë„ì… (ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸, Wide format)
3. âœ… ë‹¤ë¥¸ ì‚¬ëŒì˜ ìš°ìˆ˜ ë°©ì‹ ì±„íƒ
4. âœ… 5-Fold GroupKFold ì§€ì›

ëª©í‘œ: Test ì„±ëŠ¥ 16ì ëŒ€ ì´í•˜
ì‘ì„±ì¼: 2025-12-16
"""

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GroupKFold
import pickle
import warnings
warnings.filterwarnings('ignore')


class DataPreprocessorV3:
    def __init__(self, data_dir='./data', K=20):
        """
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            K: ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ ì‚¬ìš© (ê¸°ë³¸ 20)
        """
        self.data_dir = data_dir
        self.K = K
        self.type_encoder = LabelEncoder()
        self.result_encoder = LabelEncoder()
        self.team_encoder = LabelEncoder()

    def load_data(self, verbose=True):
        """ë°ì´í„° ë¡œë”© (Train + Test í†µí•©)"""
        if verbose:
            print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")

        # Train ë°ì´í„°
        train_path = os.path.join(self.data_dir, 'train.csv')
        train_data = pd.read_csv(train_path)
        train_data['is_train'] = 1

        # Test ë°ì´í„° (test_index.csv ì‚¬ìš©)
        test_index_path = os.path.join(self.data_dir, 'test_index.csv')
        test_index = pd.read_csv(test_index_path)

        test_events_list = []
        for _, row in test_index.iterrows():
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            ep_path = os.path.join(self.data_dir, row['path'].replace('./', ''))
            df_ep = pd.read_csv(ep_path)
            test_events_list.append(df_ep)

        test_events = pd.concat(test_events_list, ignore_index=True)
        test_events['is_train'] = 0

        # Train + Test ê²°í•©
        data = pd.concat([train_data, test_events], ignore_index=True)

        if verbose:
            print(f"âœ… Train: {len(train_data):,} ì´ë²¤íŠ¸, {train_data['game_episode'].nunique():,} ì—í”¼ì†Œë“œ")
            print(f"âœ… Test: {len(test_events):,} ì´ë²¤íŠ¸, {test_events['game_episode'].nunique():,} ì—í”¼ì†Œë“œ\n")

        return data

    def sort_and_index(self, data, verbose=True):
        """ì‹œê°„ ì •ë ¬ ë° ì¸ë±ì‹±"""
        if verbose:
            print("â° ì‹œê°„ ì •ë ¬ ë° ì¸ë±ì‹±...")

        # ì •ë ¬
        data = data.sort_values(['game_episode', 'time_seconds', 'action_id']).reset_index(drop=True)

        # ì—í”¼ì†Œë“œ ë‚´ ì¸ë±ìŠ¤
        data['event_idx'] = data.groupby('game_episode').cumcount()
        data['n_events'] = data.groupby('game_episode')['event_idx'].transform('max') + 1
        data['ep_idx_norm'] = data['event_idx'] / (data['n_events'] - 1).clip(lower=1)

        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ í”Œë˜ê·¸
        data['last_idx'] = data.groupby('game_episode')['event_idx'].transform('max')
        data['is_last'] = (data['event_idx'] == data['last_idx']).astype(int)

        if verbose:
            print("âœ… ì •ë ¬ ë° ì¸ë±ì‹± ì™„ë£Œ\n")

        return data

    def create_basic_features(self, data, verbose=True):
        """ê¸°ë³¸ í”¼ì²˜ ìƒì„±"""
        if verbose:
            print("ğŸ”§ ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì¤‘...")

        # ì‹œê°„ ì°¨ì´
        data['prev_time'] = data.groupby('game_episode')['time_seconds'].shift(1)
        data['dt'] = data['time_seconds'] - data['prev_time']
        data['dt'] = data['dt'].fillna(0.0)

        # ì´ë™ëŸ‰/ê±°ë¦¬
        data['dx'] = data['end_x'] - data['start_x']
        data['dy'] = data['end_y'] - data['start_y']
        data['dist'] = np.sqrt(data['dx']**2 + data['dy']**2)

        # ì†ë„
        data['speed'] = data['dist'] / data['dt'].replace(0, 1e-3)

        # Zone ë¶„í• 
        data['x_zone'] = (data['start_x'] / (105/7)).astype(int).clip(0, 6)
        data['lane'] = pd.cut(
            data['start_y'],
            bins=[0, 68/3, 2*68/3, 68],
            labels=[0, 1, 2],
            include_lowest=True
        ).astype(int)

        # ê³¨ë¬¸ ê±°ë¦¬
        goal_x, goal_y = 105, 34
        data['distance_to_goal_start'] = np.sqrt(
            (data['start_x'] - goal_x)**2 +
            (data['start_y'] - goal_y)**2
        )

        # í˜ë„í‹° ë°•ìŠ¤
        data['in_penalty_area'] = ((data['start_x'] > 87.5) &
                                   (data['start_y'] > 22.9) &
                                   (data['start_y'] < 45.1)).astype(int)

        # Final third
        data['in_final_third'] = (data['start_x'] > 70).astype(int)

        # ê²½ê¸° ì‹œê°„ (ë¶„)
        data['game_clock_min'] = np.where(
            data['period_id'] == 1,
            data['time_seconds'] / 60.0,
            45.0 + data['time_seconds'] / 60.0
        )

        if verbose:
            print("âœ… ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n")

        return data

    def extract_labels(self, data, verbose=True):
        """ğŸ¯ íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ (Train ì „ìš©)"""
        if verbose:
            print("ğŸ¯ íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ ì¤‘...")

        # Train ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
        train_events = data[data['is_train'] == 1].copy()
        last_events = train_events[train_events['is_last'] == 1].copy()

        labels = last_events[['game_episode', 'end_x', 'end_y']].rename(
            columns={'end_x': 'target_x', 'end_y': 'target_y'}
        )

        # Episode ë©”íƒ€ ì •ë³´
        ep_meta = last_events[['game_episode', 'game_id', 'team_id', 'is_home',
                               'period_id', 'time_seconds', 'game_clock_min']].copy()
        ep_meta = ep_meta.rename(columns={'team_id': 'final_team_id'})

        if verbose:
            print(f"âœ… {len(labels):,}ê°œ Train ì—í”¼ì†Œë“œì˜ íƒ€ê²Ÿ ì¶”ì¶œ ì™„ë£Œ\n")

        return labels, ep_meta

    def add_final_team_flag(self, data, ep_meta, verbose=True):
        """ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€"""
        if verbose:
            print("âš½ ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€ ì¤‘...")

        data = data.merge(
            ep_meta[['game_episode', 'final_team_id']],
            on='game_episode',
            how='left'
        )

        data['is_final_team'] = (data['team_id'] == data['final_team_id']).astype(int)

        if verbose:
            print("âœ… ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€ ì™„ë£Œ\n")

        return data

    def mask_target_leakage(self, data, verbose=True):
        """ğŸš¨ Data Leakage ì œê±°"""
        if verbose:
            print("ğŸš¨ Data Leakage ì œê±° ì¤‘...")

        mask_last = data['is_last'] == 1

        leakage_cols = ['end_x', 'end_y', 'dx', 'dy', 'dist', 'speed']
        for col in leakage_cols:
            if col in data.columns:
                data.loc[mask_last, col] = np.nan

        if verbose:
            print(f"âœ… {len(leakage_cols)}ê°œ ì»¬ëŸ¼ì˜ Leakage ì œê±° ì™„ë£Œ")
            print("   â†’ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ end_x, end_y ë“± NaN ì²˜ë¦¬\n")

        return data

    def encode_categorical(self, data, verbose=True):
        """ë²”ì£¼í˜• ì¸ì½”ë”©"""
        if verbose:
            print("ğŸ”¤ ë²”ì£¼í˜• ì¸ì½”ë”© ì¤‘...")

        data['type_name'] = data['type_name'].fillna('__NA_TYPE__')
        data['type_id'] = self.type_encoder.fit_transform(data['type_name'])

        data['result_name'] = data['result_name'].fillna('__NA_RES__')
        data['res_id'] = self.result_encoder.fit_transform(data['result_name'])

        if data['team_id'].dtype == 'object':
            data['team_id_enc'] = self.team_encoder.fit_transform(data['team_id'])
        else:
            data['team_id_enc'] = data['team_id'].astype(int)

        if verbose:
            print("âœ… ë²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ\n")

        return data

    def create_lastK_wide_features(self, data, verbose=True):
        """ğŸ”¥ í•µì‹¬: ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ Wide format ë³€í™˜"""
        if verbose:
            print(f"ğŸ”¥ ë§ˆì§€ë§‰ {self.K}ê°œ ì´ë²¤íŠ¸ Wide format ë³€í™˜ ì¤‘...")

        # ì—­ìˆœ ì¸ë±ìŠ¤
        data['rev_idx'] = data.groupby('game_episode')['event_idx'].transform(
            lambda s: s.max() - s
        )

        # ë§ˆì§€ë§‰ Kê°œë§Œ
        lastK = data[data['rev_idx'] < self.K].copy()

        # pos_in_K í• ë‹¹
        def assign_pos_in_K(df):
            df = df.sort_values('event_idx')
            L = len(df)
            df = df.copy()
            df['pos_in_K'] = np.arange(self.K - L, self.K)
            return df

        lastK = lastK.groupby('game_episode', group_keys=False).apply(assign_pos_in_K)

        # Wide format í”¼ì²˜ ì„ íƒ (sample_from_other.pyì™€ ë™ì¼í•˜ê²Œ)
        num_cols = [
            'start_x', 'start_y',
            'end_x', 'end_y',
            'dx', 'dy', 'dist', 'speed',
            'dt',
            'ep_idx_norm',
            'x_zone', 'lane',
            'is_final_team',
        ]

        cat_cols = [
            'type_id',
            'res_id',
            'team_id_enc',
            'is_home',
            'period_id',
            'is_last',
        ]

        feature_cols = num_cols + cat_cols
        feature_cols = [c for c in feature_cols if c in lastK.columns]

        wide = lastK[['game_episode', 'pos_in_K'] + feature_cols].copy()

        # ìˆ«ìí˜•ê³¼ ë²”ì£¼í˜• ë”°ë¡œ pivot (sample_from_other.py ë°©ì‹)
        num_cols_available = [c for c in num_cols if c in wide.columns]
        cat_cols_available = [c for c in cat_cols if c in wide.columns]

        wide_num = wide.pivot_table(
            index='game_episode',
            columns='pos_in_K',
            values=num_cols_available,
            aggfunc='first'
        )

        wide_cat = wide.pivot_table(
            index='game_episode',
            columns='pos_in_K',
            values=cat_cols_available,
            aggfunc='first'
        )

        # ì»¬ëŸ¼ ì´ë¦„ í‰íƒ„í™”
        wide_num.columns = [f"{c}_{int(pos)}" for (c, pos) in wide_num.columns]
        wide_cat.columns = [f"{c}_{int(pos)}" for (c, pos) in wide_cat.columns]

        # ë³‘í•©
        X = pd.concat([wide_num, wide_cat], axis=1).reset_index()

        if verbose:
            print(f"âœ… Wide format ë³€í™˜ ì™„ë£Œ")
            print(f"   - ì—í”¼ì†Œë“œ ìˆ˜: {len(X):,}")
            print(f"   - í”¼ì²˜ ìˆ˜: {X.shape[1] - 1}\n")

        return X

    def merge_metadata_and_labels(self, X, ep_meta, labels, verbose=True):
        """ë©”íƒ€ë°ì´í„° ë° ë ˆì´ë¸” ë³‘í•©"""
        if verbose:
            print("ğŸ”— ë©”íƒ€ë°ì´í„° ë° ë ˆì´ë¸” ë³‘í•© ì¤‘...")

        # ë©”íƒ€ ì •ë³´ ë³‘í•© (sample_from_other.pyì™€ ë™ì¼)
        X = X.merge(
            ep_meta[['game_episode', 'game_id', 'game_clock_min', 'final_team_id', 'is_home', 'period_id']],
            on='game_episode',
            how='left'
        )

        # ë ˆì´ë¸” ë³‘í•© (TestëŠ” NaNìœ¼ë¡œ ë‚¨ìŒ)
        X = X.merge(labels, on='game_episode', how='left')

        if verbose:
            labeled = X['target_x'].notna().sum()
            total = len(X)
            print(f"âœ… ë³‘í•© ì™„ë£Œ (Train: {labeled:,}, Test: {total-labeled:,})\n")

        return X

    def prepare_model_data(self, X, verbose=True):
        """ëª¨ë¸ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„"""
        if verbose:
            print("ğŸ“Š ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        train_mask = X['target_x'].notna()
        X_train = X[train_mask].copy()

        y_train_x = X_train['target_x'].values
        y_train_y = X_train['target_y'].values
        y_train = np.column_stack([y_train_x, y_train_y])

        # í”¼ì²˜ ì¶”ì¶œ
        drop_cols = ['game_episode', 'game_id', 'target_x', 'target_y']
        X_train_feat = X_train.drop(columns=drop_cols)

        # NaN ì±„ìš°ê¸°
        X_train_feat = X_train_feat.fillna(0)

        # game_id ì¶”ì¶œ
        game_ids = X_train['game_id'].values

        if verbose:
            print(f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            print(f"   - ìƒ˜í”Œ ìˆ˜: {len(X_train_feat):,}")
            print(f"   - í”¼ì²˜ ìˆ˜: {X_train_feat.shape[1]}\n")

        return X_train_feat, y_train, game_ids

    def create_train_val_split(self, X_train_feat, y_train, game_ids, n_splits=5, verbose=True):
        """5-Fold GroupKFold Split"""
        if verbose:
            print(f"ğŸ“Š {n_splits}-Fold GroupKFold ìƒì„± ì¤‘...")

        gkf = GroupKFold(n_splits=n_splits)

        splits = []
        for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train_feat, groups=game_ids)):
            splits.append({
                'fold': fold,
                'train_idx': train_idx,
                'val_idx': val_idx,
            })

            if verbose:
                print(f"  Fold {fold+1}: Train {len(train_idx):,}, Val {len(val_idx):,}")

        if verbose:
            print()

        return splits

    def preprocess_pipeline(self, verbose=True):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V3"""
        print("=" * 80)
        print("  K-League Pass Prediction - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ V3")
        print(f"  ê°œì„ : Data Leakage ì œê±° + ì‹œí€€ìŠ¤ ëª¨ë¸ë§ (K={self.K})")
        print("=" * 80)
        print()

        # 1. ë°ì´í„° ë¡œë”©
        data = self.load_data(verbose=verbose)

        # 2. ì •ë ¬ ë° ì¸ë±ì‹±
        data = self.sort_and_index(data, verbose=verbose)

        # 3. ê¸°ë³¸ í”¼ì²˜ ìƒì„±
        data = self.create_basic_features(data, verbose=verbose)

        # 4. íƒ€ê²Ÿ ë ˆì´ë¸” ì¶”ì¶œ (Leakage ì œê±° ì „!)
        labels, ep_meta = self.extract_labels(data, verbose=verbose)

        # 5. ê³µê²© íŒ€ í”Œë˜ê·¸ ì¶”ê°€
        data = self.add_final_team_flag(data, ep_meta, verbose=verbose)

        # 6. Data Leakage ì œê±°
        data = self.mask_target_leakage(data, verbose=verbose)

        # 7. ë²”ì£¼í˜• ì¸ì½”ë”©
        data = self.encode_categorical(data, verbose=verbose)

        # 8. ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸ Wide format ë³€í™˜
        X = self.create_lastK_wide_features(data, verbose=verbose)

        # 9. ë©”íƒ€ë°ì´í„° ë° ë ˆì´ë¸” ë³‘í•©
        X = self.merge_metadata_and_labels(X, ep_meta, labels, verbose=verbose)

        # 10. ëª¨ë¸ ë°ì´í„° ì¤€ë¹„
        X_train_feat, y_train, game_ids = self.prepare_model_data(X, verbose=verbose)

        # 11. Train/Val Split
        splits = self.create_train_val_split(X_train_feat, y_train, game_ids, n_splits=5, verbose=verbose)

        print("=" * 80)
        print("âœ… ì „ì²˜ë¦¬ V3 ì™„ë£Œ!")
        print("=" * 80)
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„°:")
        print(f"   - í•™ìŠµ ìƒ˜í”Œ: {len(X_train_feat):,}")
        print(f"   - í”¼ì²˜ ìˆ˜: {X_train_feat.shape[1]}")
        print(f"   - K (ì‹œí€€ìŠ¤ ê¸¸ì´): {self.K}")
        print(f"   - Fold ìˆ˜: {len(splits)}")
        print("\nğŸš¨ ì£¼ìš” ê°œì„ :")
        print("   âœ… Data Leakage ì œê±° (end_x, end_y ë§ˆìŠ¤í‚¹)")
        print("   âœ… ì‹œí€€ìŠ¤ ëª¨ë¸ë§ (ë§ˆì§€ë§‰ Kê°œ ì´ë²¤íŠ¸)")
        print("   âœ… Wide format (ì‹œê°„ ìˆœì„œ ë³´ì¡´)")
        print("   âœ… 5-Fold GroupKFold (ì•ˆì •ì  ê²€ì¦)")
        print("=" * 80)

        return X_train_feat, y_train, game_ids, splits, X

    def save_preprocessor(self, filename='preprocessor_v3.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'type_encoder': self.type_encoder,
                'result_encoder': self.result_encoder,
                'team_encoder': self.team_encoder,
                'K': self.K,
            }, f)
        print(f"âœ… Preprocessor V3 ì €ì¥: {filename}")

    def load_preprocessor(self, filename='preprocessor_v3.pkl'):
        """ì „ì²˜ë¦¬ ê°ì²´ ë¡œë”©"""
        with open(filename, 'rb') as f:
            saved = pickle.load(f)
            self.type_encoder = saved['type_encoder']
            self.result_encoder = saved['result_encoder']
            self.team_encoder = saved['team_encoder']
            self.K = saved['K']
        print(f"Preprocessor V3 loaded: {filename}")


def main():
    """V3 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("  ì „ì²˜ë¦¬ V3 ì‹¤í–‰")
    print("="*80 + "\n")

    # Preprocessor ì´ˆê¸°í™” (K=20)
    preprocessor = DataPreprocessorV3(data_dir='./data', K=20)

    # ì „ì²˜ë¦¬ ì‹¤í–‰
    X_train, y_train, game_ids, splits, X_full = preprocessor.preprocess_pipeline(verbose=True)

    # Preprocessor ì €ì¥
    preprocessor.save_preprocessor('preprocessor_v3.pkl')

    # Train ë°ì´í„° ì €ì¥
    train_mask = X_full['target_x'].notna()
    X_train_full = X_full[train_mask].copy()
    X_train_full.to_csv('processed_train_data_v3.csv', index=False)
    print(f"\nâœ… ì²˜ë¦¬ëœ Train ë°ì´í„° ì €ì¥: processed_train_data_v3.csv")

    # Test ë°ì´í„° ì €ì¥ (ì¶”ë¡ ìš©)
    X_test_full = X_full[~train_mask].copy()
    X_test_full.to_csv('processed_test_data_v3.csv', index=False)
    print(f"âœ… ì²˜ë¦¬ëœ Test ë°ì´í„° ì €ì¥: processed_test_data_v3.csv")

    # ë¹„êµ
    print("\n" + "="*80)
    print("  V1 vs V3 ë¹„êµ")
    print("="*80)
    print("\nV1 (ê¸°ì¡´):")
    print("  - í”¼ì²˜ ìˆ˜: 54ê°œ")
    print("  - ë°©ì‹: ë§ˆì§€ë§‰ 1ê°œ ì´ë²¤íŠ¸ + Aggregate")
    print("  - Data Leakage: âš ï¸ ìˆìŒ (end_x, end_y í¬í•¨)")
    print("  - Validation: 0.93m (í•˜ì§€ë§Œ ë¶€ì •í™•)")
    print("  - Test: 24ì ëŒ€")

    print("\nV3 (ê°œì„ ):")
    print(f"  - í”¼ì²˜ ìˆ˜: {X_train.shape[1]}ê°œ")
    print(f"  - ë°©ì‹: ë§ˆì§€ë§‰ {preprocessor.K}ê°œ ì´ë²¤íŠ¸ + Wide format")
    print("  - Data Leakage: âœ… ì œê±°ë¨")
    print("  - ì˜ˆìƒ Validation: 1.5~2m (ì •ìƒ)")
    print("  - ì˜ˆìƒ Test: 15~18ì ëŒ€ (ì¦‰ì‹œ), 12~15ì ëŒ€ (íŠœë‹ í›„)")

    print("\n" + "="*80)
    print("âœ… ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. train_lightgbm_v3.py ì‹¤í–‰ (5-Fold ì•™ìƒë¸”)")
    print("   2. inference_v3.py ì‹¤í–‰ (Test ì¶”ë¡ )")
    print("   3. ì œì¶œ ë° ì ìˆ˜ í™•ì¸")
    print("="*80)

    return X_train, y_train, game_ids, splits, preprocessor


if __name__ == "__main__":
    X_train, y_train, game_ids, splits, preprocessor = main()

