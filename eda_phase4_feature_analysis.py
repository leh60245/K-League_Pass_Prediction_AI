"""
K-League Pass Prediction - EDA Phase 4
í”¼ì²˜ íš¨ê³¼ì„± ë° ê°œì„  ë°©í–¥ ë¶„ì„

ëª©í‘œ:
1. í˜„ì¬ í”¼ì²˜ë“¤ì˜ ì˜ˆì¸¡ë ¥ ë¶„ì„
2. í”¼ì²˜ ê°„ ìƒê´€ê´€ê³„ ë° ì¤‘ë³µì„± íŒŒì•…
3. ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„ (ì–´ë–¤ ìƒí™©ì—ì„œ ì˜ˆì¸¡ì´ ì–´ë ¤ìš´ê°€?)
4. ìƒˆë¡œìš´ í”¼ì²˜ ì•„ì´ë””ì–´ ë„ì¶œ
5. ì‹¤ìš©ì ì¸ í”¼ì²˜ ê°œì„  ë°©í–¥ ì œì‹œ

ì‘ì„±ì¼: 2025-12-16
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
from collections import Counter, defaultdict
import pickle
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', lambda x: f'{x:.4f}')

class Phase4FeatureAnalyzer:
    def __init__(self, data_dir='./data'):
        self.data_dir = data_dir
        self.insights = []
        self.train_data = None
        self.processed_data = None

    def log_insight(self, text):
        """ì¸ì‚¬ì´íŠ¸ ë¡œê¹…"""
        print(text)
        self.insights.append(text)

    def print_section(self, title, level=1):
        """ì„¹ì…˜ êµ¬ë¶„ ì¶œë ¥"""
        if level == 1:
            separator = "=" * 80
            self.log_insight(f"\n{separator}")
            self.log_insight(f"  {title}")
            self.log_insight(separator + "\n")
        elif level == 2:
            self.log_insight(f"\n{'â”€' * 60}")
            self.log_insight(f"[{title}]")
            self.log_insight('â”€' * 60)

    def load_data(self):
        """ë°ì´í„° ë¡œë”©"""
        self.log_insight("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")

        # ì›ë³¸ ë°ì´í„°
        train_path = os.path.join(self.data_dir, 'train.csv')
        self.train_data = pd.read_csv(train_path)

        # ì „ì²˜ë¦¬ëœ ë°ì´í„°
        if os.path.exists('processed_train_data.csv'):
            self.processed_data = pd.read_csv('processed_train_data.csv')
            self.log_insight(f"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©: {self.processed_data.shape}")
        else:
            self.log_insight("âš ï¸  ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. preprocessing.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        self.log_insight(f"âœ… ì›ë³¸ ë°ì´í„° ë¡œë”©: {self.train_data.shape}\n")

    def analyze_baseline_performance(self):
        """ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ë¶„ì„"""
        self.print_section("PHASE 4-1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ë¶„ì„", level=1)

        if self.processed_data is None:
            self.log_insight("âš ï¸  ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return

        # ì‹¤ì œ íƒ€ê²Ÿ ê°’
        y_true_x = self.processed_data['end_x'].values
        y_true_y = self.processed_data['end_y'].values

        # 1. ì‹œì‘ ìœ„ì¹˜ = ë„ì°© ìœ„ì¹˜ (ë² ì´ìŠ¤ë¼ì¸)
        y_pred_x = self.processed_data['start_x'].values
        y_pred_y = self.processed_data['start_y'].values

        errors = np.sqrt((y_true_x - y_pred_x)**2 + (y_true_y - y_pred_y)**2)

        self.log_insight(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ (start = end) ì„±ëŠ¥:")
        self.log_insight(f"  - í‰ê·  ì˜¤ì°¨: {errors.mean():.2f}m")
        self.log_insight(f"  - ì¤‘ì•™ê°’ ì˜¤ì°¨: {np.median(errors):.2f}m")
        self.log_insight(f"  - í‘œì¤€í¸ì°¨: {errors.std():.2f}m")
        self.log_insight(f"  - ìµœì†Œ ì˜¤ì°¨: {errors.min():.2f}m")
        self.log_insight(f"  - ìµœëŒ€ ì˜¤ì°¨: {errors.max():.2f}m")

        # ë°±ë¶„ìœ„ìˆ˜
        self.log_insight(f"\nğŸ“Š ì˜¤ì°¨ ë¶„í¬ (ë°±ë¶„ìœ„ìˆ˜):")
        for p in [25, 50, 75, 90, 95, 99]:
            self.log_insight(f"  - {p}%: {np.percentile(errors, p):.2f}m")

        # 2. ì˜¤ì°¨ ë²”ìœ„ë³„ ë¹„ìœ¨
        self.log_insight(f"\nğŸ“Š ì˜¤ì°¨ ë²”ìœ„ë³„ ì—í”¼ì†Œë“œ ë¹„ìœ¨:")
        ranges = [(0, 5), (5, 10), (10, 15), (15, 20), (20, 30), (30, 50), (50, 100)]
        for low, high in ranges:
            count = ((errors >= low) & (errors < high)).sum()
            pct = (count / len(errors)) * 100
            self.log_insight(f"  - {low:3d}m ~ {high:3d}m: {count:5,}ê°œ ({pct:5.1f}%)")

    def analyze_feature_coverage(self):
        """í”¼ì²˜ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ - ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜"""
        self.print_section("PHASE 4-2: í”¼ì²˜ í’ˆì§ˆ ë¶„ì„", level=1)

        if self.processed_data is None:
            return

        self.print_section("2.1 ê²°ì¸¡ì¹˜ í˜„í™©", level=2)

        missing_stats = []
        for col in self.processed_data.columns:
            missing_count = self.processed_data[col].isna().sum()
            if missing_count > 0:
                missing_pct = (missing_count / len(self.processed_data)) * 100
                missing_stats.append({
                    'column': col,
                    'missing_count': missing_count,
                    'missing_pct': missing_pct
                })

        if missing_stats:
            missing_df = pd.DataFrame(missing_stats).sort_values('missing_pct', ascending=False)
            self.log_insight(f"ğŸ“Š ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í”¼ì²˜: {len(missing_df)}ê°œ")
            for _, row in missing_df.head(20).iterrows():
                self.log_insight(f"  - {row['column']:35s}: {row['missing_count']:6,} ({row['missing_pct']:5.1f}%)")
        else:
            self.log_insight("âœ… ëª¨ë“  í”¼ì²˜ì— ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # 2.2 í”¼ì²˜ ë¶„ì‚° ë¶„ì„
        self.print_section("2.2 í”¼ì²˜ ë¶„ì‚° ë¶„ì„ (ë‚®ì€ ë¶„ì‚° = ì •ë³´ëŸ‰ ì ìŒ)", level=2)

        numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
        variance_stats = []

        for col in numeric_cols:
            if col not in ['end_x', 'end_y', 'game_id']:
                var = self.processed_data[col].var()
                std = self.processed_data[col].std()
                mean = self.processed_data[col].mean()
                cv = std / (abs(mean) + 1e-10)  # Coefficient of Variation

                variance_stats.append({
                    'column': col,
                    'variance': var,
                    'std': std,
                    'mean': mean,
                    'cv': cv
                })

        var_df = pd.DataFrame(variance_stats).sort_values('variance')

        self.log_insight(f"ğŸ“Š ë¶„ì‚°ì´ ê°€ì¥ ë‚®ì€ í”¼ì²˜ Top 15:")
        for _, row in var_df.head(15).iterrows():
            self.log_insight(f"  - {row['column']:35s}: var={row['variance']:10.4f}, CV={row['cv']:6.2f}")

    def analyze_feature_correlation(self):
        """í”¼ì²˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        self.print_section("PHASE 4-3: í”¼ì²˜ ìƒê´€ê´€ê³„ ë¶„ì„", level=1)

        if self.processed_data is None:
            return

        # íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„
        self.print_section("3.1 íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„", level=2)

        numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
        feature_cols = [col for col in numeric_cols
                       if col not in ['end_x', 'end_y', 'game_id', 'episode_id']]

        corr_x = []
        corr_y = []

        for col in feature_cols:
            try:
                cx = self.processed_data[[col, 'end_x']].corr().iloc[0, 1]
                cy = self.processed_data[[col, 'end_y']].corr().iloc[0, 1]
                corr_x.append({'feature': col, 'corr': cx})
                corr_y.append({'feature': col, 'corr': cy})
            except:
                pass

        # end_xì™€ ìƒê´€ê´€ê³„ ë†’ì€ í”¼ì²˜
        self.log_insight(f"ğŸ“Š end_xì™€ ìƒê´€ê´€ê³„ ë†’ì€ í”¼ì²˜ Top 20:")
        corr_x_df = pd.DataFrame(corr_x).sort_values('corr', key=abs, ascending=False)
        for i, row in corr_x_df.head(20).iterrows():
            self.log_insight(f"  {i+1:2d}. {row['feature']:35s}: {row['corr']:7.4f}")

        # end_yì™€ ìƒê´€ê´€ê³„ ë†’ì€ í”¼ì²˜
        self.log_insight(f"\nğŸ“Š end_yì™€ ìƒê´€ê´€ê³„ ë†’ì€ í”¼ì²˜ Top 20:")
        corr_y_df = pd.DataFrame(corr_y).sort_values('corr', key=abs, ascending=False)
        for i, row in corr_y_df.head(20).iterrows():
            self.log_insight(f"  {i+1:2d}. {row['feature']:35s}: {row['corr']:7.4f}")

        # 3.2 í”¼ì²˜ ê°„ ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„
        self.print_section("3.2 í”¼ì²˜ ê°„ ë†’ì€ ìƒê´€ê´€ê³„ (ë‹¤ì¤‘ê³µì„ ì„±)", level=2)

        # ìƒìœ„ 30ê°œ ì¤‘ìš” í”¼ì²˜ë§Œ ë¶„ì„ (ê³„ì‚° íš¨ìœ¨ì„±)
        top_features_x = corr_x_df.head(30)['feature'].tolist()
        top_features_y = corr_y_df.head(30)['feature'].tolist()
        top_features = list(set(top_features_x + top_features_y))

        if len(top_features) > 2:
            corr_matrix = self.processed_data[top_features].corr()

            # ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸° (|r| > 0.8)
            high_corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.8:
                        high_corr_pairs.append({
                            'feature1': corr_matrix.columns[i],
                            'feature2': corr_matrix.columns[j],
                            'correlation': corr_val
                        })

            if high_corr_pairs:
                self.log_insight(f"âš ï¸  ë†’ì€ ìƒê´€ê´€ê³„ í”¼ì²˜ ìŒ (|r| > 0.8): {len(high_corr_pairs)}ê°œ")
                high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('correlation', key=abs, ascending=False)
                for i, row in high_corr_df.head(15).iterrows():
                    self.log_insight(f"  - {row['feature1']:30s} â†” {row['feature2']:30s}: {row['correlation']:6.3f}")
            else:
                self.log_insight("âœ… ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ ì—†ìŒ (ìƒìœ„ í”¼ì²˜ ê¸°ì¤€)")

    def analyze_error_patterns(self):
        """ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„ - ì–´ë–¤ ìƒí™©ì—ì„œ ì˜ˆì¸¡ì´ ì–´ë ¤ìš´ê°€?"""
        self.print_section("PHASE 4-4: ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„", level=1)

        if self.processed_data is None:
            return

        # ë² ì´ìŠ¤ë¼ì¸ ì˜¤ì°¨ ê³„ì‚°
        errors = np.sqrt(
            (self.processed_data['end_x'] - self.processed_data['start_x'])**2 +
            (self.processed_data['end_y'] - self.processed_data['start_y'])**2
        )
        self.processed_data['baseline_error'] = errors

        # 4.1 ê²½ê¸°ì¥ ìœ„ì¹˜ë³„ ì˜¤ì°¨
        self.print_section("4.1 ê²½ê¸°ì¥ ìœ„ì¹˜ë³„ ì˜ˆì¸¡ ë‚œì´ë„", level=2)

        # Xì¶• êµ¬ê°„ë³„
        self.log_insight("ğŸ“Š Xì¶• ìœ„ì¹˜ë³„ í‰ê·  ì˜¤ì°¨:")
        x_bins = [(0, 35, 'ìˆ˜ë¹„ì§„'), (35, 70, 'ì¤‘ì›'), (70, 105, 'ê³µê²©ì§„')]
        for low, high, label in x_bins:
            mask = (self.processed_data['start_x'] >= low) & (self.processed_data['start_x'] < high)
            avg_error = errors[mask].mean()
            count = mask.sum()
            self.log_insight(f"  - {label:10s} ({low:3d}-{high:3d}m): {avg_error:6.2f}m (n={count:,})")

        # Yì¶• êµ¬ê°„ë³„
        self.log_insight("\nğŸ“Š Yì¶• ìœ„ì¹˜ë³„ í‰ê·  ì˜¤ì°¨:")
        y_bins = [(0, 22.67, 'ì¢Œì¸¡'), (22.67, 45.33, 'ì¤‘ì•™'), (45.33, 68, 'ìš°ì¸¡')]
        for low, high, label in y_bins:
            mask = (self.processed_data['start_y'] >= low) & (self.processed_data['start_y'] < high)
            avg_error = errors[mask].mean()
            count = mask.sum()
            self.log_insight(f"  - {label:10s} ({low:5.2f}-{high:5.2f}m): {avg_error:6.2f}m (n={count:,})")

        # 4.2 ì—í”¼ì†Œë“œ íŠ¹ì„±ë³„ ì˜¤ì°¨
        self.print_section("4.2 ì—í”¼ì†Œë“œ íŠ¹ì„±ë³„ ì˜ˆì¸¡ ë‚œì´ë„", level=2)

        # ì—í”¼ì†Œë“œ ê¸¸ì´ë³„
        if 'episode_length' in self.processed_data.columns:
            self.log_insight("ğŸ“Š ì—í”¼ì†Œë“œ ê¸¸ì´ë³„ í‰ê·  ì˜¤ì°¨:")
            length_bins = [(1, 5), (5, 10), (10, 20), (20, 30), (30, 50), (50, 100)]
            for low, high in length_bins:
                mask = (self.processed_data['episode_length'] >= low) & (self.processed_data['episode_length'] < high)
                if mask.sum() > 0:
                    avg_error = errors[mask].mean()
                    count = mask.sum()
                    self.log_insight(f"  - {low:3d} ~ {high:3d}ê°œ: {avg_error:6.2f}m (n={count:,})")

        # ì´ë²¤íŠ¸ íƒ€ì…ë³„
        if 'type_name' in self.train_data.columns:
            self.log_insight("\nğŸ“Š ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ íƒ€ì…ë³„ í‰ê·  ì˜¤ì°¨:")

            # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œ
            last_events = self.train_data.groupby('game_episode').tail(1).copy()

            # ì—í”¼ì†Œë“œë³„ë¡œ ë§¤ì¹­
            merged = pd.merge(
                self.processed_data[['game_episode', 'baseline_error']],
                last_events[['game_episode', 'type_name']],
                on='game_episode',
                how='left'
            )

            type_errors = merged.groupby('type_name')['baseline_error'].agg(['mean', 'count'])
            type_errors = type_errors.sort_values('mean', ascending=False)

            for i, (type_name, row) in enumerate(type_errors.head(15).iterrows(), 1):
                if row['count'] >= 10:  # ìµœì†Œ 10ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ
                    self.log_insight(f"  {i:2d}. {type_name:30s}: {row['mean']:6.2f}m (n={int(row['count']):,})")

        # 4.3 íŠ¹ì • í”¼ì²˜ ê°’ì— ë”°ë¥¸ ì˜¤ì°¨
        self.print_section("4.3 ì£¼ìš” í”¼ì²˜ ê°’ì— ë”°ë¥¸ ì˜ˆì¸¡ ë‚œì´ë„", level=2)

        # ê³¨ë¬¸ ê±°ë¦¬ë³„
        if 'distance_to_goal_start' in self.processed_data.columns:
            self.log_insight("ğŸ“Š ê³¨ë¬¸ ê±°ë¦¬ë³„ í‰ê·  ì˜¤ì°¨:")
            goal_bins = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 150)]
            for low, high in goal_bins:
                mask = (self.processed_data['distance_to_goal_start'] >= low) & \
                       (self.processed_data['distance_to_goal_start'] < high)
                if mask.sum() > 0:
                    avg_error = errors[mask].mean()
                    count = mask.sum()
                    self.log_insight(f"  - {low:3d} ~ {high:3d}m: {avg_error:6.2f}m (n={count:,})")

        # í˜ë„í‹° ë°•ìŠ¤ ë‚´/ì™¸
        if 'in_penalty_area' in self.processed_data.columns:
            self.log_insight("\nğŸ“Š í˜ë„í‹° ë°•ìŠ¤ ë‚´/ì™¸ í‰ê·  ì˜¤ì°¨:")
            for val, label in [(1, 'í˜ë„í‹° ë°•ìŠ¤ ë‚´'), (0, 'í˜ë„í‹° ë°•ìŠ¤ ì™¸')]:
                mask = self.processed_data['in_penalty_area'] == val
                avg_error = errors[mask].mean()
                count = mask.sum()
                self.log_insight(f"  - {label:20s}: {avg_error:6.2f}m (n={count:,})")

    def analyze_feature_interactions(self):
        """í”¼ì²˜ ê°„ ìƒí˜¸ì‘ìš© ë¶„ì„"""
        self.print_section("PHASE 4-5: í”¼ì²˜ ìƒí˜¸ì‘ìš© ë¶„ì„", level=1)

        if self.processed_data is None:
            return

        errors = self.processed_data['baseline_error']

        # 5.1 ìœ„ì¹˜ Ã— ì—í”¼ì†Œë“œ ê¸¸ì´
        self.print_section("5.1 ìœ„ì¹˜ Ã— ì—í”¼ì†Œë“œ ê¸¸ì´", level=2)

        if 'episode_length' in self.processed_data.columns:
            self.log_insight("ğŸ“Š ê³µê²©ì§„ì—ì„œì˜ ì—í”¼ì†Œë“œ ê¸¸ì´ë³„ ì˜¤ì°¨:")
            mask_attack = self.processed_data['start_x'] >= 70

            for length_range, label in [((1, 10), 'ì§§ì€ ì—í”¼ì†Œë“œ'),
                                       ((10, 30), 'ì¤‘ê°„ ì—í”¼ì†Œë“œ'),
                                       ((30, 100), 'ê¸´ ì—í”¼ì†Œë“œ')]:
                low, high = length_range
                mask = mask_attack & \
                       (self.processed_data['episode_length'] >= low) & \
                       (self.processed_data['episode_length'] < high)

                if mask.sum() > 0:
                    avg_error = errors[mask].mean()
                    count = mask.sum()
                    self.log_insight(f"  - {label:20s} ({low:2d}-{high:3d}): {avg_error:6.2f}m (n={count:,})")

        # 5.2 ì†ë„ Ã— ê±°ë¦¬
        self.print_section("5.2 ì†ë„ Ã— ì´ë™ ê±°ë¦¬", level=2)

        if 'velocity' in self.processed_data.columns and 'distance' in self.processed_data.columns:
            # velocityê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ
            valid_velocity = self.processed_data['velocity'].notna() & \
                           (self.processed_data['velocity'] >= 0) & \
                           (self.processed_data['velocity'] < 100)

            if valid_velocity.sum() > 0:
                self.log_insight("ğŸ“Š ì´ë™ ì†ë„ Ã— ê±°ë¦¬ ì¡°í•©ë³„ ì˜¤ì°¨:")

                for vel_range, vel_label in [((0, 5), 'ëŠë¦° ì†ë„'),
                                            ((5, 15), 'ì¤‘ê°„ ì†ë„'),
                                            ((15, 100), 'ë¹ ë¥¸ ì†ë„')]:
                    vel_low, vel_high = vel_range

                    for dist_range, dist_label in [((0, 10), 'ì§§ì€ ê±°ë¦¬'),
                                                  ((10, 30), 'ê¸´ ê±°ë¦¬')]:
                        dist_low, dist_high = dist_range

                        mask = valid_velocity & \
                               (self.processed_data['velocity'] >= vel_low) & \
                               (self.processed_data['velocity'] < vel_high) & \
                               (self.processed_data['distance'] >= dist_low) & \
                               (self.processed_data['distance'] < dist_high)

                        if mask.sum() > 100:  # ìµœì†Œ 100ê°œ ì´ìƒ
                            avg_error = errors[mask].mean()
                            count = mask.sum()
                            self.log_insight(f"  - {vel_label:15s} Ã— {dist_label:15s}: {avg_error:6.2f}m (n={count:,})")

    def suggest_feature_improvements(self):
        """í”¼ì²˜ ê°œì„  ì œì•ˆ"""
        self.print_section("PHASE 4-6: í”¼ì²˜ ê°œì„  ì œì•ˆ", level=1)

        suggestions = []

        # 1. ìƒê´€ê´€ê³„ ë¶„ì„ ê¸°ë°˜ ì œì•ˆ
        suggestions.append({
            'category': 'ğŸ¯ íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ê°œì„ ',
            'suggestions': [
                '1. start_x/yì˜ ë¹„ì„ í˜• ë³€í™˜ ì‹œë„ (log, sqrt, polynomial)',
                '2. ê³¨ë¬¸ ê±°ë¦¬ì˜ ì—­ìˆ˜ ë˜ëŠ” ì§€ìˆ˜ ë³€í™˜',
                '3. ê°ë„ í”¼ì²˜ì˜ sin/cos ë³€í™˜',
                '4. êµ¬ê°„ë³„ ë”ë¯¸ ë³€ìˆ˜ ìƒì„± (íŠ¹ì • ìœ„ì¹˜ì—ì„œì˜ í–‰ë™ íŒ¨í„´)',
            ]
        })

        # 2. ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
        suggestions.append({
            'category': 'âš ï¸  ë‹¤ì¤‘ê³µì„ ì„± ì œê±°',
            'suggestions': [
                '1. ê³ ë„ë¡œ ìƒê´€ëœ í”¼ì²˜ ìŒ ì¤‘ í•˜ë‚˜ ì œê±°',
                '2. PCA/LDAë¥¼ í†µí•œ ì°¨ì› ì¶•ì†Œ',
                '3. íŒŒìƒ í”¼ì²˜ ëŒ€ì‹  ì›ë³¸ í”¼ì²˜ ì‚¬ìš© ê³ ë ¤',
                '4. Regularization (L1/L2) ê°•í™”',
            ]
        })

        # 3. ì˜¤ë¥˜ íŒ¨í„´ ê¸°ë°˜ ì œì•ˆ
        suggestions.append({
            'category': 'ğŸ” ì˜¤ë¥˜ íŒ¨í„´ ê¸°ë°˜',
            'suggestions': [
                '1. ì˜ˆì¸¡ ì–´ë ¤ìš´ ìœ„ì¹˜(ê³µê²©ì§„, í˜ë„í‹° ë°•ìŠ¤)ì— íŠ¹í™”ëœ í”¼ì²˜',
                '2. ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë§ì¶¤ í”¼ì²˜ (Cross, Shot ë“±)',
                '3. ê¸´ ì—í”¼ì†Œë“œë¥¼ ìœ„í•œ ì‹œí€€ìŠ¤ ìš”ì•½ í”¼ì²˜',
                '4. ì••ë°• ìƒí™© ê°ì§€ í”¼ì²˜ ê°•í™”',
            ]
        })

        # 4. ìƒˆë¡œìš´ í”¼ì²˜ ì•„ì´ë””ì–´
        suggestions.append({
            'category': 'ğŸ’¡ ìƒˆë¡œìš´ í”¼ì²˜ ì•„ì´ë””ì–´',
            'suggestions': [
                '1. ì„ ìˆ˜ ì—­í• /í¬ì§€ì…˜ ê¸°ë°˜ í”¼ì²˜ (player_id í™œìš©)',
                '2. íŒ€ ì „ìˆ  ìŠ¤íƒ€ì¼ í”¼ì²˜ (team_id ê¸°ë°˜)',
                '3. ìƒëŒ€ íŒ€ ìˆ˜ë¹„ ë°€ì§‘ë„ ì¶”ì •',
                '4. ì‹œê°„ëŒ€ë³„ ë“ì  í™•ë¥  (ê²½ê¸° ì¢…ë£Œ ì„ë°•)',
                '5. ì—°ì† ì„±ê³µ íŒ¨ìŠ¤ íšŸìˆ˜',
                '6. ì§ì „ Nê°œ íŒ¨ìŠ¤ì˜ í‰ê·  ê°ë„/ê±°ë¦¬',
                '7. ì—í”¼ì†Œë“œ ë‚´ X/Y ì¢Œí‘œì˜ í‘œì¤€í¸ì°¨ (ê³µê°„ í™œìš©ë„)',
                '8. ê³¨í‚¤í¼ ìœ„ì¹˜ ì¶”ì • (ê³¨ë¬¸ ê±°ë¦¬ + ê°ë„)',
            ]
        })

        # 5. ëª¨ë¸ë§ ê°œì„ 
        suggestions.append({
            'category': 'ğŸš€ ëª¨ë¸ë§ ê°œì„ ',
            'suggestions': [
                '1. Feature Selection (Recursive Feature Elimination)',
                '2. Feature Importance ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •',
                '3. ìœ„ì¹˜ë³„ ê°œë³„ ëª¨ë¸ í•™ìŠµ (ì•™ìƒë¸”)',
                '4. Stacking: 1ë‹¨ê³„ ì˜ˆì¸¡ì„ 2ë‹¨ê³„ í”¼ì²˜ë¡œ í™œìš©',
                '5. Cross-validation fold ìˆ˜ ì¡°ì •',
            ]
        })

        # ì¶œë ¥
        for item in suggestions:
            self.log_insight(f"\n{item['category']}")
            for suggestion in item['suggestions']:
                self.log_insight(f"  {suggestion}")

    def analyze_low_variance_features(self):
        """ë‚®ì€ ë¶„ì‚° í”¼ì²˜ ì‹¬í™” ë¶„ì„"""
        self.print_section("PHASE 4-7: ë‚®ì€ ì •ë³´ëŸ‰ í”¼ì²˜ ìƒì„¸ ë¶„ì„", level=1)

        if self.processed_data is None:
            return

        numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
        feature_cols = [col for col in numeric_cols
                       if col not in ['end_x', 'end_y', 'game_id', 'episode_id']]

        low_info_features = []

        for col in feature_cols:
            unique_count = self.processed_data[col].nunique()
            total_count = len(self.processed_data)
            unique_ratio = unique_count / total_count

            # ê³ ìœ ê°’ì´ 10ê°œ ì´í•˜ì´ê±°ë‚˜, ê³ ìœ ê°’ ë¹„ìœ¨ì´ 1% ì´í•˜
            if unique_count <= 10 or unique_ratio < 0.01:
                value_counts = self.processed_data[col].value_counts()
                low_info_features.append({
                    'feature': col,
                    'unique_count': unique_count,
                    'unique_ratio': unique_ratio,
                    'top_value': value_counts.index[0],
                    'top_value_count': value_counts.iloc[0],
                    'top_value_pct': (value_counts.iloc[0] / total_count) * 100
                })

        if low_info_features:
            self.log_insight(f"âš ï¸  ë‚®ì€ ì •ë³´ëŸ‰ í”¼ì²˜: {len(low_info_features)}ê°œ\n")
            low_info_df = pd.DataFrame(low_info_features).sort_values('unique_ratio')

            for _, row in low_info_df.head(20).iterrows():
                self.log_insight(f"  - {row['feature']:35s}: {row['unique_count']:4d}ê°œ ê³ ìœ ê°’ "
                               f"({row['unique_ratio']*100:5.2f}%), "
                               f"ìµœë¹ˆê°’={row['top_value']:.2f} ({row['top_value_pct']:.1f}%)")
        else:
            self.log_insight("âœ… ëª¨ë“  í”¼ì²˜ê°€ ì¶©ë¶„í•œ ì •ë³´ëŸ‰ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.")

    def save_insights(self):
        """ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'archive/EDA_Phase4_Feature_Analysis_{timestamp}.txt'

        os.makedirs('archive', exist_ok=True)

        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.insights))

        self.log_insight(f"\nâœ… ì¸ì‚¬ì´íŠ¸ ì €ì¥: {filename}")

    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        self.print_section("K-League Pass Prediction - Phase 4: í”¼ì²˜ íš¨ê³¼ì„± ë¶„ì„", level=1)
        self.log_insight(f"ë¶„ì„ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # ë°ì´í„° ë¡œë”©
        self.load_data()

        if self.processed_data is None:
            self.log_insight("âš ï¸  ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            self.log_insight("ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”: python preprocessing.py")
            return

        # ë¶„ì„ ë‹¨ê³„ë³„ ì‹¤í–‰
        self.analyze_baseline_performance()
        self.analyze_feature_coverage()
        self.analyze_feature_correlation()
        self.analyze_error_patterns()
        self.analyze_feature_interactions()
        self.analyze_low_variance_features()
        self.suggest_feature_improvements()

        # ìµœì¢… ìš”ì•½
        self.print_section("ë¶„ì„ ì™„ë£Œ", level=1)
        self.log_insight(f"ì´ {len(self.insights)}ê°œì˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
        self.log_insight(f"ë¶„ì„ ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # ì €ì¥
        self.save_insights()

        return self.insights


if __name__ == "__main__":
    analyzer = Phase4FeatureAnalyzer(data_dir='./data')
    insights = analyzer.run_full_analysis()

    print("\n" + "="*80)
    print("âœ… Phase 4 ë¶„ì„ ì™„ë£Œ!")
    print("="*80)

