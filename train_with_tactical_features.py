"""
K-League Pass Prediction - ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ë¥¼ í™œìš©í•œ ëª¨ë¸ í•™ìŠµ

ìƒˆë¡œìš´ í”¼ì²˜:
- ì••ë°• ê°•ë„ (Pressure Intensity)
- ê³µê°„ ì°½ì¶œ (Space Creation)
- ì§„í–‰ ë°©í–¥ì„± (Directional Consistency)
- ê²½ë¡œ íš¨ìœ¨ì„± (Path Efficiency)
- ê³¨ ê°ë„ (Shooting Angle)
- í…œí¬ ë¶„ì„ (Tempo Analysis)
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import pickle
from preprocessing import DataPreprocessor
import os
from datetime import datetime

def train_model_with_tactical_features():
    """ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ë¥¼ í™œìš©í•œ ëª¨ë¸ í•™ìŠµ"""

    print("=" * 80)
    print("  K-League Pass Prediction - ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ ëª¨ë¸ í•™ìŠµ")
    print("=" * 80)
    print()

    # 1. ë°ì´í„° ë¡œë”©
    print("ğŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”© ì¤‘...")
    if os.path.exists('processed_train_data.csv'):
        processed_data = pd.read_csv('processed_train_data.csv')
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {processed_data.shape}")
    else:
        print("âŒ processed_train_data.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. preprocessing.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # 2. Preprocessor ë¡œë”©
    print("\nğŸ”§ Preprocessor ë¡œë”© ì¤‘...")
    preprocessor = DataPreprocessor(data_dir='./data')
    if os.path.exists('preprocessor.pkl'):
        preprocessor.load_preprocessor('preprocessor.pkl')
    else:
        print("âŒ preprocessor.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. í”¼ì²˜ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
    feature_cols = preprocessor.get_feature_columns()

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
    available_features = [col for col in feature_cols if col in processed_data.columns]
    print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(available_features)}ê°œ")

    # 4. íƒ€ê²Ÿ ë³€ìˆ˜
    target_cols = ['end_x', 'end_y']

    # 5. Train/Val Split ìƒì„±
    print("\nğŸ“Š Train/Val Split ìƒì„± ì¤‘...")
    splits = preprocessor.create_train_val_split(processed_data, n_splits=5, verbose=False)

    # Fold 0ë§Œ ì‚¬ìš© (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
    fold = 0
    train_idx = splits[fold]['train_idx']
    val_idx = splits[fold]['val_idx']

    X_train = processed_data.loc[train_idx, available_features]
    y_train = processed_data.loc[train_idx, target_cols]
    X_val = processed_data.loc[val_idx, available_features]
    y_val = processed_data.loc[val_idx, target_cols]

    print(f"âœ… Train: {X_train.shape}, Val: {X_val.shape}")

    # 6. ê²°ì¸¡ì¹˜ í™•ì¸ ë° ì²˜ë¦¬
    print("\nğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")
    X_train = X_train.fillna(0)
    X_val = X_val.fillna(0)
    print(f"âœ… Train NaN: {X_train.isna().sum().sum()}, Val NaN: {X_val.isna().sum().sum()}")

    # 7. ëª¨ë¸ í•™ìŠµ (X, Y ì¢Œí‘œ ê°ê°)
    print("\n" + "=" * 80)
    print("  ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("=" * 80)

    models = {}
    results = {}

    for target in ['end_x', 'end_y']:
        print(f"\nğŸ¯ íƒ€ê²Ÿ: {target}")
        print("-" * 40)

        # XGBoost íŒŒë¼ë¯¸í„° (ê³ ê¸‰ ì„¤ì •)
        params = {
            'objective': 'reg:squarederror',
            'eval_metric': 'rmse',  # ì—¬ê¸°ë¡œ ì´ë™
            'n_estimators': 500,
            'max_depth': 8,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'min_child_weight': 3,
            'gamma': 0.1,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0,
            'random_state': 42,
            'tree_method': 'hist',
            'n_jobs': -1
        }

        # ëª¨ë¸ ì´ˆê¸°í™”
        model = xgb.XGBRegressor(**params)

        # í•™ìŠµ
        print("ğŸ”„ í•™ìŠµ ì¤‘...")
        model.fit(
            X_train, y_train[target],
            eval_set=[(X_train, y_train[target]), (X_val, y_val[target])],
            verbose=50
        )

        # ì˜ˆì¸¡
        train_pred = model.predict(X_train)
        val_pred = model.predict(X_val)

        # í‰ê°€
        train_rmse = np.sqrt(mean_squared_error(y_train[target], train_pred))
        val_rmse = np.sqrt(mean_squared_error(y_val[target], val_pred))

        print(f"\nğŸ“Š ì„±ëŠ¥:")
        print(f"  Train RMSE: {train_rmse:.4f}")
        print(f"  Val RMSE:   {val_rmse:.4f}")

        models[target] = model
        results[target] = {
            'train_rmse': train_rmse,
            'val_rmse': val_rmse
        }

    # 8. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    print("\n" + "=" * 80)
    print("  í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (Top 20)")
    print("=" * 80)

    for target in ['end_x', 'end_y']:
        print(f"\nğŸ¯ {target}:")
        print("-" * 40)

        model = models[target]
        importance = model.feature_importances_

        # ì¤‘ìš”ë„ ì •ë ¬
        feature_importance = pd.DataFrame({
            'feature': available_features,
            'importance': importance
        }).sort_values('importance', ascending=False)

        # Top 20 ì¶œë ¥
        for i, row in feature_importance.head(20).iterrows():
            print(f"  {row['feature']:30s}: {row['importance']:.4f}")

        # ì „ìˆ  í”¼ì²˜ ì¤‘ìš”ë„ ë”°ë¡œ ë¶„ì„
        tactical_features = [
            'shooting_angle', 'goal_approach',
            'local_pressure', 'weighted_pressure', 'event_density',
            'distance_change_rate', 'vertical_spread', 'attack_width',
            'forward_momentum', 'pass_angle_change',
            'direction_consistency', 'path_efficiency',
            'dist_from_team_center', 'match_phase',
            'velocity', 'acceleration', 'tempo_change'
        ]

        tactical_importance = feature_importance[
            feature_importance['feature'].isin(tactical_features)
        ]

        if len(tactical_importance) > 0:
            print(f"\nâš½ ì „ìˆ  í”¼ì²˜ ì¤‘ìš”ë„:")
            for i, row in tactical_importance.head(10).iterrows():
                print(f"  {row['feature']:30s}: {row['importance']:.4f}")

    # 9. ëª¨ë¸ ì €ì¥
    print("\n" + "=" * 80)
    print("  ëª¨ë¸ ì €ì¥")
    print("=" * 80)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_dir = f"models/tactical_features_{timestamp}"
    os.makedirs(model_dir, exist_ok=True)

    # ê° ëª¨ë¸ ì €ì¥
    for target, model in models.items():
        model_path = os.path.join(model_dir, f'{target}_model.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        print(f"âœ… {target} ëª¨ë¸ ì €ì¥: {model_path}")

    # ê²°ê³¼ ì €ì¥
    results_path = os.path.join(model_dir, 'performance.txt')
    with open(results_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("  K-League Pass Prediction - ê³ ê¸‰ ì „ìˆ  í”¼ì²˜ ëª¨ë¸ ì„±ëŠ¥\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"í•™ìŠµ ì‹œê°„: {timestamp}\n")
        f.write(f"í”¼ì²˜ ê°œìˆ˜: {len(available_features)}\n")
        f.write(f"Train ìƒ˜í”Œ: {len(X_train)}\n")
        f.write(f"Val ìƒ˜í”Œ: {len(X_val)}\n\n")

        for target in ['end_x', 'end_y']:
            f.write(f"\n{target}:\n")
            f.write(f"  Train RMSE: {results[target]['train_rmse']:.4f}\n")
            f.write(f"  Val RMSE:   {results[target]['val_rmse']:.4f}\n")

        f.write("\n\nì‚¬ìš©ëœ ì „ìˆ  í”¼ì²˜:\n")
        for feature in tactical_features:
            if feature in available_features:
                f.write(f"  - {feature}\n")

    print(f"âœ… ì„±ëŠ¥ ê²°ê³¼ ì €ì¥: {results_path}")

    print("\n" + "=" * 80)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 80)

    return models, results, available_features

if __name__ == "__main__":
    models, results, features = train_model_with_tactical_features()

    print("\nğŸ“Š ìµœì¢… ìš”ì•½:")
    print("-" * 80)
    print(f"ì´ í”¼ì²˜ ìˆ˜: {len(features)}")
    print(f"end_x Val RMSE: {results['end_x']['val_rmse']:.4f}")
    print(f"end_y Val RMSE: {results['end_y']['val_rmse']:.4f}")
    print(f"í‰ê·  RMSE: {(results['end_x']['val_rmse'] + results['end_y']['val_rmse']) / 2:.4f}")

