"""
K-League Pass Prediction - 3-Model Ensemble

XGBoost + LightGBM + CatBoost ì•™ìƒë¸”
ëª©í‘œ: 0.7m ì´í•˜ ë‹¬ì„±
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

def euclidean_distance(y_true, y_pred):
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    true_x, true_y = y_true[:, 0], y_true[:, 1]
    pred_x, pred_y = y_pred[:, 0], y_pred[:, 1]
    return np.mean(np.sqrt((true_x - pred_x)**2 + (true_y - pred_y)**2))


class ThreeModelEnsemble:
    """3ì¢… GBM ì•™ìƒë¸” í´ë˜ìŠ¤"""

    def __init__(self):
        self.models = []
        self.model_names = []
        self.weights = None
        self.best_weights = None
        self.best_score = float('inf')

    def add_model(self, model_path, model_name, weight=None):
        """ëª¨ë¸ ì¶”ê°€"""
        with open(model_path, 'rb') as f:
            model = pickle.load(f)

        self.models.append(model)
        self.model_names.append(model_name)

        if weight is not None:
            if self.weights is None:
                self.weights = []
            self.weights.append(weight)

        print(f"âœ… ëª¨ë¸ ì¶”ê°€: {model_name} (ê°€ì¤‘ì¹˜: {weight if weight else 'ë¯¸ì •'})")

    def predict(self, X, weights=None):
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        if weights is None:
            weights = self.weights if self.weights else [1.0/len(self.models)] * len(self.models)

        predictions = []

        for model in self.models:
            pred_x = model['model_x'].predict(X)
            pred_y = model['model_y'].predict(X)
            pred = np.column_stack([pred_x, pred_y])
            predictions.append(pred)

        # ê°€ì¤‘ í‰ê· 
        predictions = np.array(predictions)
        weights = np.array(weights).reshape(-1, 1, 1)

        ensemble_pred = np.sum(predictions * weights, axis=0)

        return ensemble_pred

    def evaluate_weights(self, X_val, y_val, weights):
        """íŠ¹ì • ê°€ì¤‘ì¹˜ë¡œ í‰ê°€"""
        y_pred = self.predict(X_val, weights)
        return euclidean_distance(y_val, y_pred)

    def optimize_weights(self, X_val, y_val, verbose=True):
        """ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰ (Grid Search)"""
        if verbose:
            print("\nğŸ” ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰ ì¤‘...")

        best_score = float('inf')
        best_weights = None

        # 3ê°œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì¡°í•© íƒìƒ‰ (í•©ì´ 1.0)
        weight_range = np.arange(0.0, 1.1, 0.1)

        for w1 in weight_range:
            for w2 in weight_range:
                w3 = 1.0 - w1 - w2
                if w3 < 0 or w3 > 1.0:
                    continue

                weights = [w1, w2, w3]
                score = self.evaluate_weights(X_val, y_val, weights)

                if score < best_score:
                    best_score = score
                    best_weights = weights

        self.best_weights = best_weights
        self.best_score = best_score

        if verbose:
            print(f"âœ… ìµœì  ê°€ì¤‘ì¹˜: {[f'{w:.2f}' for w in best_weights]}")
            print(f"âœ… ìµœì  ì„±ëŠ¥: {best_score:.2f}m")

        return best_weights, best_score

    def evaluate(self, X, y_true, weights=None, verbose=True):
        """í‰ê°€"""
        y_pred = self.predict(X, weights)

        eucl_dist = euclidean_distance(y_true, y_pred)
        mse_x = mean_squared_error(y_true[:, 0], y_pred[:, 0])
        mse_y = mean_squared_error(y_true[:, 1], y_pred[:, 1])

        if verbose:
            print(f"ğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥:")
            print(f"  - ìœ í´ë¦¬ë“œ ê±°ë¦¬: {eucl_dist:.2f}m")
            print(f"  - MSE X: {mse_x:.2f}")
            print(f"  - MSE Y: {mse_y:.2f}")

        return eucl_dist, mse_x, mse_y

    def save(self, filename='ensemble_3models.pkl'):
        """ì•™ìƒë¸” ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'models': self.models,
                'model_names': self.model_names,
                'weights': self.best_weights if self.best_weights else self.weights,
                'val_score': self.best_score if self.best_score else None
            }, f)
        print(f"âœ… ì•™ìƒë¸” ì €ì¥: {filename}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("  K-League Pass Prediction - 3-Model Ensemble")
    print("  XGBoost + LightGBM + CatBoost")
    print("=" * 80 + "\n")

    # train_utils ì‚¬ìš©
    from train_utils import load_data_and_features

    # 1. ë°ì´í„° ë¡œë”©
    data, feature_cols, target_cols, config = load_data_and_features()

    print(f"\nğŸ“Š í”¼ì²˜ ì •ë³´:")
    print(f"  - ì„¤ì • íŒŒì¼ í”¼ì²˜: {len(feature_cols)}ê°œ")
    print(f"  - ì‚¬ìš© ê°€ëŠ¥ í”¼ì²˜: {len([c for c in feature_cols if c in data.columns])}ê°œ")
    print(f"  - íƒ€ê²Ÿ: {', '.join(target_cols)}")

    # 2. Train/Val Split
    games = data['game_id'].unique()
    np.random.seed(42)
    np.random.shuffle(games)

    n_val_games = int(len(games) * 0.2)
    val_games = games[:n_val_games]

    val_mask = data['game_id'].isin(val_games)
    train_mask = ~val_mask

    # DataFrame í˜•íƒœë¡œ ìœ ì§€ (CatBoostë¥¼ ìœ„í•´)
    X_train = data.loc[train_mask, feature_cols].fillna(0).copy()
    y_train = data.loc[train_mask, target_cols].values
    X_val = data.loc[val_mask, feature_cols].fillna(0).copy()
    y_val = data.loc[val_mask, target_cols].values

    # ë²”ì£¼í˜• í”¼ì²˜ë¥¼ integerë¡œ ë³€í™˜ (CatBoost ìš”êµ¬ì‚¬í•­)
    categorical_features = config.get_categorical_features()
    categorical_features = [f for f in categorical_features if f in feature_cols]

    for col in categorical_features:
        if col in X_train.columns:
            X_train[col] = X_train[col].astype(int)
            X_val[col] = X_val[col].astype(int)

    print(f"\nğŸ“Š Train/Val Split (ê²Œì„ ê¸°ë°˜)...")
    print(f"  - Train: {len(games) - n_val_games} ê²Œì„, {len(X_train):,} ì—í”¼ì†Œë“œ")
    print(f"  - Val: {n_val_games} ê²Œì„, {len(X_val):,} ì—í”¼ì†Œë“œ")
    print(f"  - í”¼ì²˜: {len(feature_cols)}ê°œ\n")

    # 3. ì•™ìƒë¸” êµ¬ì„±
    print("\n" + "=" * 80)
    print("  ì•™ìƒë¸” êµ¬ì„±")
    print("=" * 80 + "\n")

    ensemble = ThreeModelEnsemble()
    ensemble.add_model('xgboost_baseline.pkl', 'XGBoost', weight=1/3)
    ensemble.add_model('lightgbm_model.pkl', 'LightGBM', weight=1/3)
    ensemble.add_model('catboost_model.pkl', 'CatBoost', weight=1/3)

    # 4. ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    print("\n" + "=" * 80)
    print("  ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ (Validation)")
    print("=" * 80 + "\n")

    individual_scores = []
    print("ê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
    print("-" * 60)

    for i, (model, name) in enumerate(zip(ensemble.models, ensemble.model_names)):
        pred_x = model['model_x'].predict(X_val)
        pred_y = model['model_y'].predict(X_val)
        pred = np.column_stack([pred_x, pred_y])

        score = euclidean_distance(y_val, pred)
        individual_scores.append(score)
        print(f"  {name:10s}: {score:.2f}m")

    print("-" * 60)

    # 5. ê¸°ë³¸ ì•™ìƒë¸” í‰ê°€ (ë™ì¼ ê°€ì¤‘ì¹˜)
    print("\n" + "=" * 80)
    print(f"  ê¸°ë³¸ ì•™ìƒë¸” í‰ê°€ (ê°€ì¤‘ì¹˜ {1/3:.2f} : {1/3:.2f} : {1/3:.2f})")
    print("=" * 80 + "\n")

    default_eucl, _, _ = ensemble.evaluate(X_val, y_val)

    # 6. ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰
    print("\n" + "=" * 80)
    print("  ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰")
    print("=" * 80)

    best_weights, best_score = ensemble.optimize_weights(X_val, y_val)

    # 7. ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” í‰ê°€
    print("\n" + "=" * 80)
    print("  ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” í‰ê°€")
    print("=" * 80 + "\n")

    print(f"ğŸ¯ ìµœì  ê°€ì¤‘ì¹˜:")
    for name, w in zip(ensemble.model_names, best_weights):
        print(f"  - {name:10s}: {w:.2f}")
    print()

    final_eucl, _, _ = ensemble.evaluate(X_val, y_val, weights=best_weights)

    # 8. ìµœì¢… ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 80)
    print("  ìµœì¢… ê²°ê³¼ ë¹„êµ")
    print("=" * 80 + "\n")

    print(f"""    ğŸ“Š ê°œë³„ ëª¨ë¸:
      - XGBoost:  {individual_scores[0]:.2f}m
      - LightGBM: {individual_scores[1]:.2f}m
      - CatBoost: {individual_scores[2]:.2f}m
    
    ğŸ“Š ì•™ìƒë¸” (ë™ì¼ ê°€ì¤‘ì¹˜):
      - ì„±ëŠ¥: {default_eucl:.2f}m
    
    ğŸ“Š ì•™ìƒë¸” (ìµœì  ê°€ì¤‘ì¹˜):
      - ê°€ì¤‘ì¹˜: XGBoost {best_weights[0]:.2f}, LightGBM {best_weights[1]:.2f}, CatBoost {best_weights[2]:.2f}
      - ì„±ëŠ¥: {final_eucl:.2f}m
    
    ğŸ“Š ê°œì„ :
      - ìµœê³  ë‹¨ë… ëª¨ë¸({min(individual_scores):.2f}m) ëŒ€ë¹„: {min(individual_scores) - final_eucl:.2f}m ê°œì„ 
    """)

    if final_eucl < 1.0:
        print("ğŸ¯ âœ… 1.0m ì´í•˜ ë‹¬ì„±!")
    if final_eucl < 0.9:
        print("ğŸ‰ âœ… 0.9m ì´í•˜ ë‹¬ì„±! ìš°ìˆ˜í•œ ì„±ëŠ¥!")
    if final_eucl < 0.8:
        print("ğŸ† âœ… 0.8m ì´í•˜ ë‹¬ì„±! íƒì›”í•œ ì„±ëŠ¥!")
    if final_eucl < 0.7:
        print("ğŸ’ âœ… 0.7m ì´í•˜ ë‹¬ì„±! ìµœìƒìœ„ ì„±ëŠ¥!")

    # 9. Train Set ì„±ëŠ¥ (ê³¼ì í•© ì²´í¬)
    print("\n" + "=" * 80)
    print("  Train Set ì„±ëŠ¥")
    print("=" * 80 + "\n")

    train_eucl, _, _ = ensemble.evaluate(X_train, y_train, weights=best_weights, verbose=True)

    print(f"\nğŸ“Š Overfitting ì²´í¬:")
    print(f"  - Train: {train_eucl:.2f}m")
    print(f"  - Val: {final_eucl:.2f}m")
    print(f"  - ë¹„ìœ¨: {train_eucl / final_eucl:.2f}")

    if train_eucl / final_eucl < 0.3:
        print("  âœ… ê³¼ì í•© ì—†ìŒ (ì•ˆì •ì )")
    else:
        print("  âš ï¸  ì•½ê°„ì˜ ê³¼ì í•© ê°€ëŠ¥ì„±")

    # 10. ì•™ìƒë¸” ì €ì¥
    print("\n" + "=" * 80)
    ensemble.save('ensemble_3models.pkl')

    # 11. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("  ğŸ‰ ìµœì¢… ìš”ì•½")
    print("=" * 80 + "\n")

    print(f"""    âœ… 3ì¢… ì•™ìƒë¸” ëª¨ë¸ ì™„ì„±!
    
    ğŸ“Š ìµœì¢… ì„±ëŠ¥:
      - Validation: {final_eucl:.2f}m
      - Train: {train_eucl:.2f}m
    
    ğŸ“Š êµ¬ì„±:
      - XGBoost ({best_weights[0]:.2f}) + LightGBM ({best_weights[1]:.2f}) + CatBoost ({best_weights[2]:.2f})
    
    ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„:
      - ë‹¨ìˆœ ë² ì´ìŠ¤ë¼ì¸ (20.37m) â†’ {final_eucl:.2f}m
      - ê°œì„ : {20.37 - final_eucl:.2f}m ({(20.37 - final_eucl)/20.37*100:.1f}%)
    
    ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:
      1. Test ë°ì´í„° ì˜ˆì¸¡ (inference_3models.py)
      2. ì œì¶œ íŒŒì¼ ìƒì„±
      3. ëŒ€íšŒ í”Œë«í¼ì— ì œì¶œ
      4. ë¦¬ë”ë³´ë“œ í™•ì¸
    
    ğŸ† í˜„ì¬ ìœ„ì¹˜: ìµœìƒìœ„ê¶Œ ì˜ˆìƒ!
    """)

    return ensemble, final_eucl


if __name__ == "__main__":
    ensemble, final_score = main()

