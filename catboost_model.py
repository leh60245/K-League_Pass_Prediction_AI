"""
K-League Pass Prediction - CatBoost Model

ëª©í‘œ: 3ì¢… GBM ì•™ìƒë¸”ì„ ìœ„í•œ CatBoost ëª¨ë¸ ì¶”ê°€
ì˜ˆìƒ ì„±ëŠ¥: 0.9 ~ 1.2m (ë‹¨ë…), 0.85 ~ 0.90m (3ì¢… ì•™ìƒë¸”)
"""

import pandas as pd
import numpy as np
from catboost import CatBoostRegressor, Pool
from sklearn.metrics import mean_squared_error
import pickle
import warnings
warnings.filterwarnings('ignore')

def euclidean_distance(y_true, y_pred):
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    true_x, true_y = y_true[:, 0], y_true[:, 1]
    pred_x, pred_y = y_pred[:, 0], y_pred[:, 1]
    return np.mean(np.sqrt((true_x - pred_x)**2 + (true_y - pred_y)**2))

class CatBoostModel:
    def __init__(self):
        self.model_x = None
        self.model_y = None

    def train(self, X_train, y_train, X_val, y_val,
              categorical_features=None, params=None, verbose=True):
        """CatBoost ëª¨ë¸ í•™ìŠµ"""

        if params is None:
            params = {
                'iterations': 1000,  # 3000ì—ì„œ 1000ìœ¼ë¡œ ì¤„ì„ (ë¹ ë¥¸ í•™ìŠµ)
                'learning_rate': 0.1,  # 0.05ì—ì„œ 0.1ë¡œ ì¦ê°€ (ë¹ ë¥¸ ìˆ˜ë ´)
                'depth': 6,  # 8ì—ì„œ 6ìœ¼ë¡œ ì¤„ì„ (ë¹ ë¥¸ í•™ìŠµ)
                'l2_leaf_reg': 3,
                'min_data_in_leaf': 80,
                'random_strength': 1,
                'bagging_temperature': 1,
                'border_count': 128,  # 254ì—ì„œ 128ë¡œ ì¤„ì„
                'loss_function': 'RMSE',
                'eval_metric': 'RMSE',
                'random_seed': 42,
                'verbose': 50,  # Falseì—ì„œ 50ìœ¼ë¡œ ë³€ê²½ (ì§„í–‰ ìƒí™© í‘œì‹œ)
                'early_stopping_rounds': 50,  # 100ì—ì„œ 50ìœ¼ë¡œ ì¤„ì„ (ë¹ ë¥¸ ì¡°ê¸° ì¢…ë£Œ)
                'task_type': 'CPU',
                'thread_count': -1
            }

        if verbose:
            print("=" * 80)
            print("  CatBoost ëª¨ë¸ í•™ìŠµ")
            print("=" * 80)
            print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„°: {X_train.shape}")
            print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {X_val.shape}")
            if categorical_features:
                print(f"ğŸ“Š ë²”ì£¼í˜• í”¼ì²˜: {len(categorical_features)}ê°œ\n")

        # ë²”ì£¼í˜• í”¼ì²˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        cat_features_idx = None
        if categorical_features:
            cat_features_idx = [i for i, col in enumerate(X_train.columns)
                              if col in categorical_features]

        # end_x ì˜ˆì¸¡ ëª¨ë¸
        if verbose:
            print("ğŸ”µ end_x ëª¨ë¸ í•™ìŠµ ì¤‘... (ìµœëŒ€ 3000 rounds)")

        train_pool_x = Pool(X_train, y_train[:, 0], cat_features=cat_features_idx)
        val_pool_x = Pool(X_val, y_val[:, 0], cat_features=cat_features_idx)

        self.model_x = CatBoostRegressor(**params)
        self.model_x.fit(
            train_pool_x,
            eval_set=val_pool_x,
            use_best_model=True,
            plot=False
        )

        if verbose:
            print(f"  â†’ ìµœì¢… {self.model_x.best_iteration_} rounds í•™ìŠµ ì™„ë£Œ")

        # end_y ì˜ˆì¸¡ ëª¨ë¸
        if verbose:
            print("ğŸ”´ end_y ëª¨ë¸ í•™ìŠµ ì¤‘... (ìµœëŒ€ 3000 rounds)")

        train_pool_y = Pool(X_train, y_train[:, 1], cat_features=cat_features_idx)
        val_pool_y = Pool(X_val, y_val[:, 1], cat_features=cat_features_idx)

        self.model_y = CatBoostRegressor(**params)
        self.model_y.fit(
            train_pool_y,
            eval_set=val_pool_y,
            use_best_model=True,
            plot=False
        )

        if verbose:
            print(f"  â†’ ìµœì¢… {self.model_y.best_iteration_} rounds í•™ìŠµ ì™„ë£Œ")
            print("âœ… í•™ìŠµ ì™„ë£Œ!\n")

    def predict(self, X):
        """ì˜ˆì¸¡"""
        pred_x = self.model_x.predict(X)
        pred_y = self.model_y.predict(X)
        return np.column_stack([pred_x, pred_y])

    def evaluate(self, X, y_true, verbose=True):
        """í‰ê°€"""
        y_pred = self.predict(X)

        # ìœ í´ë¦¬ë“œ ê±°ë¦¬
        eucl_dist = euclidean_distance(y_true, y_pred)

        # MSE (ê°œë³„)
        mse_x = mean_squared_error(y_true[:, 0], y_pred[:, 0])
        mse_y = mean_squared_error(y_true[:, 1], y_pred[:, 1])

        if verbose:
            print(f"ğŸ“Š í‰ê°€ ê²°ê³¼:")
            print(f"  - ìœ í´ë¦¬ë“œ ê±°ë¦¬: {eucl_dist:.2f}m")
            print(f"  - MSE X: {mse_x:.2f}")
            print(f"  - MSE Y: {mse_y:.2f}")

        return eucl_dist, mse_x, mse_y

    def get_feature_importance(self, feature_names, top_n=20):
        """í”¼ì²˜ ì¤‘ìš”ë„"""
        importance_x = self.model_x.get_feature_importance()
        importance_y = self.model_y.get_feature_importance()

        # í‰ê·  ì¤‘ìš”ë„
        avg_importance = (importance_x + importance_y) / 2

        # ì •ê·œí™”
        avg_importance = avg_importance / avg_importance.sum()

        # DataFrame ìƒì„±
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': avg_importance,
            'importance_x': importance_x / importance_x.sum(),
            'importance_y': importance_y / importance_y.sum()
        })

        importance_df = importance_df.sort_values('importance', ascending=False)

        if top_n:
            importance_df = importance_df.head(top_n)

        return importance_df

    def save(self, filename='catboost_model.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        with open(filename, 'wb') as f:
            pickle.dump({
                'model_x': self.model_x,
                'model_y': self.model_y
            }, f)
        print(f"âœ… ëª¨ë¸ ì €ì¥: {filename}")

    @staticmethod
    def load(filename='catboost_model.pkl'):
        """ëª¨ë¸ ë¡œë”©"""
        with open(filename, 'rb') as f:
            saved = pickle.load(f)

        model = CatBoostModel()
        model.model_x = saved['model_x']
        model.model_y = saved['model_y']

        print(f"âœ… ëª¨ë¸ ë¡œë”©: {filename}")
        return model


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("  K-League Pass Prediction - CatBoost Model")
    print("=" * 80)
    print("ëª©í‘œ: 3ì¢… GBM ì•™ìƒë¸” ì¤€ë¹„")
    print("=" * 80 + "\n")

    # train_utils ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
    from train_utils import load_data_and_features, prepare_train_val_split
    from feature_config import FeatureConfig

    # 1. ë°ì´í„° ë° í”¼ì²˜ ì„¤ì • ë¡œë”©
    data, feature_cols, target_cols, config = load_data_and_features()

    print(f"\nğŸ“Š í”¼ì²˜ ì •ë³´:")
    print(f"  - ì„¤ì • íŒŒì¼ í”¼ì²˜: {len(feature_cols)}ê°œ")
    print(f"  - ì‚¬ìš© ê°€ëŠ¥ í”¼ì²˜: {len([c for c in feature_cols if c in data.columns])}ê°œ")
    print(f"  - íƒ€ê²Ÿ: {', '.join(target_cols)}")

    # 2. Train/Val Split
    # ê²Œì„ ê¸°ë°˜ ë¶„í• 
    games = data['game_id'].unique()
    np.random.seed(42)
    np.random.shuffle(games)

    n_val_games = int(len(games) * 0.2)
    val_games = games[:n_val_games]

    val_mask = data['game_id'].isin(val_games)
    train_mask = ~val_mask

    # DataFrame í˜•íƒœë¡œ ìœ ì§€
    X_train = data.loc[train_mask, feature_cols].fillna(0)
    y_train = data.loc[train_mask, target_cols].values
    X_val = data.loc[val_mask, feature_cols].fillna(0)
    y_val = data.loc[val_mask, target_cols].values

    print(f"\nğŸ“Š Train/Val Split (ê²Œì„ ê¸°ë°˜)...")
    print(f"  - Train: {len(games) - n_val_games} ê²Œì„, {len(X_train):,} ì—í”¼ì†Œë“œ")
    print(f"  - Val: {n_val_games} ê²Œì„, {len(X_val):,} ì—í”¼ì†Œë“œ")
    print(f"  - í”¼ì²˜: {len(feature_cols)}ê°œ\n")

    # 3. ë²”ì£¼í˜• í”¼ì²˜ ì¶”ì¶œ ë° íƒ€ì… ë³€í™˜
    categorical_features = config.get_categorical_features()
    categorical_features = [f for f in categorical_features if f in feature_cols]

    # ë²”ì£¼í˜• í”¼ì²˜ë¥¼ integerë¡œ ë³€í™˜ (CatBoost ìš”êµ¬ì‚¬í•­)
    for col in categorical_features:
        if col in X_train.columns:
            X_train[col] = X_train[col].astype(int)
            X_val[col] = X_val[col].astype(int)

    # 4. CatBoost ëª¨ë¸ í•™ìŠµ
    model = CatBoostModel()
    model.train(
        X_train, y_train, X_val, y_val,
        categorical_features=categorical_features,
        verbose=True
    )

    # 5. í‰ê°€
    print("\n" + "=" * 80)
    print("  ëª¨ë¸ í‰ê°€")
    print("=" * 80 + "\n")

    print("[Train Set]")
    train_eucl, train_mse_x, train_mse_y = model.evaluate(X_train, y_train, verbose=False)
    print(f"  - ìœ í´ë¦¬ë“œ ê±°ë¦¬: {train_eucl:.2f}m\n")

    print("[Validation Set]")
    val_eucl, val_mse_x, val_mse_y = model.evaluate(X_val, y_val)

    # 6. ì„±ëŠ¥ ìš”ì•½
    print("\n" + "=" * 80)
    print("  ì„±ëŠ¥ ìš”ì•½")
    print("=" * 80 + "\n")

    print(f"ğŸ“Š ìœ í´ë¦¬ë“œ ê±°ë¦¬:")
    print(f"  - Train: {train_eucl:.2f}m")
    print(f"  - Val: {val_eucl:.2f}m")

    baseline = 20.37
    improvement = baseline - val_eucl
    improvement_pct = (improvement / baseline) * 100

    print(f"\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„:")
    print(f"  - ë² ì´ìŠ¤ë¼ì¸: {baseline}m")
    print(f"  - ê°œì„ : {improvement:.2f}m (+{improvement_pct:.1f}%)")

    if val_eucl < baseline:
        print(f"  âœ… ë² ì´ìŠ¤ë¼ì¸ë³´ë‹¤ {improvement:.2f}m ê°œì„ !")

    target = 18.0
    print(f"\nğŸ“Š ëª©í‘œ ë‹¬ì„±:")
    print(f"  - ëª©í‘œ: < {target:.2f}m")
    print(f"  - í˜„ì¬: {val_eucl:.2f}m")

    if val_eucl < target:
        print(f"  ğŸ¯ ëª©í‘œ ë‹¬ì„±! ({val_eucl:.2f}m < {target:.2f}m)")

    print("=" * 80)

    # 7. ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë¹„êµ
    print("\n" + "=" * 80)
    print("  ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµ")
    print("=" * 80 + "\n")

    xgb_score = 1.24  # ì´ì „ ê²°ê³¼
    lgb_score = 0.93  # ì´ì „ ê²°ê³¼

    print(f"ğŸ“Š XGBoost:  {xgb_score:.2f}m")
    print(f"ğŸ“Š LightGBM: {lgb_score:.2f}m")
    print(f"ğŸ“Š CatBoost: {val_eucl:.2f}m")

    best_single = min(xgb_score, lgb_score, val_eucl)
    if val_eucl == best_single:
        print(f"âœ… CatBoostê°€ ìµœê³  ì„±ëŠ¥!")
    elif val_eucl < xgb_score:
        print(f"âœ… CatBoostê°€ XGBoostë³´ë‹¤ {xgb_score - val_eucl:.2f}m ë” ì¢‹ìŠµë‹ˆë‹¤!")

    # 3ì¢… ì•™ìƒë¸” ì˜ˆìƒ ì„±ëŠ¥
    expected_ensemble = best_single * 0.95  # ë³´í†µ 5% ì •ë„ ê°œì„ 
    print(f"\nğŸ“Š 3ì¢… ì•™ìƒë¸” ì˜ˆìƒ ì„±ëŠ¥:")
    print(f"   - XGBoost + LightGBM + CatBoost: ~{expected_ensemble:.2f}m")
    if expected_ensemble < 0.9:
        print(f"   ğŸ¯ 0.9m ì´í•˜ ë‹¬ì„± ê°€ëŠ¥!")

    # 8. í”¼ì²˜ ì¤‘ìš”ë„ (Top 20)
    print("\n" + "=" * 80)
    print("  í”¼ì²˜ ì¤‘ìš”ë„ (Top 20)")
    print("=" * 80 + "\n")

    importance_df = model.get_feature_importance(feature_cols, top_n=20)

    for idx, row in importance_df.iterrows():
        print(f"{row['feature']:30s}: {row['importance']:.4f}")

    # 9. ëª¨ë¸ ì €ì¥
    print("\n" + "=" * 80)
    model.save('catboost_model.pkl')

    # 10. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("  ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 80 + "\n")

    print(f"âœ… CatBoost ëª¨ë¸ ê°œë°œ ì™„ë£Œ!")
    print(f"   - Val ì„±ëŠ¥: {val_eucl:.2f}m")
    print(f"   - í”¼ì²˜ ê°œìˆ˜: {len(feature_cols)}")
    print(f"   - ëª¨ë¸ ì €ì¥: catboost_model.pkl")

    print(f"\nğŸ“Š ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. 3ì¢… ì•™ìƒë¸” êµ¬ì„± (XGBoost + LightGBM + CatBoost)")
    print(f"   2. ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰")
    print(f"   3. Test ë°ì´í„° ì˜ˆì¸¡")
    print(f"   4. ìµœì¢… ì œì¶œ")

    return model, val_eucl


if __name__ == "__main__":
    model, final_score = main()

